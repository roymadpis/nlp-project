{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cf22d0d",
   "metadata": {},
   "source": [
    "### Step_0 Retrieve tweets for brexit\n",
    "In this notebook we retrive from twitter tweets that are relevant to brexit from different time-frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da172a0e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-17T11:55:50.997548Z",
     "start_time": "2022-06-17T11:55:50.986557Z"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv , datetime, unicodedata, time, tweeterid #dateutil.parserm,\n",
    "import gensim\n",
    "import openpyxl\n",
    "import json\n",
    "\n",
    "from os import path\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "from inputimeout import inputimeout, TimeoutOccurred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68b74142",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-17T11:55:51.836070Z",
     "start_time": "2022-06-17T11:55:51.785110Z"
    }
   },
   "outputs": [],
   "source": [
    "from Brexit_Package import TwitterCrawler\n",
    "\n",
    "my_token = 'NLP_is_fun' ### Of course one need to provide here a real valid token, unfortunelty we can't publish our token...\n",
    "#my_token = \"AAAAAAAAAAAAAAAAAAAAAPr2WAEAAAAARCTqXt1KnbCbnG4FzY8S8A5zoYg%3DYWyy0y9SQtwDenwjkU8UB662tfhm8yxZl3Ud3T3aEerCMT6B9W\" #roy madpis\n",
    "my_token = 'AAAAAAAAAAAAAAAAAAAAADRFOwEAAAAAaTp%2Bdd1OhobYMYb5ExPXm7IL6RA%3DDHknH402gOXoegUGxNtpC6giIjdackRLtdRx6tjrnnLeFN1ntT' #idc\n",
    "my_twitter_crawler = TwitterCrawler(bearer_token= my_token)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "892e352c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-17T11:55:52.602207Z",
     "start_time": "2022-06-17T11:55:52.593210Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000\n"
     ]
    }
   ],
   "source": [
    "limit_amount_of_returned_tweets = 25000\n",
    "max_results = 500\n",
    "dir_name = \"Roy_tweets_brexit\"\n",
    "query = \"(Brexit OR BREXIT OR brexit OR BRexit OR BREX OR brex OR brexi OR Brexi) lang:en -is:retweet -is:reply -is:quote -from:theresa_may -from:NicolaSturgeon -from:MichelBarnier -from:fhollande -from:PhilipHammondUK -from:DavidDavisMP -from:JunckerEU -from:guyverhofstadt -from:EndaKennyTD -from:hilarybennmp -from:MinPres -from:MartinSelmayr -from:Keir_Starmer -from:LiamFox -from:TimmermansEU -from:BorisJohnson -from:Nigel_Farage -from:ManfredWeber -from:davidmcallister -from:matteorenzi -from:SadiqKhan -from:cbicarolyn -from:rupertmurdoch -from:WeyandSabine -from:MLP_officiel -from:FrancesOGrady -from:giannipittella -from:MalmstromEU -from:TheGinaMiller -from:CER_Grant -from:AMCarwyn -from:AlunCairns -from:DominicRaab  -from:michaelgove  -from:theJeremyVine -from:George_Osborne  -from:michaelhsltine_  -from:WilliamJHague -from:ChukaUmunna -from:jeremycorbyn -from:Dyson -from:SteveO_Connell -from:MorrisseyHelena -from:GroovyTimbo\"\n",
    " \n",
    "\n",
    "print(limit_amount_of_returned_tweets*8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30d9304",
   "metadata": {},
   "source": [
    "### Retrive tweets from 2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0667c90f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-17T11:36:30.966871Z",
     "start_time": "2022-06-17T11:36:10.002695Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dir Roy_tweets_brexit already exist\n",
      "The dir Roy_tweets_brexit\\log_tweets already exist\n",
      "The dir Roy_tweets_brexit\\log_tweets\\brexit_2014 already exist\n",
      "no more tweets from this user\n",
      "Total amount of collected tweets =  4252\n"
     ]
    }
   ],
   "source": [
    "start_time = \"2014-01-01T00:00:00Z\"\n",
    "end_time = \"2014-12-31T00:00:00Z\"\n",
    "csv_table_name = \"brexit_2014\"\n",
    "limit_amount_of_returned_tweets = 40000\n",
    "###########################################\n",
    "json_response_list, num_of_returned_tweets, next_tokens  = my_twitter_crawler.return_tweets_given_query(\n",
    "    query=query,\n",
    "    start_time = start_time,\n",
    "    end_time = end_time,\n",
    "    max_results = max_results, evaluate_last_token = True,\n",
    "    limit_amount_of_returned_tweets = limit_amount_of_returned_tweets,\n",
    "   verbose_10 = False, dir_name =dir_name, csv_table_name = csv_table_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5fc10f9",
   "metadata": {},
   "source": [
    "### Retrive tweets from 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "687a30f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-17T12:02:02.996615Z",
     "start_time": "2022-06-17T11:56:03.878320Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dir Roy_tweets_brexit already exist\n",
      "The dir Roy_tweets_brexit\\log_tweets already exist\n",
      "The dir Roy_tweets_brexit\\log_tweets\\brexit_2015 already exist\n",
      "1 Got from twitter 487 tweets, and there are more tweets of that user to get, I am bringing more tweets!\n",
      "\n",
      "21 Got from twitter 490 tweets, and there are more tweets of that user to get, I am bringing more tweets!\n",
      "\n",
      "41 Got from twitter 494 tweets, and there are more tweets of that user to get, I am bringing more tweets!\n",
      "\n",
      "oooops, There may be more tweets to return, but you asked to limit the amount of returned tweets\n",
      "infact you got 25002 returned tweets and limited the function to get 25000 tweets\n"
     ]
    }
   ],
   "source": [
    "start_time = \"2015-01-01T00:00:00Z\"\n",
    "end_time = \"2015-12-31T00:00:00Z\"\n",
    "csv_table_name = \"brexit_2015\"\n",
    "\n",
    "###########################################\n",
    "json_response_list, num_of_returned_tweets, next_tokens  = my_twitter_crawler.return_tweets_given_query(\n",
    "    query=query,\n",
    "    start_time = start_time,\n",
    "    end_time = end_time,\n",
    "    max_results = max_results, evaluate_last_token = True,\n",
    "    limit_amount_of_returned_tweets = limit_amount_of_returned_tweets,\n",
    "   verbose_10 = True, dir_name =dir_name, csv_table_name = csv_table_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62206657",
   "metadata": {},
   "source": [
    "### Retrive tweets from 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62fcc5c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-17T12:07:09.721477Z",
     "start_time": "2022-06-17T12:02:33.530666Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dir Roy_tweets_brexit already exist\n",
      "The dir Roy_tweets_brexit\\log_tweets already exist\n",
      "The dir Roy_tweets_brexit\\log_tweets\\brexit_2016 already exist\n",
      "1 Got from twitter 495 tweets, and there are more tweets of that user to get, I am bringing more tweets!\n",
      "\n",
      "21 Got from twitter 493 tweets, and there are more tweets of that user to get, I am bringing more tweets!\n",
      "\n",
      "41 Got from twitter 498 tweets, and there are more tweets of that user to get, I am bringing more tweets!\n",
      "\n",
      "oooops, There may be more tweets to return, but you asked to limit the amount of returned tweets\n",
      "infact you got 25009 returned tweets and limited the function to get 25000 tweets\n"
     ]
    }
   ],
   "source": [
    "start_time = \"2016-01-01T00:00:00Z\"\n",
    "end_time = \"2016-12-31T00:00:00Z\"\n",
    "csv_table_name = \"brexit_2016\"\n",
    "\n",
    "###########################################\n",
    "json_response_list, num_of_returned_tweets, next_tokens  = my_twitter_crawler.return_tweets_given_query(\n",
    "    query=query,\n",
    "    start_time = start_time,\n",
    "    end_time = end_time,\n",
    "    max_results = max_results, evaluate_last_token = True,\n",
    "    limit_amount_of_returned_tweets = limit_amount_of_returned_tweets,\n",
    "   verbose_10 = True, dir_name =dir_name, csv_table_name = csv_table_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94327ba6",
   "metadata": {},
   "source": [
    "### Retrive tweets from 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2dc6e064",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-17T12:13:40.392640Z",
     "start_time": "2022-06-17T12:07:32.978863Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dir Roy_tweets_brexit already exist\n",
      "The dir Roy_tweets_brexit\\log_tweets already exist\n",
      "The dir Roy_tweets_brexit\\log_tweets\\brexit_2017 already exist\n",
      "1 Got from twitter 489 tweets, and there are more tweets of that user to get, I am bringing more tweets!\n",
      "\n",
      "21 Got from twitter 488 tweets, and there are more tweets of that user to get, I am bringing more tweets!\n",
      "\n",
      "41 Got from twitter 492 tweets, and there are more tweets of that user to get, I am bringing more tweets!\n",
      "\n",
      "oooops, There may be more tweets to return, but you asked to limit the amount of returned tweets\n",
      "infact you got 25004 returned tweets and limited the function to get 25000 tweets\n"
     ]
    }
   ],
   "source": [
    "start_time = \"2017-01-01T00:00:00Z\"\n",
    "end_time = \"2017-12-31T00:00:00Z\"\n",
    "csv_table_name = \"brexit_2017\"\n",
    "\n",
    "###########################################\n",
    "json_response_list, num_of_returned_tweets, next_tokens  = my_twitter_crawler.return_tweets_given_query(\n",
    "    query=query,\n",
    "    start_time = start_time,\n",
    "    end_time = end_time,\n",
    "    max_results = max_results, evaluate_last_token = True,\n",
    "    limit_amount_of_returned_tweets = limit_amount_of_returned_tweets,\n",
    "   verbose_10 = True, dir_name =dir_name, csv_table_name = csv_table_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f066e1",
   "metadata": {},
   "source": [
    "### Retrive tweets from 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7b457f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-17T12:19:50.996707Z",
     "start_time": "2022-06-17T12:14:05.541970Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dir Roy_tweets_brexit already exist\n",
      "The dir Roy_tweets_brexit\\log_tweets already exist\n",
      "The dir Roy_tweets_brexit\\log_tweets\\brexit_2018 already exist\n",
      "1 Got from twitter 489 tweets, and there are more tweets of that user to get, I am bringing more tweets!\n",
      "\n",
      "21 Got from twitter 493 tweets, and there are more tweets of that user to get, I am bringing more tweets!\n",
      "\n",
      "41 Got from twitter 482 tweets, and there are more tweets of that user to get, I am bringing more tweets!\n",
      "\n",
      "oooops, There may be more tweets to return, but you asked to limit the amount of returned tweets\n",
      "infact you got 25003 returned tweets and limited the function to get 25000 tweets\n"
     ]
    }
   ],
   "source": [
    "start_time = \"2018-01-01T00:00:00Z\"\n",
    "end_time = \"2018-12-31T00:00:00Z\"\n",
    "csv_table_name = \"brexit_2018\"\n",
    "\n",
    "###########################################\n",
    "json_response_list, num_of_returned_tweets, next_tokens  = my_twitter_crawler.return_tweets_given_query(\n",
    "    query=query,\n",
    "    start_time = start_time,\n",
    "    end_time = end_time,\n",
    "    max_results = max_results, evaluate_last_token = True,\n",
    "    limit_amount_of_returned_tweets = limit_amount_of_returned_tweets,\n",
    "   verbose_10 = True, dir_name =dir_name, csv_table_name = csv_table_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb160cd3",
   "metadata": {},
   "source": [
    "### Retrive tweets from 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4541d87",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-17T12:26:13.731308Z",
     "start_time": "2022-06-17T12:20:32.425998Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dir Roy_tweets_brexit already exist\n",
      "The dir Roy_tweets_brexit\\log_tweets already exist\n",
      "The dir Roy_tweets_brexit\\log_tweets\\brexit_2019 already exist\n",
      "1 Got from twitter 484 tweets, and there are more tweets of that user to get, I am bringing more tweets!\n",
      "\n",
      "21 Got from twitter 490 tweets, and there are more tweets of that user to get, I am bringing more tweets!\n",
      "\n",
      "41 Got from twitter 478 tweets, and there are more tweets of that user to get, I am bringing more tweets!\n",
      "\n",
      "oooops, There may be more tweets to return, but you asked to limit the amount of returned tweets\n",
      "infact you got 25007 returned tweets and limited the function to get 25000 tweets\n"
     ]
    }
   ],
   "source": [
    "start_time = \"2019-01-01T00:00:00Z\"\n",
    "end_time = \"2019-12-31T00:00:00Z\"\n",
    "csv_table_name = \"brexit_2019\"\n",
    "\n",
    "###########################################\n",
    "json_response_list, num_of_returned_tweets, next_tokens  = my_twitter_crawler.return_tweets_given_query(\n",
    "    query=query,\n",
    "    start_time = start_time,\n",
    "    end_time = end_time,\n",
    "    max_results = max_results, evaluate_last_token = True,\n",
    "    limit_amount_of_returned_tweets = limit_amount_of_returned_tweets,\n",
    "   verbose_10 = True, dir_name =dir_name, csv_table_name = csv_table_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dfb8e4f",
   "metadata": {},
   "source": [
    "### Retrive tweets from 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc46d00b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-17T12:30:55.372093Z",
     "start_time": "2022-06-17T12:26:38.733891Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dir Roy_tweets_brexit already exist\n",
      "The dir Roy_tweets_brexit\\log_tweets already exist\n",
      "The dir Roy_tweets_brexit\\log_tweets\\brexit_2020 already exist\n",
      "1 Got from twitter 487 tweets, and there are more tweets of that user to get, I am bringing more tweets!\n",
      "\n",
      "21 Got from twitter 482 tweets, and there are more tweets of that user to get, I am bringing more tweets!\n",
      "\n",
      "41 Got from twitter 487 tweets, and there are more tweets of that user to get, I am bringing more tweets!\n",
      "\n",
      "oooops, There may be more tweets to return, but you asked to limit the amount of returned tweets\n",
      "infact you got 25001 returned tweets and limited the function to get 25000 tweets\n"
     ]
    }
   ],
   "source": [
    "start_time = \"2020-01-01T00:00:00Z\"\n",
    "end_time = \"2020-12-31T00:00:00Z\"\n",
    "csv_table_name = \"brexit_2020\"\n",
    "\n",
    "###########################################\n",
    "json_response_list, num_of_returned_tweets, next_tokens  = my_twitter_crawler.return_tweets_given_query(\n",
    "    query=query,\n",
    "    start_time = start_time,\n",
    "    end_time = end_time,\n",
    "    max_results = max_results, evaluate_last_token = True,\n",
    "    limit_amount_of_returned_tweets = limit_amount_of_returned_tweets,\n",
    "   verbose_10 = True, dir_name =dir_name, csv_table_name = csv_table_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587630dc",
   "metadata": {},
   "source": [
    "### Retrive tweets from 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3cf2c94c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-17T12:36:43.505644Z",
     "start_time": "2022-06-17T12:31:23.882169Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dir Roy_tweets_brexit already exist\n",
      "The dir Roy_tweets_brexit\\log_tweets already exist\n",
      "The dir Roy_tweets_brexit\\log_tweets\\brexit_2021 already exist\n",
      "1 Got from twitter 497 tweets, and there are more tweets of that user to get, I am bringing more tweets!\n",
      "\n",
      "21 Got from twitter 494 tweets, and there are more tweets of that user to get, I am bringing more tweets!\n",
      "\n",
      "41 Got from twitter 490 tweets, and there are more tweets of that user to get, I am bringing more tweets!\n",
      "\n",
      "oooops, There may be more tweets to return, but you asked to limit the amount of returned tweets\n",
      "infact you got 25008 returned tweets and limited the function to get 25000 tweets\n"
     ]
    }
   ],
   "source": [
    "start_time = \"2021-01-01T00:00:00Z\"\n",
    "end_time = \"2021-12-31T00:00:00Z\"\n",
    "csv_table_name = \"brexit_2021\"\n",
    "\n",
    "###########################################\n",
    "json_response_list, num_of_returned_tweets, next_tokens  = my_twitter_crawler.return_tweets_given_query(\n",
    "    query=query,\n",
    "    start_time = start_time,\n",
    "    end_time = end_time,\n",
    "    max_results = max_results, evaluate_last_token = True,\n",
    "    limit_amount_of_returned_tweets = limit_amount_of_returned_tweets,\n",
    "   verbose_10 = True, dir_name =dir_name, csv_table_name = csv_table_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753d66db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6403f7eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c81455b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e117e8ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e07ce14",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"(Brexit OR BREXIT)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb423f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"(Brexit OR BREXIT OR brexit)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb103c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"(Brexit OR BREXIT OR brexit) lang:en -is:retweet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e92723bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-17T08:24:25.115556Z",
     "start_time": "2022-06-17T08:24:25.109561Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03072e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#is:verified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33783ed5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-17T07:08:02.463555Z",
     "start_time": "2022-06-17T07:07:59.288367Z"
    }
   },
   "outputs": [],
   "source": [
    "filtered_table = pd.read_excel(\"data_folder/tweets_table_filtered2.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7bdace61",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-17T07:08:21.716882Z",
     "start_time": "2022-06-17T07:08:21.706889Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Walking out of the government won’t make Brexit go away, but as an optimist by nature, I hope that it creates some unity needed to find a parliamentary majority for an agreement that works. #brexit #BrexitShambles'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_table.text[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b3841bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-17T07:08:05.675722Z",
     "start_time": "2022-06-17T07:08:05.376892Z"
    }
   },
   "outputs": [],
   "source": [
    "def clean_text(x):\n",
    "    from gensim.utils import simple_preprocess\n",
    "    import contractions\n",
    "    x = contractions.fix(x)\n",
    "    x = ' '.join(simple_preprocess(x))\n",
    "    return x\n",
    "\n",
    "\n",
    "filtered_table['text1'] = filtered_table['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "71398419",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-17T07:08:34.615576Z",
     "start_time": "2022-06-17T07:08:34.605583Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'walking out of the government will not make brexit go away but as an optimist by nature hope that it creates some unity needed to find parliamentary majority for an agreement that works brexit brexitshambles'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_table.text1[2]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f04b1271",
   "metadata": {},
   "source": [
    "## Step 2 - Filtering Key Opinion Leaders Tweets\n",
    "\n",
    "In this step we are filtering the tweets of the Key Opinion Leaders, that we retrieved in the first step. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71ddb502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting inputimeout\n",
      "  Downloading inputimeout-1.0.4-py3-none-any.whl (4.6 kB)\n",
      "Installing collected packages: inputimeout\n",
      "Successfully installed inputimeout-1.0.4\n"
     ]
    }
   ],
   "source": [
    "#! pip install inputimeout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b2bdd5e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-17T12:37:22.151769Z",
     "start_time": "2022-06-17T12:37:21.904912Z"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv , datetime, unicodedata, time, tweeterid #dateutil.parserm,\n",
    "import gensim\n",
    "import openpyxl\n",
    "import json\n",
    "\n",
    "from os import path\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "from inputimeout import inputimeout, TimeoutOccurred\n",
    "\n",
    "data_folder_name = \"data_folder\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "53af82e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install gensim==4.1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "483acb8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.8.3'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gensim\n",
    "gensim.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "48fb5a41",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-17T12:39:30.864505Z",
     "start_time": "2022-06-17T12:39:30.831526Z"
    }
   },
   "outputs": [],
   "source": [
    "from Brexit_Package import TwitterCrawler\n",
    "\n",
    "my_token = 'NLP_is_fun' ### Of course one need to provide here a real valid token, unfortunelty we can't publish our token...\n",
    "my_twitter_crawler = TwitterCrawler(bearer_token= my_token)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5a6838",
   "metadata": {},
   "source": [
    "### Read all the data we have = all the tweets we read from twitter + some Preprocess\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "184358e2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-17T13:28:58.239452Z",
     "start_time": "2022-06-17T13:18:15.734325Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Reading all the csv files\n",
      "There are:  1362559 Tweets\n",
      "There are:  979821 Non duplicates Tweets\n",
      "Step 4-A: Reading stop words data and adding your stop words\n",
      "\n",
      "Step 4-B: Preprocess the tweets table - the text column - using contractions \n",
      "\n",
      "Step 5: Preprocess the tweets table for scoring:\n",
      "Removing Stop words| bigram, trigram, forthgram | merging the tweets table with the KOP and Events tables | \n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'gensim.models.phrases' has no attribute 'ENGLISH_CONNECTOR_WORDS'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_33944/2557764432.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[1;31m#print(f\"connector words: {gensim.models.phrases.ENGLISH_CONNECTOR_WORDS}\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[1;31m## train bygram model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m \u001b[0mbigram\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgensim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPhrases\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtweets_table\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'text_tokens'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_count\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconnector_words\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgensim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mphrases\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mENGLISH_CONNECTOR_WORDS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m \u001b[0mbigram_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgensim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mphrases\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPhraser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbigram\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"found {len(bigram_model.phrasegrams)} bigrams\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'gensim.models.phrases' has no attribute 'ENGLISH_CONNECTOR_WORDS'"
     ]
    }
   ],
   "source": [
    "import os \n",
    "\n",
    "dir_with_all_tweets = os.path.join(\"KOL tweets\")\n",
    "stop_words_file_name = \"stopwords.txt\"\n",
    "\n",
    "score_for_KOP = 0\n",
    "score_for_key_event = 5\n",
    "score_for_key_words = 5\n",
    "\n",
    "key_words = [\"brexit\", \"eu\", \"deal\", \"economy\"]\n",
    "threshold_score = 5\n",
    "verbose = True\n",
    "\n",
    "KOP_excel_name = \"KOP brexit.xlsx\"\n",
    "key_events_excel_name = \"Brexit_key_events.xlsx\"\n",
    "\n",
    "stop_words_to_add = [\"http\", \"https\", \"rt\", \"co\", \"vrkhaxde\"]\n",
    "\n",
    "start_fun_time = time.time()\n",
    "############# step 1 - Reading the tweets data #############\n",
    "if verbose: print(\"Step 1: Reading all the csv files\")\n",
    "tweets_tables = []\n",
    "csv_files_evaluated = []\n",
    "for root,dirs,files in os.walk(dir_with_all_tweets):\n",
    "    for file in files:\n",
    "        if file.endswith(\".csv\"): #if the file is csv\n",
    "            csv_files_evaluated.append(file)\n",
    "            #print(file)\n",
    "            file_location = os.path.join(dir_with_all_tweets, file)\n",
    "            tweets_tables.append(pd.read_csv(file_location))\n",
    "\n",
    "tweets_table = pd.concat(tweets_tables)\n",
    "tweets_table = tweets_table.drop(labels = [\"Unnamed: 0\"], axis = 1)\n",
    "all_tweets_back_up = tweets_table.copy()\n",
    "if verbose: print(\"There are: \", tweets_table.shape[0], \"Tweets\")\n",
    "    \n",
    "### removing duplicates rows\n",
    "tweets_table = tweets_table.drop_duplicates(subset=['author_id_new', 'conv_id_new', \"id_new\", \"created_at\", \"public_metrics.like_count\", \"text\"])\n",
    "if verbose: print(\"There are: \", tweets_table.shape[0], \"Non duplicates Tweets\")\n",
    "    \n",
    "# ############# step 2 - Reading events data #############\n",
    "# if verbose: print(\"Step 2: Reading The Events Excel File\")\n",
    "# dir_path_for_events_table = os.path.join(key_events_excel_name)\n",
    "# events_table = pd.read_excel(dir_path_for_events_table)\n",
    "# events_table = events_table.drop(labels = [\"tweets\", \"Arguments\", \"Index\"], axis = 1)\n",
    "# #display(events_table.head())\n",
    "\n",
    "# ############# step 3 - Reading KOP data #############\n",
    "# if verbose: print(\"Step 3: Reading and preprocessing Key Opinion Leaders data\")\n",
    "# dir_path_for_KOP_table = os.path.join(KOP_excel_name)\n",
    "# KOP_table = pd.read_excel(dir_path_for_KOP_table)\n",
    "# try:\n",
    "#     KOP_table.rename(columns = {'Unnamed: 0':'KOP_num',\n",
    "#                                 \"Born In\":\"Born_in\",\n",
    "#                                 \"Twitter acount name\" : \"twitter_user_name\",}, inplace = True)\n",
    "#     #drop unnecessary columns\n",
    "#     KOP_table = KOP_table.drop(labels = [\"Unnamed: 7\", \"Source\"], axis = 1)\n",
    "# except: print()\n",
    "\n",
    "# #remove KOP without twitter account name\n",
    "# KOP_table = KOP_table[KOP_table['twitter_user_name'].notna()]\n",
    "# #remove the \"@\" at the begining of some user names\n",
    "# KOP_table[\"clean_user_name\"] = KOP_table[\"twitter_user_name\"].apply(lambda x: x.replace(\"@\", \"\"))\n",
    "\n",
    "# def take_all_except_first_char(x):\n",
    "#     try:\n",
    "#         author_id = tweeterid.handle_to_id(x)\n",
    "#     except:\n",
    "#         author_id = \"-\"\n",
    "#     return author_id\n",
    "\n",
    "# KOP_table[\"author_id\"] = KOP_table[\"clean_user_name\"].apply(take_all_except_first_char)\n",
    "\n",
    "############# step 4-A - Stop-words #############\n",
    "if verbose: print(\"Step 4-A: Reading stop words data and adding your stop words\")\n",
    "stopwords_file_name = os.path.join(stop_words_file_name)\n",
    "stopwords_url = \"https://gist.githubusercontent.com/sebleier/554280/raw/7e0e4a1ce04c2bb7bd41089c9821dbcf6d0c786c/NLTK's%2520list%2520of%2520english%2520stopwords\"\n",
    "\n",
    "if not os.path.isfile(stopwords_file_name):\n",
    "    stopwords = requests.get(stopwords_url).text.split()\n",
    "    with open(stopwords_file_name,'w+t', encoding='utf-8') as out_file:\n",
    "        out_file.write(' '.join(stopwords))\n",
    "else:\n",
    "    with open(stopwords_file_name,'rt', encoding='utf-8') as in_file:\n",
    "        stopwords = in_file.readline().split()\n",
    "stopwords = set(stopwords)\n",
    "\n",
    "#### Adding stopWords\n",
    "for word_i in stop_words_to_add:\n",
    "    stopwords.add(word_i)\n",
    "\n",
    "############# step 4-B - contractions #############\n",
    "if verbose: print(\"\\nStep 4-B: Preprocess the tweets table - the text column - using contractions \")\n",
    "def clean_text(x):\n",
    "    from gensim.utils import simple_preprocess\n",
    "    import contractions\n",
    "    try:\n",
    "        x = contractions.fix(x)\n",
    "        x = ' '.join(simple_preprocess(x))\n",
    "    except:\n",
    "        fun = \"fun\"\n",
    "    return x\n",
    "tweets_table['text'] = tweets_table['text'].apply(clean_text)\n",
    "\n",
    "############# step 5 - Preprocess the tweets table for scoring #############\n",
    "if verbose: print(\"\\nStep 5: Preprocess the tweets table for scoring:\\nRemoving Stop words\\\n",
    "| bigram, trigram, forthgram | merging the tweets table with the KOP and Events tables | \")\n",
    "\n",
    "start_time = time.time()\n",
    "#using gensim function to split the text into tokens\n",
    "tweets_table[\"text_tokens\"] = tweets_table[\"text\"].apply(gensim.utils.simple_preprocess,{\"deacc\":True, \"min_len\":2,\"max_len\":25})\n",
    "\n",
    "#remove stopwords:\n",
    "def remove_stopwords(tokens, stopwords):\n",
    "    return [token for token in tokens if token not in stopwords]\n",
    "tweets_table['text_tokens'] = tweets_table['text_tokens'].apply(remove_stopwords, stopwords=stopwords)\n",
    "\n",
    "################################## add bygrams to the tokens\n",
    "#print(f\"connector words: {gensim.models.phrases.ENGLISH_CONNECTOR_WORDS}\")\n",
    "## train bygram model\n",
    "bigram = gensim.models.Phrases(tweets_table['text_tokens'], min_count=7, threshold=2, connector_words=gensim.models.phrases.ENGLISH_CONNECTOR_WORDS)\n",
    "bigram_model = gensim.models.phrases.Phraser(bigram)\n",
    "if verbose: print(f\"found {len(bigram_model.phrasegrams)} bigrams\")\n",
    "# bigram_model.phrasegrams #the bygrams the model found\n",
    "tweets_table['text_tokens'] = tweets_table['text_tokens'].apply(lambda x: bigram_model[x])\n",
    "###### add trigram to the tokens\n",
    "trigram = gensim.models.Phrases(tweets_table['text_tokens'], min_count=7, threshold=2, connector_words=gensim.models.phrases.ENGLISH_CONNECTOR_WORDS)\n",
    "trigram_model = gensim.models.phrases.Phraser(trigram)\n",
    "if verbose: print(f\"found {len(trigram_model.phrasegrams)} trigram\")\n",
    "#trigram_model.phrasegrams #the trigram that the model found\n",
    "tweets_table['text_tokens'] = tweets_table['text_tokens'].apply(lambda x: trigram_model[x])\n",
    "############################################################################\n",
    "###### add forthgram to the tokens\n",
    "forthgram = gensim.models.Phrases(tweets_table['text_tokens'], min_count=7, threshold=6, connector_words=gensim.models.phrases.ENGLISH_CONNECTOR_WORDS)\n",
    "forthgram_model = gensim.models.phrases.Phraser(forthgram)\n",
    "if verbose: print(f\"found {len(forthgram_model.phrasegrams)} forthgram\")\n",
    "#forthgram_model.phrasegrams #the trigram that the model found\n",
    "tweets_table['text_tokens'] = tweets_table['text_tokens'].apply(lambda x: forthgram_model[x])\n",
    "############################################################################\n",
    "### add tweet date column\n",
    "def take_only_10_first_char(x):\n",
    "    return(x[0:10])\n",
    "tweets_table[\"created_at_date\"] = tweets_table[\"created_at\"].apply(take_only_10_first_char)\n",
    "tweets_table[\"created_at_date\"] = pd.to_datetime(tweets_table[\"created_at_date\"])\n",
    "\n",
    "tweets_table[\"Year_tweet\"] = pd.DatetimeIndex(tweets_table['created_at']).year\n",
    "\n",
    "### add column is_in_special_date that checks wheter the tweet was published in a special event day\n",
    "#tweets_table['is_in_special_date'] = tweets_table['created_at_date'].apply(lambda x : pd.Series(x).isin(events_table[\"Date\"]).any())\n",
    "\n",
    "# ### Joining the event table so we can get additional information for the special events\n",
    "# tweets_table = tweets_table.merge(events_table, left_on = \"created_at_date\", right_on = \"Date\", how = \"left\")\n",
    "# tweets_table.rename(columns = {'Date':'Event_Date'}, inplace = True)\n",
    "# tweets_table['Event_Date'] = tweets_table['Event_Date'].fillna(\"No-Event\")\n",
    "\n",
    "# ### Joining the KOP table so we can get additional information for the KOP\n",
    "# tweets_table = tweets_table.merge(KOP_table, left_on = \"author_id\", right_on = \"author_id\", how = \"left\")\n",
    "# try:\n",
    "#     tweets_table['KOP_num'] = tweets_table['KOP_num'].fillna(\"No-KOP\")\n",
    "#     tweets_table['Index'] = tweets_table['Index'].fillna(\"No-KOP\")\n",
    "#     tweets_table['Name'] = tweets_table['Name'].fillna(\"No-KOP\")\n",
    "#     tweets_table['Born_in'] = tweets_table['Born_in'].fillna(\"No-KOP\")\n",
    "#     tweets_table['Role'] = tweets_table['Role'].fillna(\"No-KOP\")\n",
    "#     tweets_table['Place'] = tweets_table['Place'].fillna(\"No-KOP\")\n",
    "# except: print()\n",
    "\n",
    "if verbose: print(\"\\nFinish preprocessing the tweets table, it took:\", round(time.time() - start_time,3), \"seconds\")\n",
    "\n",
    "# ############# step 6 - Scoring #############\n",
    "# if verbose: print(\"Step 6: Scoring the Tweets\")\n",
    "\n",
    "# KOP_ids = list(set(KOP_table.author_id))\n",
    "\n",
    "# ### the following scorer - count the number of times the key words apprear in a certain text. If a certain word (brexit)\n",
    "# # appear more than once, it will be counted twice\n",
    "# def scorer_keywords_brexit(tweet_tokens, key_words):\n",
    "#     #scoring the keywords:\n",
    "#     count_key_words = 0\n",
    "#     for word in key_words:\n",
    "#         count_key_words += tweet_tokens.count(word)\n",
    "#     return count_key_words\n",
    "# ##########################################################################################################\n",
    "# def scorer_KOP_brexit(author_id, KOP_ids):\n",
    "#     if author_id in KOP_ids:\n",
    "#         score = 1\n",
    "#     else:\n",
    "#         score = 0\n",
    "#     return score\n",
    "# ##########################################################################################################\n",
    "# ### adding year column\n",
    "# #tweets_table[\"Year_tweet\"] = pd.DatetimeIndex(tweets_table['created_at']).year\n",
    "\n",
    "# ### scoring key-words\n",
    "# tweets_table[\"score_key_words\"] = tweets_table['text_tokens'].apply(scorer_keywords_brexit, key_words = key_words)\n",
    "\n",
    "# #scoring KOP: if the author is KOP then the score in this column will be 1, else 0\n",
    "# tweets_table[\"score_KOP\"] = tweets_table['author_id'].apply(scorer_KOP_brexit, KOP_ids = KOP_ids)\n",
    "\n",
    "# ### scoring events - column is_in_special_date\n",
    "\n",
    "# #tweets_table[\"total_score\"]: adding the weights of each scorer\n",
    "# tweets_table[\"total_score\"] = score_for_key_words*tweets_table['score_key_words'] + score_for_key_event*tweets_table[\"is_in_special_date\"] + score_for_KOP*tweets_table[\"score_KOP\"]\n",
    "\n",
    "# #Geting a table with all the tweets that passed the score threshold\n",
    "# tweets_table_filtered = tweets_table[tweets_table[\"total_score\"]>=threshold_score].copy()\n",
    "# #Sort the filtered table by score such that the tweets with the highest score will be first\n",
    "# tweets_table_filtered.sort_values(by = \"total_score\", ascending=False, inplace=True)\n",
    "\n",
    "print(\"\\nFinish!\\nTotal time:\", round(time.time() - start_fun_time,3),\n",
    "    \"Seconds (\",round((time.time() - start_fun_time)/60,3), \"Minutes)\")\n",
    "\n",
    "bigrams_models = [bigram, trigram, forthgram]\n",
    "#return (tweets_table, csv_files_evaluated, bigrams_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6bebde64",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-17T13:30:08.854627Z",
     "start_time": "2022-06-17T13:30:08.824646Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tweets=977305\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total number of tweets={tweets_table.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0b61ee7c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-17T12:16:36.486214Z",
     "start_time": "2022-06-17T12:16:36.471215Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Martin Flanagan: Market bulls reign amid Trump and Brexit https://t.co/Jc8yuVuYw4 #BREXIT #StrongerIn #No2EU #EUref #LeaveEU #VoteLeave'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example = pd.DataFrame({\"text\" : [\"Martin Flanagan: Market bulls reign amid Trump and Brexit https://t.co/Jc8yuVuYw4 #BREXIT #StrongerIn #No2EU #EUref #LeaveEU #VoteLeave\"]})\n",
    "# example[\"text\"][0]\n",
    "# example[\"text_tokens\"] = example[\"text\"].apply(gensim.utils.simple_preprocess,{\"deacc\":True, \"min_len\":2,\"max_len\":25})\n",
    "# example[\"text_tokens\"][0]\n",
    "# example['text_tokens1'] = example['text_tokens'].apply(remove_stopwords, stopwords=stopwords)\n",
    "# example[\"text_tokens1\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "be06b5af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-17T10:37:57.777903Z",
     "start_time": "2022-06-17T10:37:57.761912Z"
    }
   },
   "outputs": [],
   "source": [
    "# ### inputs for the filter function\n",
    "# import os \n",
    "# dir_with_all_tweets = os.path.join(\"KOL tweets\")\n",
    "\n",
    "# score_for_KOP = 0\n",
    "# score_for_key_event = 5\n",
    "# score_for_key_words = 5\n",
    "\n",
    "# key_words = [\"brexit\", \"eu\", \"deal\", \"economy\"]\n",
    "# threshold_score = 5\n",
    "\n",
    "# KOP_excel_name = \"KOP brexit.xlsx\"\n",
    "# key_events_excel_name = \"Brexit_key_events.xlsx\"\n",
    "# stop_words_to_add = [\"https\", \"rt\"]\n",
    "# #########################################################\n",
    "# tweets_table_filtered, tweets_table, csv_files_evaluated, bigrams_models = my_twitter_crawler.filter_tweets_Brexit(\n",
    "#     dir_with_all_tweets = dir_with_all_tweets,\n",
    "#     score_for_KOP = score_for_KOP,\n",
    "#     score_for_key_event = score_for_key_event,\n",
    "#     score_for_key_words = score_for_key_words,\n",
    "#     key_words = key_words,\n",
    "#     threshold_score = threshold_score,\n",
    "#     KOP_excel_name = KOP_excel_name,\n",
    "#     key_events_excel_name = key_events_excel_name,\n",
    "#     stop_words_to_add = stop_words_to_add,\n",
    "#     stop_words_file_name = \"stopwords.txt\",\n",
    "#     verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9d0ff81",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-16T14:01:42.840074Z",
     "start_time": "2022-06-16T14:01:42.054484Z"
    }
   },
   "outputs": [],
   "source": [
    "# tweets_table[\"Year_tweet\"] = pd.DatetimeIndex(tweets_table['created_at']).year\n",
    "# tweets_table_filtered[\"Year_tweet\"] = pd.DatetimeIndex(tweets_table_filtered['created_at']).year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fdeb29bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-16T14:01:44.102321Z",
     "start_time": "2022-06-16T14:01:44.093322Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tweets of the KOL=435750\n",
      "Total number of filtered tweets of the KOL=409916\n",
      "Total number of remained tweets of the KOL=25834\n"
     ]
    }
   ],
   "source": [
    "# print(f\"Total number of tweets of the KOL={tweets_table.shape[0]}\")\n",
    "# print(f\"Total number of filtered tweets of the KOL={ tweets_table.shape[0] - tweets_table_filtered.shape[0]}\")\n",
    "# print(f\"Total number of remained tweets of the KOL={tweets_table_filtered.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919413a8",
   "metadata": {},
   "source": [
    "### Add basic sentiment using NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2a9e1c34",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-17T13:34:40.101289Z",
     "start_time": "2022-06-17T13:34:32.124817Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\Roy\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4b0cdc7a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-17T13:35:43.111203Z",
     "start_time": "2022-06-17T13:35:43.093213Z"
    }
   },
   "outputs": [],
   "source": [
    "def nltk_sentiment(row, sentiment_intensity_analyzer, column_text_name = \"text\"):\n",
    "    import numpy as np, pandas as pd\n",
    "    sentiment_names = ['negative', 'neutral', 'positive']\n",
    "    nltk_sentiment = sentiment_intensity_analyzer.polarity_scores(row[column_text_name])\n",
    "    \n",
    "    #nltk_sentiment['nltk_verdict'] = sentiment_names[np.argmax([nltk_sentiment[s] for s in ['neg','neu','pos']])]\n",
    "    if nltk_sentiment['neu']>0.95:\n",
    "        nltk_sentiment['nltk_verdict'] = 'neutral'\n",
    "    elif nltk_sentiment['neg'] < nltk_sentiment['pos']:\n",
    "        nltk_sentiment['nltk_verdict'] = 'positive'\n",
    "    else:\n",
    "        nltk_sentiment['nltk_verdict'] = 'negative'\n",
    "    #nltk_sentiment['ground_truth'] = row['airline_sentiment']\n",
    "    #nltk_sentiment['ground_truth_value'] = {'negative': -1, 'neutral':0, 'positive':1 }[nltk_sentiment['ground_truth']]\n",
    "    return pd.Series(nltk_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c489f994",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-17T13:59:06.850765Z",
     "start_time": "2022-06-17T13:36:40.288732Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_24412/4080110914.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0msentiment_intensity_analyzer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSentimentIntensityAnalyzer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mnltk_sentiment_tweets_table\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtweets_table\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnltk_sentiment\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msentiment_intensity_analyzer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msentiment_intensity_analyzer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumn_text_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"text\"\u001b[0m  \u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m##### Adding the sentiment analysis columns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[0;32m   8831\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   8832\u001b[0m         )\n\u001b[1;32m-> 8833\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"apply\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   8834\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   8835\u001b[0m     def applymap(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    729\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    850\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_standard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 851\u001b[1;33m         \u001b[0mresults\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mres_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_series_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    852\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    853\u001b[0m         \u001b[1;31m# wrap results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply_series_generator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    865\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    866\u001b[0m                 \u001b[1;31m# ignore SettingWithCopy here in case the user mutates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 867\u001b[1;33m                 \u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    868\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    869\u001b[0m                     \u001b[1;31m# If we have a view on v, we need to make a copy because\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mf\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m             \u001b[1;32mdef\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 138\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    139\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_24412/1499722055.py\u001b[0m in \u001b[0;36mnltk_sentiment\u001b[1;34m(row, sentiment_intensity_analyzer, column_text_name)\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;31m#nltk_sentiment['ground_truth'] = row['airline_sentiment']\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;31m#nltk_sentiment['ground_truth_value'] = {'negative': -1, 'neutral':0, 'positive':1 }[nltk_sentiment['ground_truth']]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnltk_sentiment\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[0;32m    415\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    416\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mis_dict_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 417\u001b[1;33m                 \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    418\u001b[0m                 \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    419\u001b[0m                 \u001b[0mcopy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m_init_dict\u001b[1;34m(self, data, index, dtype)\u001b[0m\n\u001b[0;32m    504\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    505\u001b[0m         \u001b[1;31m# TODO: passing np.float64 to not break anything yet. See GH-17261\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 506\u001b[1;33m         s = create_series_with_explicit_dtype(\n\u001b[0m\u001b[0;32m    507\u001b[0m             \u001b[1;31m# error: Argument \"index\" to \"create_series_with_explicit_dtype\" has\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    508\u001b[0m             \u001b[1;31m# incompatible type \"Tuple[Any, ...]\"; expected \"Union[ExtensionArray,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\construction.py\u001b[0m in \u001b[0;36mcreate_series_with_explicit_dtype\u001b[1;34m(data, index, dtype, name, copy, fastpath, dtype_if_empty)\u001b[0m\n\u001b[0;32m    854\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mis_empty_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    855\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdtype_if_empty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 856\u001b[1;33m     return Series(\n\u001b[0m\u001b[0;32m    857\u001b[0m         \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfastpath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfastpath\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m     )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[0;32m    449\u001b[0m                     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    450\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 451\u001b[1;33m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msanitize_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    452\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    453\u001b[0m                 \u001b[0mmanager\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_option\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"mode.data_manager\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\construction.py\u001b[0m in \u001b[0;36msanitize_array\u001b[1;34m(data, index, dtype, copy, raise_cast_failure, allow_2d)\u001b[0m\n\u001b[0;32m    591\u001b[0m             \u001b[0msubarr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_try_cast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_cast_failure\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 593\u001b[1;33m             \u001b[0msubarr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmaybe_convert_platform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    594\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0msubarr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m                 \u001b[0msubarr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubarr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\dtypes\\cast.py\u001b[0m in \u001b[0;36mmaybe_convert_platform\u001b[1;34m(values)\u001b[0m\n\u001b[0;32m    128\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_dtype_obj\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m         \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m         \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaybe_convert_objects\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.maybe_convert_objects\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\numeric.py\u001b[0m in \u001b[0;36mfull\u001b[1;34m(shape, fill_value, dtype, order, like)\u001b[0m\n\u001b[0;32m    338\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 340\u001b[1;33m         \u001b[0mfill_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    341\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    342\u001b[0m     \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "sentiment_intensity_analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "nltk_sentiment_tweets_table = tweets_table.apply(nltk_sentiment, sentiment_intensity_analyzer=sentiment_intensity_analyzer, column_text_name = \"text\"  ,axis=1)\n",
    "\n",
    "##### Adding the sentiment analysis columns\n",
    "tweets_table[\"KOL_Tweet_negative\"] = nltk_sentiment_tweets_table.neg\n",
    "tweets_table[\"KOL_Tweet_neutural\"] = nltk_sentiment_tweets_table.neu\n",
    "tweets_table[\"KOL_Tweet_positive\"] = nltk_sentiment_tweets_table.pos\n",
    "tweets_table[\"KOL_Tweet_compound\"] = nltk_sentiment_tweets_table.compound\n",
    "\n",
    "#### This columns contain the final \"verdict\" of the NLTK Model\n",
    "tweets_table[\"KOL_Tweet_nltk_verdict\"] = nltk_sentiment_tweets_table.nltk_verdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "52d0b0c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-16T11:06:47.289892Z",
     "start_time": "2022-06-16T11:06:20.227403Z"
    }
   },
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "# sentiment_intensity_analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# nltk_sentiment_tweets_table_filtered = tweets_table_filtered.apply(nltk_sentiment, sentiment_intensity_analyzer=sentiment_intensity_analyzer, column_text_name = \"text\"  ,axis=1)\n",
    "\n",
    "# ##### Adding the sentiment analysis columns\n",
    "# tweets_table_filtered[\"KOL_Tweet_negative\"] = nltk_sentiment_tweets_table.neg\n",
    "# tweets_table_filtered[\"KOL_Tweet_neutural\"] = nltk_sentiment_tweets_table.neu\n",
    "# tweets_table_filtered[\"KOL_Tweet_positive\"] = nltk_sentiment_tweets_table.pos\n",
    "# tweets_table_filtered[\"KOL_Tweet_compound\"] = nltk_sentiment_tweets_table.compound\n",
    "\n",
    "# #### This columns contain the final \"verdict\" of the NLTK Model\n",
    "# tweets_table_filtered[\"KOL_Tweet_nltk_verdict\"] = nltk_sentiment_tweets_table.nltk_verdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c08f3f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-17T13:59:07.002679Z",
     "start_time": "2022-06-17T13:59:07.002679Z"
    }
   },
   "outputs": [],
   "source": [
    "tweets_table.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000264da",
   "metadata": {},
   "source": [
    "### Writing the filtered table to excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4c3bcb17",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-16T11:18:29.251059Z",
     "start_time": "2022-06-16T11:06:48.817659Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data_folder'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tweets_table.to_excel(os.path.join(data_folder_name, \"tweets_table_all3.xlsx\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "300e1679",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-17T13:33:03.058006Z",
     "start_time": "2022-06-17T13:30:51.614008Z"
    }
   },
   "outputs": [],
   "source": [
    "### write to csv\n",
    "tweets_table.to_csv(os.path.join(data_folder_name, \"tweets_table_all4.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9ce9c613",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-15T13:01:15.714345Z",
     "start_time": "2022-06-15T13:01:12.272462Z"
    }
   },
   "outputs": [],
   "source": [
    "# tweets_table_filtered.to_excel(os.path.join(data_folder_name, \"tweets_table_filtered2.xlsx\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32213021",
   "metadata": {},
   "source": [
    "## Add language classification\n",
    "And filter the non English Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a345672f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "language_classifications = []\n",
    "for row in tqdm_notebook(tweets_table.text): #tqdm_notebook - to pring progress bar\n",
    "    language_classification, score = langid.classify(row)\n",
    "    language_classifications.append(language_classification)\n",
    "\n",
    "\n",
    "tweets_table[\"language\"] = language_classifications\n",
    "tweets_table = tweets_table[tweets_table[\"language\"] == \"en\"]\n",
    "\n",
    "### reset index\n",
    "tweets_table.reset_index(inplace=True)\n",
    "tweets_table[\"index\"] = tweets_table.index\n",
    "\n",
    "print(f\"Total number of tweets of the KOL in English={tweets_table.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039fe4d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3ac155",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99b0db7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48eee7a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c0b1b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6a742649",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-15T15:40:28.294556Z",
     "start_time": "2022-06-15T15:40:27.924762Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>author_id_new</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>users.name</th>\n",
       "      <th>Year_tweet</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Jeremy Vine</th>\n",
       "      <th>2019</th>\n",
       "      <td>19406</td>\n",
       "      <td>19406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ChukaUmunna</th>\n",
       "      <th>2019</th>\n",
       "      <td>8512</td>\n",
       "      <td>8512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sadiq Khan</th>\n",
       "      <th>2019</th>\n",
       "      <td>7318</td>\n",
       "      <td>7318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Jeremy Vine</th>\n",
       "      <th>2018</th>\n",
       "      <td>7171</td>\n",
       "      <td>7171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>7118</td>\n",
       "      <td>7118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rupert Murdoch</th>\n",
       "      <th>2017</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rt. Hon. Michael Heseltine</th>\n",
       "      <th>2015</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Paul Dacre</th>\n",
       "      <th>2016</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Olly Robbins</th>\n",
       "      <th>2018</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>326 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       author_id_new     id\n",
       "users.name                 Year_tweet                      \n",
       "Jeremy Vine                2019                19406  19406\n",
       "ChukaUmunna                2019                 8512   8512\n",
       "Sadiq Khan                 2019                 7318   7318\n",
       "Jeremy Vine                2018                 7171   7171\n",
       "                           2016                 7118   7118\n",
       "...                                              ...    ...\n",
       "Rupert Murdoch             2017                    1      1\n",
       "Rt. Hon. Michael Heseltine 2015                    1      1\n",
       "Paul Dacre                 2016                    1      1\n",
       "                           2014                    1      1\n",
       "Olly Robbins               2018                    1      1\n",
       "\n",
       "[326 rows x 2 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Get the number of tweets per KOL\n",
    "tweets_table[[\"author_id_new\", \"id\", \"users.name\", \"Year_tweet\"]].groupby(by = [\"users.name\", \"Year_tweet\"]).count().sort_values(by = \"id\", ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "49073323",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-15T15:41:13.026964Z",
     "start_time": "2022-06-15T15:41:12.969004Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>author_id_new</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>users.name</th>\n",
       "      <th>Year_tweet</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Charles Grant</th>\n",
       "      <th>2017</th>\n",
       "      <td>869</td>\n",
       "      <td>869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>852</td>\n",
       "      <td>852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Martin Selmayr</th>\n",
       "      <th>2017</th>\n",
       "      <td>776</td>\n",
       "      <td>776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ChukaUmunna</th>\n",
       "      <th>2017</th>\n",
       "      <td>709</td>\n",
       "      <td>709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Charles Grant</th>\n",
       "      <th>2019</th>\n",
       "      <td>684</td>\n",
       "      <td>684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dr Liam Fox MP</th>\n",
       "      <th>2014</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Steve O'Connell</th>\n",
       "      <th>2014</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dyson</th>\n",
       "      <th>2018</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Matteo Renzi</th>\n",
       "      <th>2014</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rupert Murdoch</th>\n",
       "      <th>2017</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>294 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            author_id_new   id\n",
       "users.name      Year_tweet                    \n",
       "Charles Grant   2017                  869  869\n",
       "                2016                  852  852\n",
       "Martin Selmayr  2017                  776  776\n",
       "ChukaUmunna     2017                  709  709\n",
       "Charles Grant   2019                  684  684\n",
       "...                                   ...  ...\n",
       "Dr Liam Fox MP  2014                    1    1\n",
       "Steve O'Connell 2014                    1    1\n",
       "Dyson           2018                    1    1\n",
       "Matteo Renzi    2014                    1    1\n",
       "Rupert Murdoch  2017                    1    1\n",
       "\n",
       "[294 rows x 2 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Get the number of tweets per KOL\n",
    "tweets_table_filtered[[\"author_id_new\", \"id\", \"users.name\", \"Year_tweet\"]].groupby(by = [\"users.name\", \"Year_tweet\"]).count().sort_values(by = \"id\", ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29aeaabf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-16T11:46:54.075896Z",
     "start_time": "2022-06-16T11:46:53.407212Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_id_new</th>\n",
       "      <th>id</th>\n",
       "      <th>users.name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year_tweet</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>127945</td>\n",
       "      <td>127945</td>\n",
       "      <td>127945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>68602</td>\n",
       "      <td>68602</td>\n",
       "      <td>68602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>67645</td>\n",
       "      <td>67645</td>\n",
       "      <td>67645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>61387</td>\n",
       "      <td>61387</td>\n",
       "      <td>61387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>56626</td>\n",
       "      <td>56626</td>\n",
       "      <td>56626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>45455</td>\n",
       "      <td>45455</td>\n",
       "      <td>45455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>8090</td>\n",
       "      <td>8090</td>\n",
       "      <td>8090</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            author_id_new      id  users.name\n",
       "Year_tweet                                   \n",
       "2019               127945  127945      127945\n",
       "2017                68602   68602       68602\n",
       "2016                67645   67645       67645\n",
       "2018                61387   61387       61387\n",
       "2015                56626   56626       56626\n",
       "2014                45455   45455       45455\n",
       "2020                 8090    8090        8090"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_table[[\"author_id_new\", \"id\", \"users.name\", \"Year_tweet\"]].groupby(by = [\"Year_tweet\"]).count().sort_values(by = \"id\", ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e37e25c6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-16T12:33:11.303362Z",
     "start_time": "2022-06-16T12:33:11.275377Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    76650839\n",
       "1    76650839\n",
       "2    76650839\n",
       "3    76650839\n",
       "4    76650839\n",
       "Name: author_id, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_table.head().author_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c3bc0da1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-16T12:33:20.138843Z",
     "start_time": "2022-06-16T12:33:19.551180Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f324899088a74e968e6f6261a51c2697",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76650839\n",
      "76650839\n",
      "76650839\n",
      "76650839\n",
      "76650839\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm_notebook\n",
    "import time\n",
    "for i in tqdm_notebook(tweets_table.head().author_id):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f5eabf8d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-16T12:57:03.834893Z",
     "start_time": "2022-06-16T12:56:54.086460Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6eb52a3297ea40f38ca7afa73f8d7fc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import contractions\n",
    "import langid #for language detection\n",
    "\n",
    "language_classifications = []\n",
    "for row in tqdm_notebook(tweets_table.head().text): #tqdm_notebook - to pring progress bar\n",
    "    language_classification, score = langid.classify(row)\n",
    "    language_classifications.append(language_classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79d0d96c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-16T14:01:45.437555Z",
     "start_time": "2022-06-16T14:01:45.424563Z"
    }
   },
   "outputs": [],
   "source": [
    "### reading the stopwords file / downloading it and add some more stopwords\n",
    "data_folder = \"data_folder\"\n",
    "stopwords_file_name =  os.path.join(data_folder, \"StopWords\")\n",
    "stopwords_url = \"https://gist.githubusercontent.com/sebleier/554280/raw/7e0e4a1ce04c2bb7bd41089c9821dbcf6d0c786c/NLTK's%2520list%2520of%2520english%2520stopwords\"\n",
    "\n",
    "stop_words_to_add = [\"http\", \"https\", \"rt\"] ### add more stopwords you want\n",
    "\n",
    "#################################################################\n",
    "if not os.path.isfile(stopwords_file_name):\n",
    "    StopWords = requests.get(stopwords_url).text.split()\n",
    "    with open(stopwords_file_name,'w+t', encoding='utf-8') as out_file:\n",
    "        out_file.write(' '.join(StopWords))\n",
    "else:\n",
    "    with open(stopwords_file_name,'rt', encoding='utf-8') as in_file:\n",
    "        StopWords = in_file.readline().split()\n",
    "StopWords = set(StopWords)\n",
    "\n",
    "for word_i in stop_words_to_add:\n",
    "    StopWords.add(word_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af1c74ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-16T14:04:11.038356Z",
     "start_time": "2022-06-16T14:01:46.805773Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46865dd698d5442183294227cd1d5b23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25834 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm_notebook\n",
    "import contractions\n",
    "import langid #for language detection\n",
    "\n",
    "language_classifications = []\n",
    "tokens_roy = []\n",
    "years_tweets = []\n",
    "for row in tqdm_notebook(tweets_table_filtered.text): #tqdm_notebook - to pring progress bar\n",
    "    language_classification, score = langid.classify(row)\n",
    "    language_classifications.append(language_classification)\n",
    "\n",
    "    data_clean = row.lower().replace(\"#\", \"\").replace(\"@\", \"\").replace(\"?\", \"\").replace(\"\\\"\", \"\").replace(\"\\'\", \"\").replace(\":\", \"\")\n",
    "    data_clean = data_clean.split()\n",
    "    data_clean = [token for token in data_clean if token not in StopWords]\n",
    "    data_clean = [token for token in data_clean if len(token) >=2]\n",
    "    tokens_roy.append(data_clean)\n",
    "\n",
    "\n",
    "texts = tweets_table_filtered.text\n",
    "text_tokens = tweets_table_filtered.text_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b7cdf9f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-16T14:04:13.359644Z",
     "start_time": "2022-06-16T14:04:13.352647Z"
    }
   },
   "outputs": [],
   "source": [
    "#years_tweets = pd.DatetimeIndex(filtered_table['created_at_date']).year\n",
    "years_tweets = tweets_table_filtered['Year_tweet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d810499f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-16T14:04:15.761144Z",
     "start_time": "2022-06-16T14:04:15.735156Z"
    }
   },
   "outputs": [],
   "source": [
    "years_tweets_2014 = [years_tweets==2014]\n",
    "years_tweets_2014 = np.asarray(years_tweets_2014).reshape(-1,1)\n",
    "\n",
    "years_tweets_2015 = [years_tweets==2015]\n",
    "years_tweets_2015 = np.asarray(years_tweets_2015).reshape(-1,1)\n",
    "\n",
    "years_tweets_2016 = [years_tweets==2016]\n",
    "years_tweets_2016 = np.asarray(years_tweets_2016).reshape(-1,1)\n",
    "\n",
    "years_tweets_2017 = [years_tweets==2017]\n",
    "years_tweets_2017 = np.asarray(years_tweets_2017).reshape(-1,1)\n",
    "\n",
    "years_tweets_2018 = [years_tweets==2018]\n",
    "years_tweets_2018 = np.asarray(years_tweets_2018).reshape(-1,1)\n",
    "\n",
    "years_tweets_2019 = [years_tweets==2019]\n",
    "years_tweets_2019 = np.asarray(years_tweets_2019).reshape(-1,1)\n",
    "\n",
    "years_tweets_2020 = [years_tweets==2020]\n",
    "years_tweets_2020 = np.asarray(years_tweets_2020).reshape(-1,1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed238b61",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-16T14:04:18.745454Z",
     "start_time": "2022-06-16T14:04:18.542571Z"
    }
   },
   "outputs": [],
   "source": [
    "tokens_df = pd.DataFrame(tokens_roy)#[years_tweets_2018]\n",
    "tokens_df_2014 = tokens_df[years_tweets_2014]\n",
    "tokens_df_2015 = tokens_df[years_tweets_2015]\n",
    "tokens_df_2016 = tokens_df[years_tweets_2016]\n",
    "tokens_df_2017 = tokens_df[years_tweets_2017]\n",
    "tokens_df_2018 = tokens_df[years_tweets_2018]\n",
    "tokens_df_2019 = tokens_df[years_tweets_2019]\n",
    "tokens_df_2020 = tokens_df[years_tweets_2020]\n",
    "tokens_df_all = tokens_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8eac4013",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-16T14:04:21.740801Z",
     "start_time": "2022-06-16T14:04:21.725808Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2014: (677, 49)\n",
      "2015: (1844, 49)\n",
      "2016: (5663, 49)\n",
      "2017: (9546, 49)\n",
      "2018: (3734, 49)\n",
      "2019: (4147, 49)\n",
      "2020: (223, 49)\n",
      "All: (25834, 49)\n"
     ]
    }
   ],
   "source": [
    "print(\"2014:\", tokens_df_2014.shape)\n",
    "print(\"2015:\", tokens_df_2015.shape)\n",
    "print(\"2016:\", tokens_df_2016.shape)\n",
    "print(\"2017:\", tokens_df_2017.shape)\n",
    "print(\"2018:\", tokens_df_2018.shape)\n",
    "print(\"2019:\", tokens_df_2019.shape)\n",
    "print(\"2020:\", tokens_df_2020.shape)\n",
    "print(\"All:\", tokens_df_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "962b5fee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-16T13:05:13.485837Z",
     "start_time": "2022-06-16T13:05:13.029009Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['(2/5)',\n",
       "  'eu',\n",
       "  'slow',\n",
       "  'trade',\n",
       "  'deals.',\n",
       "  'took',\n",
       "  'eu',\n",
       "  'years',\n",
       "  'reach',\n",
       "  'deal',\n",
       "  'singapore,',\n",
       "  'usa',\n",
       "  '2.',\n",
       "  'korea',\n",
       "  'deal',\n",
       "  'took',\n",
       "  'eu',\n",
       "  'years,',\n",
       "  'us'],\n",
       " ['deal',\n",
       "  'enormous',\n",
       "  'boost',\n",
       "  'uk',\n",
       "  'economy.',\n",
       "  'always',\n",
       "  'clear',\n",
       "  'leave',\n",
       "  'eu',\n",
       "  'opportunity',\n",
       "  'build',\n",
       "  'close',\n",
       "  'relationships',\n",
       "  'allies',\n",
       "  'like',\n",
       "  'australia.',\n",
       "  'perfect',\n",
       "  'illustration',\n",
       "  'government',\n",
       "  'exactly',\n",
       "  'that.',\n",
       "  'https//t.co/cai4wj8t6w'],\n",
       " ['eu',\n",
       "  'realises',\n",
       "  'overplayed',\n",
       "  'hand',\n",
       "  '&amp;',\n",
       "  'parliament',\n",
       "  'won’t',\n",
       "  'wear',\n",
       "  'shameful',\n",
       "  'surrender,',\n",
       "  'faced',\n",
       "  'choice',\n",
       "  'proper',\n",
       "  '&amp;',\n",
       "  'equitable',\n",
       "  'deal',\n",
       "  'split',\n",
       "  'without',\n",
       "  'deal',\n",
       "  'prospect',\n",
       "  'don’t',\n",
       "  'relish,',\n",
       "  'least',\n",
       "  'lose',\n",
       "  'leverage',\n",
       "  'us',\n",
       "  '4/4'],\n",
       " ['eucyprus',\n",
       "  'eu',\n",
       "  'turns',\n",
       "  '60',\n",
       "  'today,',\n",
       "  '60',\n",
       "  'good',\n",
       "  'reasons',\n",
       "  'eu!',\n",
       "  '🇪🇺',\n",
       "  'take',\n",
       "  'look',\n",
       "  'album',\n",
       "  'https//t.co/lsdhtututt.',\n",
       "  'eu…'],\n",
       " ['instead',\n",
       "  'brexit',\n",
       "  'everyone,',\n",
       "  'leaving',\n",
       "  'single',\n",
       "  'market',\n",
       "  'could',\n",
       "  'mean',\n",
       "  'deal',\n",
       "  'tax',\n",
       "  'dodgers,',\n",
       "  'hedge',\n",
       "  'funds',\n",
       "  '&amp;',\n",
       "  'vulture',\n",
       "  'companies',\n",
       "  'eyeing',\n",
       "  'nhs'],\n",
       " ['markreckless',\n",
       "  'eu',\n",
       "  'yes.',\n",
       "  'support',\n",
       "  'deal',\n",
       "  'nz',\n",
       "  'would',\n",
       "  'allow',\n",
       "  'unlimited',\n",
       "  'lamb',\n",
       "  'imports',\n",
       "  'one',\n",
       "  'undermines',\n",
       "  'steel'],\n",
       " ['launch',\n",
       "  'cer_london',\n",
       "  'report',\n",
       "  'brexit,',\n",
       "  'martinwolf_',\n",
       "  'says',\n",
       "  'uk',\n",
       "  'much',\n",
       "  'influence',\n",
       "  'eu',\n",
       "  'scotland',\n",
       "  'wd',\n",
       "  'leave',\n",
       "  'uk',\n",
       "  'outside',\n",
       "  'eu.'],\n",
       " ['refusing',\n",
       "  'bring',\n",
       "  'deal',\n",
       "  'back',\n",
       "  'parliament',\n",
       "  'continuing',\n",
       "  'threaten',\n",
       "  'country',\n",
       "  'damage',\n",
       "  'deal',\n",
       "  'brexit',\n",
       "  'utterly',\n",
       "  'irresponsible.',\n",
       "  'wednesday',\n",
       "  'parliament',\n",
       "  'needs',\n",
       "  'vote',\n",
       "  'safeguard',\n",
       "  'prevent',\n",
       "  'us',\n",
       "  'leaving',\n",
       "  'eu',\n",
       "  'deal',\n",
       "  '29',\n",
       "  'march.',\n",
       "  'https//t.co/qvrptazcyp'],\n",
       " ['gloriadepiero',\n",
       "  'i’ve',\n",
       "  'long',\n",
       "  'argued',\n",
       "  'cross',\n",
       "  'party',\n",
       "  'compromise',\n",
       "  'brexit.',\n",
       "  'fiercely',\n",
       "  'deal',\n",
       "  'look',\n",
       "  'deal',\n",
       "  'seriousl…'],\n",
       " ['campbellclaret',\n",
       "  'facts',\n",
       "  'intrude',\n",
       "  'lalaland',\n",
       "  'brexit',\n",
       "  'fantasies.',\n",
       "  '‘brexit’',\n",
       "  'make',\n",
       "  'britain’s',\n",
       "  'mediocre',\n",
       "  'economy',\n",
       "  'worse',\n",
       "  'http…'],\n",
       " ['stefaanderynck',\n",
       "  'set',\n",
       "  'slides',\n",
       "  'ended',\n",
       "  'friday',\n",
       "  'busy',\n",
       "  'week',\n",
       "  'eu27',\n",
       "  'working',\n",
       "  'party',\n",
       "  'brexit.',\n",
       "  'slides',\n",
       "  'deal',\n",
       "  'acti…'],\n",
       " ['gekylafas',\n",
       "  '[boris]',\n",
       "  'johnson',\n",
       "  '&amp;',\n",
       "  'brexit',\n",
       "  'proponents',\n",
       "  'campaigning',\n",
       "  'caricature',\n",
       "  'eu',\n",
       "  'helped',\n",
       "  'create',\n",
       "  'https/…'],\n",
       " ['uk',\n",
       "  'wont',\n",
       "  'ever',\n",
       "  'leave',\n",
       "  'eu',\n",
       "  'without',\n",
       "  'deal...',\n",
       "  'wont',\n",
       "  'deal',\n",
       "  'commons',\n",
       "  'votes',\n",
       "  'deal',\n",
       "  'eu...',\n",
       "  'eu',\n",
       "  'wont',\n",
       "  'adjust',\n",
       "  '(unacceptable)',\n",
       "  'deal',\n",
       "  'theyve',\n",
       "  'already',\n",
       "  'sent',\n",
       "  'us...',\n",
       "  'uk',\n",
       "  'wont',\n",
       "  'ever',\n",
       "  'leave',\n",
       "  'eu.',\n",
       "  'logic',\n",
       "  'last',\n",
       "  'night.'],\n",
       " ['robertvanderoer',\n",
       "  'cer_grant',\n",
       "  'explains',\n",
       "  'eu',\n",
       "  'bbc',\n",
       "  'anchor.',\n",
       "  'one',\n",
       "  'exiting',\n",
       "  'country',\n",
       "  'cannot',\n",
       "  'dictate',\n",
       "  '27',\n",
       "  'eu',\n",
       "  'countries.',\n",
       "  'uk',\n",
       "  'unilateralism',\n",
       "  'vs',\n",
       "  'eu',\n",
       "  'multi…'],\n",
       " ['refusing',\n",
       "  'bring',\n",
       "  'deal',\n",
       "  'back',\n",
       "  'parliament',\n",
       "  'continuing',\n",
       "  'threaten',\n",
       "  'country',\n",
       "  'damage',\n",
       "  'deal',\n",
       "  'brexit',\n",
       "  'utterly',\n",
       "  'irresponsible.',\n",
       "  'wednesday',\n",
       "  'parliament',\n",
       "  'needs',\n",
       "  'vote',\n",
       "  'safeguard',\n",
       "  'prevent',\n",
       "  'us',\n",
       "  'leaving',\n",
       "  'eu',\n",
       "  'deal',\n",
       "  '29',\n",
       "  'march.',\n",
       "  'https//t.co/qvrptazcyp'],\n",
       " ['uk',\n",
       "  'wont',\n",
       "  'ever',\n",
       "  'leave',\n",
       "  'eu',\n",
       "  'without',\n",
       "  'deal...',\n",
       "  'wont',\n",
       "  'deal',\n",
       "  'commons',\n",
       "  'votes',\n",
       "  'deal',\n",
       "  'eu...',\n",
       "  'eu',\n",
       "  'wont',\n",
       "  'adjust',\n",
       "  '(unacceptable)',\n",
       "  'deal',\n",
       "  'theyve',\n",
       "  'already',\n",
       "  'sent',\n",
       "  'us...',\n",
       "  'uk',\n",
       "  'wont',\n",
       "  'ever',\n",
       "  'leave',\n",
       "  'eu.',\n",
       "  'logic',\n",
       "  'last',\n",
       "  'night.'],\n",
       " ['gloriadepiero',\n",
       "  'i’ve',\n",
       "  'long',\n",
       "  'argued',\n",
       "  'cross',\n",
       "  'party',\n",
       "  'compromise',\n",
       "  'brexit.',\n",
       "  'fiercely',\n",
       "  'deal',\n",
       "  'look',\n",
       "  'deal',\n",
       "  'seriousl…'],\n",
       " ['paladinoeu',\n",
       "  'brexit',\n",
       "  'brexit',\n",
       "  'johnspringford',\n",
       "  'cer_grant',\n",
       "  'list',\n",
       "  '10',\n",
       "  'compromises',\n",
       "  'may',\n",
       "  'never',\n",
       "  'talked',\n",
       "  'ecj',\n",
       "  'eubudget',\n",
       "  'etc',\n",
       "  'https…'],\n",
       " ['walking',\n",
       "  'government',\n",
       "  'won’t',\n",
       "  'make',\n",
       "  'brexit',\n",
       "  'go',\n",
       "  'away,',\n",
       "  'optimist',\n",
       "  'nature,',\n",
       "  'hope',\n",
       "  'creates',\n",
       "  'unity',\n",
       "  'needed',\n",
       "  'find',\n",
       "  'parliamentary',\n",
       "  'majority',\n",
       "  'agreement',\n",
       "  'works.',\n",
       "  'brexit',\n",
       "  'brexitshambles'],\n",
       " ['coyleneil',\n",
       "  'watch',\n",
       "  'eu',\n",
       "  'titan',\n",
       "  'sebdance',\n",
       "  'voteneilcoyle',\n",
       "  'today',\n",
       "  'strong',\n",
       "  'eu',\n",
       "  'voice',\n",
       "  'https//t.co/mtrwchqjzm'],\n",
       " ['demand',\n",
       "  'people’s',\n",
       "  'vote',\n",
       "  'final',\n",
       "  'brexit',\n",
       "  'deal',\n",
       "  'grow.',\n",
       "  'new',\n",
       "  'facts',\n",
       "  'consequences',\n",
       "  'leaving',\n",
       "  'eu',\n",
       "  'coming',\n",
       "  'light',\n",
       "  'every',\n",
       "  'day,',\n",
       "  'clearer',\n",
       "  'ever',\n",
       "  'brexit',\n",
       "  'big',\n",
       "  'deal,',\n",
       "  'done',\n",
       "  'deal.',\n",
       "  '(4)'],\n",
       " ['mina_andreeva',\n",
       "  '.michelbarnier',\n",
       "  'daviddavismp',\n",
       "  'brexit',\n",
       "  'taxpayers',\n",
       "  'eu27',\n",
       "  'pay',\n",
       "  'obligations',\n",
       "  'taken',\n",
       "  'eu28,',\n",
       "  'including'],\n",
       " ['sensible',\n",
       "  'piece',\n",
       "  'brexit',\n",
       "  'nickjtimothy',\n",
       "  'uk',\n",
       "  'pay',\n",
       "  'get',\n",
       "  'trade',\n",
       "  'deal,',\n",
       "  'give',\n",
       "  'eu',\n",
       "  'citz',\n",
       "  'preferential',\n",
       "  'access',\n",
       "  'https//t.co/gppzfbbeup'],\n",
       " ['eu_commission',\n",
       "  'futureofeurope',\n",
       "  'rome',\n",
       "  'summit',\n",
       "  'birth',\n",
       "  'moment',\n",
       "  'eu',\n",
       "  '27.',\n",
       "  '25',\n",
       "  'march',\n",
       "  '2017',\n",
       "  'eu60',\n",
       "  'eu27',\n",
       "  'junckereu',\n",
       "  'ht…'],\n",
       " ['euroguido',\n",
       "  'corbyn',\n",
       "  'travelling',\n",
       "  'brussels',\n",
       "  'tell',\n",
       "  'eu',\n",
       "  'britain',\n",
       "  'accepting',\n",
       "  'deal',\n",
       "  'give',\n",
       "  'us.',\n",
       "  'cheers',\n",
       "  'jez.'],\n",
       " ['mr.',\n",
       "  'cameron,',\n",
       "  'eu',\n",
       "  'fanatic,',\n",
       "  'always',\n",
       "  'going',\n",
       "  'campaign',\n",
       "  'stay',\n",
       "  'eu.',\n",
       "  'so-called',\n",
       "  'deal',\n",
       "  'con',\n",
       "  'job.',\n",
       "  'https//t.co/8n3r7ucfcm'],\n",
       " ['het',\n",
       "  'geen',\n",
       "  'geheim',\n",
       "  'dat',\n",
       "  'ik',\n",
       "  'het',\n",
       "  'britse',\n",
       "  'vertrek',\n",
       "  'uit',\n",
       "  'eu',\n",
       "  'zeer',\n",
       "  'betreur.',\n",
       "  'nl',\n",
       "  'wordt',\n",
       "  'daardoor',\n",
       "  'elk',\n",
       "  'scenario',\n",
       "  'getroffen,',\n",
       "  'maar',\n",
       "  'die',\n",
       "  'gevolgen',\n",
       "  'zijn',\n",
       "  'een',\n",
       "  'no-deal',\n",
       "  'scenario',\n",
       "  'veel',\n",
       "  'ernstiger',\n",
       "  'dan',\n",
       "  'bij',\n",
       "  'een',\n",
       "  'terugtrekkingsakkoord.',\n",
       "  'de',\n",
       "  'deal',\n",
       "  'die',\n",
       "  'er',\n",
       "  'nu',\n",
       "  'ligt',\n",
       "  'het',\n",
       "  'maximaal',\n",
       "  'haalbare.',\n",
       "  'brexit'],\n",
       " ['pm',\n",
       "  'made',\n",
       "  'strong',\n",
       "  'case',\n",
       "  'remain.',\n",
       "  'observer',\n",
       "  'piece',\n",
       "  'argues',\n",
       "  'deal',\n",
       "  'tilts',\n",
       "  'balance',\n",
       "  'firmly',\n",
       "  'favour',\n",
       "  'staying',\n",
       "  'eu',\n",
       "  'https//t.co/piewvr2j5t'],\n",
       " ['ludicrous',\n",
       "  'suggest',\n",
       "  'trade',\n",
       "  'deficit',\n",
       "  'eu',\n",
       "  'pm',\n",
       "  'seems',\n",
       "  'suggest',\n",
       "  'brexit'],\n",
       " ['say',\n",
       "  'though',\n",
       "  'election',\n",
       "  'isnt',\n",
       "  'national',\n",
       "  'interest.',\n",
       "  'focus',\n",
       "  'brexit',\n",
       "  'economy',\n",
       "  'opinion',\n",
       "  'polls'],\n",
       " ['overwhelming',\n",
       "  'majority',\n",
       "  'leaders',\n",
       "  'financial',\n",
       "  'services',\n",
       "  'believe',\n",
       "  'london',\n",
       "  'remain',\n",
       "  'europe’s',\n",
       "  'top',\n",
       "  'hub',\n",
       "  'brexit.',\n",
       "  'lloyds',\n",
       "  'survey',\n",
       "  'boost',\n",
       "  'confidence',\n",
       "  'economy,',\n",
       "  'britain’s',\n",
       "  'post-brexit',\n",
       "  'prospects.',\n",
       "  'https//t.co/qngntb1scg'],\n",
       " ['dlf',\n",
       "  'die',\n",
       "  'eu,',\n",
       "  'die',\n",
       "  'briten',\n",
       "  'und',\n",
       "  'der',\n",
       "  'brexit',\n",
       "  'dazu',\n",
       "  'jetzt',\n",
       "  'im',\n",
       "  'dlf',\n",
       "  'der',\n",
       "  'präsident',\n",
       "  'des',\n",
       "  'europaparlaments,',\n",
       "  'martinschulz',\n",
       "  'https//t.co/x2kg4rkvlk'],\n",
       " ['dcd128',\n",
       "  'montie',\n",
       "  'timesredbox',\n",
       "  'bias',\n",
       "  'british',\n",
       "  'media',\n",
       "  'misreports',\n",
       "  'eu',\n",
       "  'https//t.co/0lycnt7s8m'],\n",
       " ['cer_ianbond',\n",
       "  'exception',\n",
       "  '(so',\n",
       "  'far)',\n",
       "  'camerons',\n",
       "  'resignation,',\n",
       "  'cer_grant',\n",
       "  'unfortunately',\n",
       "  'spot',\n",
       "  'crystal',\n",
       "  'ball.',\n",
       "  'brexit',\n",
       "  'https//…'],\n",
       " ['today',\n",
       "  'celebrate',\n",
       "  'eu',\n",
       "  'day',\n",
       "  'homo/',\n",
       "  'transphobia',\n",
       "  'idaho.',\n",
       "  'much',\n",
       "  'love.',\n",
       "  'special',\n",
       "  'thoughts',\n",
       "  'lgbt',\n",
       "  'people',\n",
       "  'chechnya'],\n",
       " ['joannasopinska',\n",
       "  'thousands',\n",
       "  'poles',\n",
       "  'show',\n",
       "  'today',\n",
       "  'much',\n",
       "  'care',\n",
       "  'eu',\n",
       "  '🇪🇺😎🇵🇱❤eu60',\n",
       "  'kochamcieeuropo',\n",
       "  'loveeu',\n",
       "  'https//t.co/npuf4wn1…'],\n",
       " ['agatagostynska',\n",
       "  'puzzled',\n",
       "  'happened',\n",
       "  'cer_grant',\n",
       "  'walks',\n",
       "  'campaign',\n",
       "  'https//t.co/1giktpjmme',\n",
       "  'brexit'],\n",
       " ['eu_commission',\n",
       "  'brexit',\n",
       "  'everything',\n",
       "  'prepared',\n",
       "  'last',\n",
       "  'detail.',\n",
       "  'margschinas',\n",
       "  'next',\n",
       "  'steps',\n",
       "  'notification',\n",
       "  'of…'],\n",
       " ['eu',\n",
       "  'relaxed',\n",
       "  'rules',\n",
       "  'origin',\n",
       "  'jordan',\n",
       "  'facilitate',\n",
       "  'export',\n",
       "  'eu.',\n",
       "  'create',\n",
       "  'jobs',\n",
       "  'syrian',\n",
       "  'refugees',\n",
       "  'jordanians',\n",
       "  'jordan🇯🇴🇪🇺'],\n",
       " ['peterjavorcik',\n",
       "  'important',\n",
       "  'times.',\n",
       "  'important',\n",
       "  'week.',\n",
       "  'important',\n",
       "  'meeting.',\n",
       "  'romesummit',\n",
       "  'preps',\n",
       "  'earlier',\n",
       "  'today.',\n",
       "  'eu60',\n",
       "  'https//t.co/6outk2rhyl'],\n",
       " ['eu_commission',\n",
       "  'brexit',\n",
       "  'notre',\n",
       "  'objectif',\n",
       "  'est',\n",
       "  'daboutir',\n",
       "  'un',\n",
       "  'accord.',\n",
       "  'nous',\n",
       "  'voulons',\n",
       "  'aboutir',\n",
       "  'un',\n",
       "  'accord',\n",
       "  'avec',\n",
       "  'le',\n",
       "  'royaume-uni,',\n",
       "  'pas',\n",
       "  'contre',\n",
       "  'le…'],\n",
       " ['guyverhofstadt',\n",
       "  'effect',\n",
       "  'trump',\n",
       "  '&amp;',\n",
       "  'brexit',\n",
       "  'europeans',\n",
       "  'rejecting',\n",
       "  'right',\n",
       "  'wing',\n",
       "  'populist',\n",
       "  'parties.',\n",
       "  'eufightback',\n",
       "  'https//t.co/mg8j26jh…'],\n",
       " ['nathalieloiseau',\n",
       "  'michelbarnier',\n",
       "  'aujourdhui',\n",
       "  'lena_fr',\n",
       "  'pour',\n",
       "  'parler',\n",
       "  'brexit.',\n",
       "  'clair,',\n",
       "  'engagé,',\n",
       "  'précis,',\n",
       "  'généreux',\n",
       "  'dans',\n",
       "  'ses',\n",
       "  'explications',\n",
       "  'un…'],\n",
       " ['brexit.',\n",
       "  'today',\n",
       "  'gva,',\n",
       "  'underlining',\n",
       "  'eu',\n",
       "  'continuity',\n",
       "  'wto',\n",
       "  '&amp;',\n",
       "  'leadership',\n",
       "  'supporting',\n",
       "  'multilateral',\n",
       "  'trading',\n",
       "  'system.',\n",
       "  'https//t.co/rk7kxsqjuq'],\n",
       " ['andrew_lilico',\n",
       "  'kill',\n",
       "  'notion',\n",
       "  'men',\n",
       "  '&amp;',\n",
       "  'women',\n",
       "  'think',\n",
       "  'differently',\n",
       "  'eu.',\n",
       "  'https//t.co/imqcnopo7y'],\n",
       " ['good',\n",
       "  'work',\n",
       "  'churchill,',\n",
       "  'helping',\n",
       "  'invent',\n",
       "  'eu,',\n",
       "  'thatcher,',\n",
       "  'giving',\n",
       "  'single',\n",
       "  'market',\n",
       "  'cer_london',\n",
       "  'https//t.co/kkxvnsfeck'],\n",
       " ['bulc_eu',\n",
       "  'thank',\n",
       "  'dear',\n",
       "  'colleagues',\n",
       "  'joint',\n",
       "  'efforts',\n",
       "  'raise',\n",
       "  'awareness',\n",
       "  'roadsafety.',\n",
       "  'lives',\n",
       "  'must',\n",
       "  'saved',\n",
       "  'eu',\n",
       "  'roads.',\n",
       "  'htt…'],\n",
       " ['lsebrexitvote',\n",
       "  'cornwall',\n",
       "  'demands',\n",
       "  'government',\n",
       "  'replaces',\n",
       "  'eu',\n",
       "  'millions',\n",
       "  '(after',\n",
       "  'voting',\n",
       "  'leave)',\n",
       "  'eurefresults',\n",
       "  'brexit',\n",
       "  'https//t.co/qs7upx9o0p',\n",
       "  'via…'],\n",
       " ['brexit',\n",
       "  'team',\n",
       "  'ready.',\n",
       "  'work',\n",
       "  'eu27',\n",
       "  'member',\n",
       "  'states,',\n",
       "  'eu',\n",
       "  'institutions',\n",
       "  '&amp;',\n",
       "  'citizens;',\n",
       "  'together"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<b>limit_output extension: Maximum message size of 10000 exceeded with 210380 characters</b>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokens_roy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "89148d33",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-16T13:05:29.845805Z",
     "start_time": "2022-06-16T13:05:29.831813Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['launch', 'cer_london', 'report', ..., None, None, None],\n",
       "       ['griechenland', 'hat', 'eu-vorsitz,', ..., None, None, None],\n",
       "       ['eu', 'started', 'discussing', ..., None, None, None],\n",
       "       ...,\n",
       "       ['doorstep', 'deal', 'excellent', ..., None, None, None],\n",
       "       ['case', 'giving', 'power', ..., None, None, None],\n",
       "       ['jesstud', 'labour', 'devolve', ..., None, None, None]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d90ccfba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-16T14:04:25.518553Z",
     "start_time": "2022-06-16T14:04:25.509557Z"
    }
   },
   "outputs": [],
   "source": [
    "vector_size = 300\n",
    "window = 7\n",
    "min_count = 2                           \n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9d495b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.asarray(tokens_df_2014)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ededa3aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-16T13:04:29.694283Z",
     "start_time": "2022-06-16T13:04:29.589343Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>launch</td>\n",
       "      <td>cer_london</td>\n",
       "      <td>report</td>\n",
       "      <td>brexit,</td>\n",
       "      <td>martinwolf_</td>\n",
       "      <td>says</td>\n",
       "      <td>uk</td>\n",
       "      <td>much</td>\n",
       "      <td>influence</td>\n",
       "      <td>eu</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>griechenland</td>\n",
       "      <td>hat</td>\n",
       "      <td>eu-vorsitz,</td>\n",
       "      <td>lettland</td>\n",
       "      <td>den</td>\n",
       "      <td>€.</td>\n",
       "      <td>bürger</td>\n",
       "      <td>werden</td>\n",
       "      <td>über</td>\n",
       "      <td>eu-fragen</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>eu</td>\n",
       "      <td>started</td>\n",
       "      <td>discussing</td>\n",
       "      <td>longer</td>\n",
       "      <td>term;</td>\n",
       "      <td>need</td>\n",
       "      <td>reduce</td>\n",
       "      <td>eu</td>\n",
       "      <td>dependence</td>\n",
       "      <td>russian</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>matthewparris3</td>\n",
       "      <td>explains</td>\n",
       "      <td>thetimes</td>\n",
       "      <td>18th</td>\n",
       "      <td>jan</td>\n",
       "      <td>extreme</td>\n",
       "      <td>tory</td>\n",
       "      <td>eu-phobes</td>\n",
       "      <td>behind</td>\n",
       "      <td>letter</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>boris</td>\n",
       "      <td>bloomberg</td>\n",
       "      <td>speech</td>\n",
       "      <td>good.</td>\n",
       "      <td>half</td>\n",
       "      <td>uk</td>\n",
       "      <td>laws</td>\n",
       "      <td>eu</td>\n",
       "      <td>dutch</td>\n",
       "      <td>cutting</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25341</th>\n",
       "      <td>instead</td>\n",
       "      <td>puting</td>\n",
       "      <td>culture</td>\n",
       "      <td>no-go</td>\n",
       "      <td>area</td>\n",
       "      <td>eu</td>\n",
       "      <td>subsidiarity,</td>\n",
       "      <td>need</td>\n",
       "      <td>make</td>\n",
       "      <td>investement</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25342</th>\n",
       "      <td>assesment</td>\n",
       "      <td>last</td>\n",
       "      <td>years.</td>\n",
       "      <td>failing</td>\n",
       "      <td>banking</td>\n",
       "      <td>union</td>\n",
       "      <td>foreign</td>\n",
       "      <td>policy.</td>\n",
       "      <td>ep2014</td>\n",
       "      <td>eu</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25449</th>\n",
       "      <td>doorstep</td>\n",
       "      <td>deal</td>\n",
       "      <td>excellent</td>\n",
       "      <td>candidate</td>\n",
       "      <td>clairhawkins,</td>\n",
       "      <td>gwynn</td>\n",
       "      <td>prosser</td>\n",
       "      <td>(former</td>\n",
       "      <td>mp),</td>\n",
       "      <td>team</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25450</th>\n",
       "      <td>case</td>\n",
       "      <td>giving</td>\n",
       "      <td>power</td>\n",
       "      <td>back</td>\n",
       "      <td>local</td>\n",
       "      <td>communities.</td>\n",
       "      <td>labours</td>\n",
       "      <td>radical</td>\n",
       "      <td>plans</td>\n",
       "      <td>new</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25451</th>\n",
       "      <td>jesstud</td>\n",
       "      <td>labour</td>\n",
       "      <td>devolve</td>\n",
       "      <td>power</td>\n",
       "      <td>across</td>\n",
       "      <td>england</td>\n",
       "      <td>innovationtaskforce</td>\n",
       "      <td>set</td>\n",
       "      <td>blueprint</td>\n",
       "      <td>new</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>677 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0           1            2          3              4   \\\n",
       "6              launch  cer_london       report    brexit,    martinwolf_   \n",
       "57       griechenland         hat  eu-vorsitz,   lettland            den   \n",
       "94                 eu     started   discussing     longer          term;   \n",
       "204    matthewparris3    explains     thetimes       18th            jan   \n",
       "207             boris   bloomberg       speech      good.           half   \n",
       "...               ...         ...          ...        ...            ...   \n",
       "25341         instead      puting      culture      no-go           area   \n",
       "25342       assesment        last       years.    failing        banking   \n",
       "25449        doorstep        deal    excellent  candidate  clairhawkins,   \n",
       "25450            case      giving        power       back          local   \n",
       "25451         jesstud      labour      devolve      power         across   \n",
       "\n",
       "                 5                    6          7           8            9   \\\n",
       "6              says                   uk       much   influence           eu   \n",
       "57               €.               bürger     werden        über    eu-fragen   \n",
       "94             need               reduce         eu  dependence      russian   \n",
       "204         extreme                 tory  eu-phobes      behind       letter   \n",
       "207              uk                 laws         eu       dutch      cutting   \n",
       "...             ...                  ...        ...         ...          ...   \n",
       "25341            eu        subsidiarity,       need        make  investement   \n",
       "25342         union              foreign    policy.      ep2014           eu   \n",
       "25449         gwynn              prosser    (former        mp),         team   \n",
       "25450  communities.              labours    radical       plans          new   \n",
       "25451       england  innovationtaskforce        set   blueprint          new   \n",
       "\n",
       "       ...    39    40    41    42    43    44    45    46    47    48  \n",
       "6      ...  None  None  None  None  None  None  None  None  None  None  \n",
       "57     ...  None  None  None  None  None  None  None  None  None  None  \n",
       "94     ...  None  None  None  None  None  None  None  None  None  None  \n",
       "204    ...  None  None  None  None  None  None  None  None  None  None  \n",
       "207    ...  None  None  None  None  None  None  None  None  None  None  \n",
       "...    ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "25341  ...  None  None  None  None  None  None  None  None  None  None  \n",
       "25342  ...  None  None  None  None  None  None  None  None  None  None  \n",
       "25449  ...  None  None  None  None  None  None  None  None  None  None  \n",
       "25450  ...  None  None  None  None  None  None  None  None  None  None  \n",
       "25451  ...  None  None  None  None  None  None  None  None  None  None  \n",
       "\n",
       "[677 rows x 49 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_df_2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "094cf6ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-16T14:11:09.380357Z",
     "start_time": "2022-06-16T14:11:09.355370Z"
    }
   },
   "outputs": [],
   "source": [
    "tokens_df_2014_new = []\n",
    "for list_i in tokens_df_2014.values.tolist():\n",
    "    list_i_new = []\n",
    "    for i in list_i:\n",
    "        if i != None:\n",
    "            list_i_new.append(i)\n",
    "\n",
    "    tokens_df_2014_new.append(list_i_new)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "df3acc71",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-16T13:51:07.476568Z",
     "start_time": "2022-06-16T13:51:06.962842Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['(2/5)',\n",
       "  'eu',\n",
       "  'slow',\n",
       "  'trade',\n",
       "  'deals.',\n",
       "  'took',\n",
       "  'eu',\n",
       "  'years',\n",
       "  'reach',\n",
       "  'deal',\n",
       "  'singapore,',\n",
       "  'usa',\n",
       "  '2.',\n",
       "  'korea',\n",
       "  'deal',\n",
       "  'took',\n",
       "  'eu',\n",
       "  'years,',\n",
       "  'us'],\n",
       " ['deal',\n",
       "  'enormous',\n",
       "  'boost',\n",
       "  'uk',\n",
       "  'economy.',\n",
       "  'always',\n",
       "  'clear',\n",
       "  'leave',\n",
       "  'eu',\n",
       "  'opportunity',\n",
       "  'build',\n",
       "  'close',\n",
       "  'relationships',\n",
       "  'allies',\n",
       "  'like',\n",
       "  'australia.',\n",
       "  'perfect',\n",
       "  'illustration',\n",
       "  'government',\n",
       "  'exactly',\n",
       "  'that.',\n",
       "  'https//t.co/cai4wj8t6w'],\n",
       " ['eu',\n",
       "  'realises',\n",
       "  'overplayed',\n",
       "  'hand',\n",
       "  '&amp;',\n",
       "  'parliament',\n",
       "  'won’t',\n",
       "  'wear',\n",
       "  'shameful',\n",
       "  'surrender,',\n",
       "  'faced',\n",
       "  'choice',\n",
       "  'proper',\n",
       "  '&amp;',\n",
       "  'equitable',\n",
       "  'deal',\n",
       "  'split',\n",
       "  'without',\n",
       "  'deal',\n",
       "  'prospect',\n",
       "  'don’t',\n",
       "  'relish,',\n",
       "  'least',\n",
       "  'lose',\n",
       "  'leverage',\n",
       "  'us',\n",
       "  '4/4'],\n",
       " ['eucyprus',\n",
       "  'eu',\n",
       "  'turns',\n",
       "  '60',\n",
       "  'today,',\n",
       "  '60',\n",
       "  'good',\n",
       "  'reasons',\n",
       "  'eu!',\n",
       "  '🇪🇺',\n",
       "  'take',\n",
       "  'look',\n",
       "  'album',\n",
       "  'https//t.co/lsdhtututt.',\n",
       "  'eu…'],\n",
       " ['instead',\n",
       "  'brexit',\n",
       "  'everyone,',\n",
       "  'leaving',\n",
       "  'single',\n",
       "  'market',\n",
       "  'could',\n",
       "  'mean',\n",
       "  'deal',\n",
       "  'tax',\n",
       "  'dodgers,',\n",
       "  'hedge',\n",
       "  'funds',\n",
       "  '&amp;',\n",
       "  'vulture',\n",
       "  'companies',\n",
       "  'eyeing',\n",
       "  'nhs'],\n",
       " ['markreckless',\n",
       "  'eu',\n",
       "  'yes.',\n",
       "  'support',\n",
       "  'deal',\n",
       "  'nz',\n",
       "  'would',\n",
       "  'allow',\n",
       "  'unlimited',\n",
       "  'lamb',\n",
       "  'imports',\n",
       "  'one',\n",
       "  'undermines',\n",
       "  'steel'],\n",
       " ['launch',\n",
       "  'cer_london',\n",
       "  'report',\n",
       "  'brexit,',\n",
       "  'martinwolf_',\n",
       "  'says',\n",
       "  'uk',\n",
       "  'much',\n",
       "  'influence',\n",
       "  'eu',\n",
       "  'scotland',\n",
       "  'wd',\n",
       "  'leave',\n",
       "  'uk',\n",
       "  'outside',\n",
       "  'eu.'],\n",
       " ['refusing',\n",
       "  'bring',\n",
       "  'deal',\n",
       "  'back',\n",
       "  'parliament',\n",
       "  'continuing',\n",
       "  'threaten',\n",
       "  'country',\n",
       "  'damage',\n",
       "  'deal',\n",
       "  'brexit',\n",
       "  'utterly',\n",
       "  'irresponsible.',\n",
       "  'wednesday',\n",
       "  'parliament',\n",
       "  'needs',\n",
       "  'vote',\n",
       "  'safeguard',\n",
       "  'prevent',\n",
       "  'us',\n",
       "  'leaving',\n",
       "  'eu',\n",
       "  'deal',\n",
       "  '29',\n",
       "  'march.',\n",
       "  'https//t.co/qvrptazcyp'],\n",
       " ['gloriadepiero',\n",
       "  'i’ve',\n",
       "  'long',\n",
       "  'argued',\n",
       "  'cross',\n",
       "  'party',\n",
       "  'compromise',\n",
       "  'brexit.',\n",
       "  'fiercely',\n",
       "  'deal',\n",
       "  'look',\n",
       "  'deal',\n",
       "  'seriousl…'],\n",
       " ['campbellclaret',\n",
       "  'facts',\n",
       "  'intrude',\n",
       "  'lalaland',\n",
       "  'brexit',\n",
       "  'fantasies.',\n",
       "  '‘brexit’',\n",
       "  'make',\n",
       "  'britain’s',\n",
       "  'mediocre',\n",
       "  'economy',\n",
       "  'worse',\n",
       "  'http…'],\n",
       " ['stefaanderynck',\n",
       "  'set',\n",
       "  'slides',\n",
       "  'ended',\n",
       "  'friday',\n",
       "  'busy',\n",
       "  'week',\n",
       "  'eu27',\n",
       "  'working',\n",
       "  'party',\n",
       "  'brexit.',\n",
       "  'slides',\n",
       "  'deal',\n",
       "  'acti…'],\n",
       " ['gekylafas',\n",
       "  '[boris]',\n",
       "  'johnson',\n",
       "  '&amp;',\n",
       "  'brexit',\n",
       "  'proponents',\n",
       "  'campaigning',\n",
       "  'caricature',\n",
       "  'eu',\n",
       "  'helped',\n",
       "  'create',\n",
       "  'https/…'],\n",
       " ['uk',\n",
       "  'wont',\n",
       "  'ever',\n",
       "  'leave',\n",
       "  'eu',\n",
       "  'without',\n",
       "  'deal...',\n",
       "  'wont',\n",
       "  'deal',\n",
       "  'commons',\n",
       "  'votes',\n",
       "  'deal',\n",
       "  'eu...',\n",
       "  'eu',\n",
       "  'wont',\n",
       "  'adjust',\n",
       "  '(unacceptable)',\n",
       "  'deal',\n",
       "  'theyve',\n",
       "  'already',\n",
       "  'sent',\n",
       "  'us...',\n",
       "  'uk',\n",
       "  'wont',\n",
       "  'ever',\n",
       "  'leave',\n",
       "  'eu.',\n",
       "  'logic',\n",
       "  'last',\n",
       "  'night.'],\n",
       " ['robertvanderoer',\n",
       "  'cer_grant',\n",
       "  'explains',\n",
       "  'eu',\n",
       "  'bbc',\n",
       "  'anchor.',\n",
       "  'one',\n",
       "  'exiting',\n",
       "  'country',\n",
       "  'cannot',\n",
       "  'dictate',\n",
       "  '27',\n",
       "  'eu',\n",
       "  'countries.',\n",
       "  'uk',\n",
       "  'unilateralism',\n",
       "  'vs',\n",
       "  'eu',\n",
       "  'multi…'],\n",
       " ['refusing',\n",
       "  'bring',\n",
       "  'deal',\n",
       "  'back',\n",
       "  'parliament',\n",
       "  'continuing',\n",
       "  'threaten',\n",
       "  'country',\n",
       "  'damage',\n",
       "  'deal',\n",
       "  'brexit',\n",
       "  'utterly',\n",
       "  'irresponsible.',\n",
       "  'wednesday',\n",
       "  'parliament',\n",
       "  'needs',\n",
       "  'vote',\n",
       "  'safeguard',\n",
       "  'prevent',\n",
       "  'us',\n",
       "  'leaving',\n",
       "  'eu',\n",
       "  'deal',\n",
       "  '29',\n",
       "  'march.',\n",
       "  'https//t.co/qvrptazcyp'],\n",
       " ['uk',\n",
       "  'wont',\n",
       "  'ever',\n",
       "  'leave',\n",
       "  'eu',\n",
       "  'without',\n",
       "  'deal...',\n",
       "  'wont',\n",
       "  'deal',\n",
       "  'commons',\n",
       "  'votes',\n",
       "  'deal',\n",
       "  'eu...',\n",
       "  'eu',\n",
       "  'wont',\n",
       "  'adjust',\n",
       "  '(unacceptable)',\n",
       "  'deal',\n",
       "  'theyve',\n",
       "  'already',\n",
       "  'sent',\n",
       "  'us...',\n",
       "  'uk',\n",
       "  'wont',\n",
       "  'ever',\n",
       "  'leave',\n",
       "  'eu.',\n",
       "  'logic',\n",
       "  'last',\n",
       "  'night.'],\n",
       " ['gloriadepiero',\n",
       "  'i’ve',\n",
       "  'long',\n",
       "  'argued',\n",
       "  'cross',\n",
       "  'party',\n",
       "  'compromise',\n",
       "  'brexit.',\n",
       "  'fiercely',\n",
       "  'deal',\n",
       "  'look',\n",
       "  'deal',\n",
       "  'seriousl…'],\n",
       " ['paladinoeu',\n",
       "  'brexit',\n",
       "  'brexit',\n",
       "  'johnspringford',\n",
       "  'cer_grant',\n",
       "  'list',\n",
       "  '10',\n",
       "  'compromises',\n",
       "  'may',\n",
       "  'never',\n",
       "  'talked',\n",
       "  'ecj',\n",
       "  'eubudget',\n",
       "  'etc',\n",
       "  'https…'],\n",
       " ['walking',\n",
       "  'government',\n",
       "  'won’t',\n",
       "  'make',\n",
       "  'brexit',\n",
       "  'go',\n",
       "  'away,',\n",
       "  'optimist',\n",
       "  'nature,',\n",
       "  'hope',\n",
       "  'creates',\n",
       "  'unity',\n",
       "  'needed',\n",
       "  'find',\n",
       "  'parliamentary',\n",
       "  'majority',\n",
       "  'agreement',\n",
       "  'works.',\n",
       "  'brexit',\n",
       "  'brexitshambles'],\n",
       " ['coyleneil',\n",
       "  'watch',\n",
       "  'eu',\n",
       "  'titan',\n",
       "  'sebdance',\n",
       "  'voteneilcoyle',\n",
       "  'today',\n",
       "  'strong',\n",
       "  'eu',\n",
       "  'voice',\n",
       "  'https//t.co/mtrwchqjzm'],\n",
       " ['demand',\n",
       "  'people’s',\n",
       "  'vote',\n",
       "  'final',\n",
       "  'brexit',\n",
       "  'deal',\n",
       "  'grow.',\n",
       "  'new',\n",
       "  'facts',\n",
       "  'consequences',\n",
       "  'leaving',\n",
       "  'eu',\n",
       "  'coming',\n",
       "  'light',\n",
       "  'every',\n",
       "  'day,',\n",
       "  'clearer',\n",
       "  'ever',\n",
       "  'brexit',\n",
       "  'big',\n",
       "  'deal,',\n",
       "  'done',\n",
       "  'deal.',\n",
       "  '(4)'],\n",
       " ['mina_andreeva',\n",
       "  '.michelbarnier',\n",
       "  'daviddavismp',\n",
       "  'brexit',\n",
       "  'taxpayers',\n",
       "  'eu27',\n",
       "  'pay',\n",
       "  'obligations',\n",
       "  'taken',\n",
       "  'eu28,',\n",
       "  'including'],\n",
       " ['sensible',\n",
       "  'piece',\n",
       "  'brexit',\n",
       "  'nickjtimothy',\n",
       "  'uk',\n",
       "  'pay',\n",
       "  'get',\n",
       "  'trade',\n",
       "  'deal,',\n",
       "  'give',\n",
       "  'eu',\n",
       "  'citz',\n",
       "  'preferential',\n",
       "  'access',\n",
       "  'https//t.co/gppzfbbeup'],\n",
       " ['eu_commission',\n",
       "  'futureofeurope',\n",
       "  'rome',\n",
       "  'summit',\n",
       "  'birth',\n",
       "  'moment',\n",
       "  'eu',\n",
       "  '27.',\n",
       "  '25',\n",
       "  'march',\n",
       "  '2017',\n",
       "  'eu60',\n",
       "  'eu27',\n",
       "  'junckereu',\n",
       "  'ht…'],\n",
       " ['euroguido',\n",
       "  'corbyn',\n",
       "  'travelling',\n",
       "  'brussels',\n",
       "  'tell',\n",
       "  'eu',\n",
       "  'britain',\n",
       "  'accepting',\n",
       "  'deal',\n",
       "  'give',\n",
       "  'us.',\n",
       "  'cheers',\n",
       "  'jez.'],\n",
       " ['mr.',\n",
       "  'cameron,',\n",
       "  'eu',\n",
       "  'fanatic,',\n",
       "  'always',\n",
       "  'going',\n",
       "  'campaign',\n",
       "  'stay',\n",
       "  'eu.',\n",
       "  'so-called',\n",
       "  'deal',\n",
       "  'con',\n",
       "  'job.',\n",
       "  'https//t.co/8n3r7ucfcm'],\n",
       " ['het',\n",
       "  'geen',\n",
       "  'geheim',\n",
       "  'dat',\n",
       "  'ik',\n",
       "  'het',\n",
       "  'britse',\n",
       "  'vertrek',\n",
       "  'uit',\n",
       "  'eu',\n",
       "  'zeer',\n",
       "  'betreur.',\n",
       "  'nl',\n",
       "  'wordt',\n",
       "  'daardoor',\n",
       "  'elk',\n",
       "  'scenario',\n",
       "  'getroffen,',\n",
       "  'maar',\n",
       "  'die',\n",
       "  'gevolgen',\n",
       "  'zijn',\n",
       "  'een',\n",
       "  'no-deal',\n",
       "  'scenario',\n",
       "  'veel',\n",
       "  'ernstiger',\n",
       "  'dan',\n",
       "  'bij',\n",
       "  'een',\n",
       "  'terugtrekkingsakkoord.',\n",
       "  'de',\n",
       "  'deal',\n",
       "  'die',\n",
       "  'er',\n",
       "  'nu',\n",
       "  'ligt',\n",
       "  'het',\n",
       "  'maximaal',\n",
       "  'haalbare.',\n",
       "  'brexit'],\n",
       " ['pm',\n",
       "  'made',\n",
       "  'strong',\n",
       "  'case',\n",
       "  'remain.',\n",
       "  'observer',\n",
       "  'piece',\n",
       "  'argues',\n",
       "  'deal',\n",
       "  'tilts',\n",
       "  'balance',\n",
       "  'firmly',\n",
       "  'favour',\n",
       "  'staying',\n",
       "  'eu',\n",
       "  'https//t.co/piewvr2j5t'],\n",
       " ['ludicrous',\n",
       "  'suggest',\n",
       "  'trade',\n",
       "  'deficit',\n",
       "  'eu',\n",
       "  'pm',\n",
       "  'seems',\n",
       "  'suggest',\n",
       "  'brexit'],\n",
       " ['say',\n",
       "  'though',\n",
       "  'election',\n",
       "  'isnt',\n",
       "  'national',\n",
       "  'interest.',\n",
       "  'focus',\n",
       "  'brexit',\n",
       "  'economy',\n",
       "  'opinion',\n",
       "  'polls'],\n",
       " ['overwhelming',\n",
       "  'majority',\n",
       "  'leaders',\n",
       "  'financial',\n",
       "  'services',\n",
       "  'believe',\n",
       "  'london',\n",
       "  'remain',\n",
       "  'europe’s',\n",
       "  'top',\n",
       "  'hub',\n",
       "  'brexit.',\n",
       "  'lloyds',\n",
       "  'survey',\n",
       "  'boost',\n",
       "  'confidence',\n",
       "  'economy,',\n",
       "  'britain’s',\n",
       "  'post-brexit',\n",
       "  'prospects.',\n",
       "  'https//t.co/qngntb1scg'],\n",
       " ['dlf',\n",
       "  'die',\n",
       "  'eu,',\n",
       "  'die',\n",
       "  'briten',\n",
       "  'und',\n",
       "  'der',\n",
       "  'brexit',\n",
       "  'dazu',\n",
       "  'jetzt',\n",
       "  'im',\n",
       "  'dlf',\n",
       "  'der',\n",
       "  'präsident',\n",
       "  'des',\n",
       "  'europaparlaments,',\n",
       "  'martinschulz',\n",
       "  'https//t.co/x2kg4rkvlk'],\n",
       " ['dcd128',\n",
       "  'montie',\n",
       "  'timesredbox',\n",
       "  'bias',\n",
       "  'british',\n",
       "  'media',\n",
       "  'misreports',\n",
       "  'eu',\n",
       "  'https//t.co/0lycnt7s8m'],\n",
       " ['cer_ianbond',\n",
       "  'exception',\n",
       "  '(so',\n",
       "  'far)',\n",
       "  'camerons',\n",
       "  'resignation,',\n",
       "  'cer_grant',\n",
       "  'unfortunately',\n",
       "  'spot',\n",
       "  'crystal',\n",
       "  'ball.',\n",
       "  'brexit',\n",
       "  'https//…'],\n",
       " ['today',\n",
       "  'celebrate',\n",
       "  'eu',\n",
       "  'day',\n",
       "  'homo/',\n",
       "  'transphobia',\n",
       "  'idaho.',\n",
       "  'much',\n",
       "  'love.',\n",
       "  'special',\n",
       "  'thoughts',\n",
       "  'lgbt',\n",
       "  'people',\n",
       "  'chechnya'],\n",
       " ['joannasopinska',\n",
       "  'thousands',\n",
       "  'poles',\n",
       "  'show',\n",
       "  'today',\n",
       "  'much',\n",
       "  'care',\n",
       "  'eu',\n",
       "  '🇪🇺😎🇵🇱❤eu60',\n",
       "  'kochamcieeuropo',\n",
       "  'loveeu',\n",
       "  'https//t.co/npuf4wn1…'],\n",
       " ['agatagostynska',\n",
       "  'puzzled',\n",
       "  'happened',\n",
       "  'cer_grant',\n",
       "  'walks',\n",
       "  'campaign',\n",
       "  'https//t.co/1giktpjmme',\n",
       "  'brexit'],\n",
       " ['eu_commission',\n",
       "  'brexit',\n",
       "  'everything',\n",
       "  'prepared',\n",
       "  'last',\n",
       "  'detail.',\n",
       "  'margschinas',\n",
       "  'next',\n",
       "  'steps',\n",
       "  'notification',\n",
       "  'of…'],\n",
       " ['eu',\n",
       "  'relaxed',\n",
       "  'rules',\n",
       "  'origin',\n",
       "  'jordan',\n",
       "  'facilitate',\n",
       "  'export',\n",
       "  'eu.',\n",
       "  'create',\n",
       "  'jobs',\n",
       "  'syrian',\n",
       "  'refugees',\n",
       "  'jordanians',\n",
       "  'jordan🇯🇴🇪🇺'],\n",
       " ['peterjavorcik',\n",
       "  'important',\n",
       "  'times.',\n",
       "  'important',\n",
       "  'week.',\n",
       "  'important',\n",
       "  'meeting.',\n",
       "  'romesummit',\n",
       "  'preps',\n",
       "  'earlier',\n",
       "  'today.',\n",
       "  'eu60',\n",
       "  'https//t.co/6outk2rhyl'],\n",
       " ['eu_commission',\n",
       "  'brexit',\n",
       "  'notre',\n",
       "  'objectif',\n",
       "  'est',\n",
       "  'daboutir',\n",
       "  'un',\n",
       "  'accord.',\n",
       "  'nous',\n",
       "  'voulons',\n",
       "  'aboutir',\n",
       "  'un',\n",
       "  'accord',\n",
       "  'avec',\n",
       "  'le',\n",
       "  'royaume-uni,',\n",
       "  'pas',\n",
       "  'contre',\n",
       "  'le…'],\n",
       " ['guyverhofstadt',\n",
       "  'effect',\n",
       "  'trump',\n",
       "  '&amp;',\n",
       "  'brexit',\n",
       "  'europeans',\n",
       "  'rejecting',\n",
       "  'right',\n",
       "  'wing',\n",
       "  'populist',\n",
       "  'parties.',\n",
       "  'eufightback',\n",
       "  'https//t.co/mg8j26jh…'],\n",
       " ['nathalieloiseau',\n",
       "  'michelbarnier',\n",
       "  'aujourdhui',\n",
       "  'lena_fr',\n",
       "  'pour',\n",
       "  'parler',\n",
       "  'brexit.',\n",
       "  'clair,',\n",
       "  'engagé,',\n",
       "  'précis,',\n",
       "  'généreux',\n",
       "  'dans',\n",
       "  'ses',\n",
       "  'explications',\n",
       "  'un…'],\n",
       " ['brexit.',\n",
       "  'today',\n",
       "  'gva,',\n",
       "  'underlining',\n",
       "  'eu',\n",
       "  'continuity',\n",
       "  'wto',\n",
       "  '&amp;',\n",
       "  'leadership',\n",
       "  'supporting',\n",
       "  'multilateral',\n",
       "  'trading',\n",
       "  'system.',\n",
       "  'https//t.co/rk7kxsqjuq'],\n",
       " ['andrew_lilico',\n",
       "  'kill',\n",
       "  'notion',\n",
       "  'men',\n",
       "  '&amp;',\n",
       "  'women',\n",
       "  'think',\n",
       "  'differently',\n",
       "  'eu.',\n",
       "  'https//t.co/imqcnopo7y'],\n",
       " ['good',\n",
       "  'work',\n",
       "  'churchill,',\n",
       "  'helping',\n",
       "  'invent',\n",
       "  'eu,',\n",
       "  'thatcher,',\n",
       "  'giving',\n",
       "  'single',\n",
       "  'market',\n",
       "  'cer_london',\n",
       "  'https//t.co/kkxvnsfeck'],\n",
       " ['bulc_eu',\n",
       "  'thank',\n",
       "  'dear',\n",
       "  'colleagues',\n",
       "  'joint',\n",
       "  'efforts',\n",
       "  'raise',\n",
       "  'awareness',\n",
       "  'roadsafety.',\n",
       "  'lives',\n",
       "  'must',\n",
       "  'saved',\n",
       "  'eu',\n",
       "  'roads.',\n",
       "  'htt…'],\n",
       " ['lsebrexitvote',\n",
       "  'cornwall',\n",
       "  'demands',\n",
       "  'government',\n",
       "  'replaces',\n",
       "  'eu',\n",
       "  'millions',\n",
       "  '(after',\n",
       "  'voting',\n",
       "  'leave)',\n",
       "  'eurefresults',\n",
       "  'brexit',\n",
       "  'https//t.co/qs7upx9o0p',\n",
       "  'via…'],\n",
       " ['brexit',\n",
       "  'team',\n",
       "  'ready.',\n",
       "  'work',\n",
       "  'eu27',\n",
       "  'member',\n",
       "  'states,',\n",
       "  'eu',\n",
       "  'institutions',\n",
       "  '&amp;',\n",
       "  'citizens;',\n",
       "  'together"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<b>limit_output extension: Maximum message size of 10000 exceeded with 210380 characters</b>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokens_roy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2975cdb6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-16T13:51:21.257374Z",
     "start_time": "2022-06-16T13:51:21.199377Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>launch</td>\n",
       "      <td>cer_london</td>\n",
       "      <td>report</td>\n",
       "      <td>brexit,</td>\n",
       "      <td>martinwolf_</td>\n",
       "      <td>says</td>\n",
       "      <td>uk</td>\n",
       "      <td>much</td>\n",
       "      <td>influence</td>\n",
       "      <td>eu</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>griechenland</td>\n",
       "      <td>hat</td>\n",
       "      <td>eu-vorsitz,</td>\n",
       "      <td>lettland</td>\n",
       "      <td>den</td>\n",
       "      <td>€.</td>\n",
       "      <td>bürger</td>\n",
       "      <td>werden</td>\n",
       "      <td>über</td>\n",
       "      <td>eu-fragen</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>eu</td>\n",
       "      <td>started</td>\n",
       "      <td>discussing</td>\n",
       "      <td>longer</td>\n",
       "      <td>term;</td>\n",
       "      <td>need</td>\n",
       "      <td>reduce</td>\n",
       "      <td>eu</td>\n",
       "      <td>dependence</td>\n",
       "      <td>russian</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>matthewparris3</td>\n",
       "      <td>explains</td>\n",
       "      <td>thetimes</td>\n",
       "      <td>18th</td>\n",
       "      <td>jan</td>\n",
       "      <td>extreme</td>\n",
       "      <td>tory</td>\n",
       "      <td>eu-phobes</td>\n",
       "      <td>behind</td>\n",
       "      <td>letter</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>boris</td>\n",
       "      <td>bloomberg</td>\n",
       "      <td>speech</td>\n",
       "      <td>good.</td>\n",
       "      <td>half</td>\n",
       "      <td>uk</td>\n",
       "      <td>laws</td>\n",
       "      <td>eu</td>\n",
       "      <td>dutch</td>\n",
       "      <td>cutting</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25341</th>\n",
       "      <td>instead</td>\n",
       "      <td>puting</td>\n",
       "      <td>culture</td>\n",
       "      <td>no-go</td>\n",
       "      <td>area</td>\n",
       "      <td>eu</td>\n",
       "      <td>subsidiarity,</td>\n",
       "      <td>need</td>\n",
       "      <td>make</td>\n",
       "      <td>investement</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25342</th>\n",
       "      <td>assesment</td>\n",
       "      <td>last</td>\n",
       "      <td>years.</td>\n",
       "      <td>failing</td>\n",
       "      <td>banking</td>\n",
       "      <td>union</td>\n",
       "      <td>foreign</td>\n",
       "      <td>policy.</td>\n",
       "      <td>ep2014</td>\n",
       "      <td>eu</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25449</th>\n",
       "      <td>doorstep</td>\n",
       "      <td>deal</td>\n",
       "      <td>excellent</td>\n",
       "      <td>candidate</td>\n",
       "      <td>clairhawkins,</td>\n",
       "      <td>gwynn</td>\n",
       "      <td>prosser</td>\n",
       "      <td>(former</td>\n",
       "      <td>mp),</td>\n",
       "      <td>team</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25450</th>\n",
       "      <td>case</td>\n",
       "      <td>giving</td>\n",
       "      <td>power</td>\n",
       "      <td>back</td>\n",
       "      <td>local</td>\n",
       "      <td>communities.</td>\n",
       "      <td>labours</td>\n",
       "      <td>radical</td>\n",
       "      <td>plans</td>\n",
       "      <td>new</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25451</th>\n",
       "      <td>jesstud</td>\n",
       "      <td>labour</td>\n",
       "      <td>devolve</td>\n",
       "      <td>power</td>\n",
       "      <td>across</td>\n",
       "      <td>england</td>\n",
       "      <td>innovationtaskforce</td>\n",
       "      <td>set</td>\n",
       "      <td>blueprint</td>\n",
       "      <td>new</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>677 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0           1            2          3              4   \\\n",
       "6              launch  cer_london       report    brexit,    martinwolf_   \n",
       "57       griechenland         hat  eu-vorsitz,   lettland            den   \n",
       "94                 eu     started   discussing     longer          term;   \n",
       "204    matthewparris3    explains     thetimes       18th            jan   \n",
       "207             boris   bloomberg       speech      good.           half   \n",
       "...               ...         ...          ...        ...            ...   \n",
       "25341         instead      puting      culture      no-go           area   \n",
       "25342       assesment        last       years.    failing        banking   \n",
       "25449        doorstep        deal    excellent  candidate  clairhawkins,   \n",
       "25450            case      giving        power       back          local   \n",
       "25451         jesstud      labour      devolve      power         across   \n",
       "\n",
       "                 5                    6          7           8            9   \\\n",
       "6              says                   uk       much   influence           eu   \n",
       "57               €.               bürger     werden        über    eu-fragen   \n",
       "94             need               reduce         eu  dependence      russian   \n",
       "204         extreme                 tory  eu-phobes      behind       letter   \n",
       "207              uk                 laws         eu       dutch      cutting   \n",
       "...             ...                  ...        ...         ...          ...   \n",
       "25341            eu        subsidiarity,       need        make  investement   \n",
       "25342         union              foreign    policy.      ep2014           eu   \n",
       "25449         gwynn              prosser    (former        mp),         team   \n",
       "25450  communities.              labours    radical       plans          new   \n",
       "25451       england  innovationtaskforce        set   blueprint          new   \n",
       "\n",
       "       ...    39    40    41    42    43    44    45    46    47    48  \n",
       "6      ...  None  None  None  None  None  None  None  None  None  None  \n",
       "57     ...  None  None  None  None  None  None  None  None  None  None  \n",
       "94     ...  None  None  None  None  None  None  None  None  None  None  \n",
       "204    ...  None  None  None  None  None  None  None  None  None  None  \n",
       "207    ...  None  None  None  None  None  None  None  None  None  None  \n",
       "...    ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "25341  ...  None  None  None  None  None  None  None  None  None  None  \n",
       "25342  ...  None  None  None  None  None  None  None  None  None  None  \n",
       "25449  ...  None  None  None  None  None  None  None  None  None  None  \n",
       "25450  ...  None  None  None  None  None  None  None  None  None  None  \n",
       "25451  ...  None  None  None  None  None  None  None  None  None  None  \n",
       "\n",
       "[677 rows x 49 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_df_2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "30c12e2c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-16T13:50:25.737476Z",
     "start_time": "2022-06-16T13:50:25.498540Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['launch', 'cer_london', 'report', 'brexit,', 'martinwolf_', 'says',\n",
       "        'uk', 'much', 'influence', 'eu', 'scotland', 'wd', 'leave', 'uk',\n",
       "        'outside', 'eu.', None, None, None, None, None, None, None, None,\n",
       "        None, None, None, None, None, None, None, None, None, None, None,\n",
       "        None, None, None, None, None, None, None, None, None, None, None,\n",
       "        None, None, None], dtype=object),\n",
       " array(['griechenland', 'hat', 'eu-vorsitz,', 'lettland', 'den', '€.',\n",
       "        'bürger', 'werden', 'über', 'eu-fragen', 'diskutieren', '&amp;',\n",
       "        'entscheiden.', 'frohes', 'neues', 'jahr', 'für', 'alle!', None,\n",
       "        None, None, None, None, None, None, None, None, None, None, None,\n",
       "        None, None, None, None, None, None, None, None, None, None, None,\n",
       "        None, None, None, None, None, None, None, None], dtype=object),\n",
       " array(['eu', 'started', 'discussing', 'longer', 'term;', 'need', 'reduce',\n",
       "        'eu', 'dependence', 'russian', 'energy', 'many', 'years', 'come',\n",
       "        'ukraine', None, None, None, None, None, None, None, None, None,\n",
       "        None, None, None, None, None, None, None, None, None, None, None,\n",
       "        None, None, None, None, None, None, None, None, None, None, None,\n",
       "        None, None, None], dtype=object),\n",
       " array(['matthewparris3', 'explains', 'thetimes', '18th', 'jan', 'extreme',\n",
       "        'tory', 'eu-phobes', 'behind', 'letter', '95', 'want', 'cameron',\n",
       "        'lose', 'general', 'election.', 'eu', None, None, None, None, None,\n",
       "        None, None, None, None, None, None, None, None, None, None, None,\n",
       "        None, None, None, None, None, None, None, None, None, None, None,\n",
       "        None, None, None, None, None], dtype=object),\n",
       " array(['boris', 'bloomberg', 'speech', 'good.', 'half', 'uk', 'laws',\n",
       "        'eu', 'dutch', 'cutting', '54', 'eu', 'competences.',\n",
       "        'drgerardlyons', 'matthewparris3', None, None, None, None, None,\n",
       "        None, None, None, None, None, None, None, None, None, None, None,\n",
       "        None, None, None, None, None, None, None, None, None, None, None,\n",
       "        None, None, None, None, None, None, None], dtype=object),\n",
       " array(['griechenland', 'hat', 'eu-vorsitz,', 'lettland', 'den', '€.',\n",
       "        'bürger', 'werden', 'über', 'eu-fragen', 'diskutieren', '&amp;',\n",
       "        'entscheiden.', 'frohes', 'neues', 'jahr', 'für', 'alle!', None,\n",
       "        None, None, None, None, None, None, None, None, None, None, None,\n",
       "        None, None, None, None, None, None, None, None, None, None, None,\n",
       "        None, None, None, None, None, None, None, None], dtype=object),\n",
       " array(['epp_fi', 'eu', 'pehmeä', 'valta.', 'sota', 'ei', 'ole',\n",
       "        'vaihtoehto', 'kenellekään.', 'sanktiot', 'ovat', 'ainut',\n",
       "        'mahdollisuus', 'vaikuttaa.', 'withjuncker', 'eurodebat', 'eu…',\n",
       "        None, None, None, None, None, None, None, None, None, None, None,\n",
       "        None, None, None, None, None, None, None, None, None, None, None,\n",
       "        None, None, None, None, None, None, None, None, None, None],\n",
       "       dtype=object),\n",
       " array(['factcheckeu', '.junckereu', 'may', 'really', 'techie,', 'hes',\n",
       "        'absolutely', 'scratch', 'eus', 'app', 'economy',\n",
       "        'http//t.co/hgiqjr…', None, None, None, None, None, None, None,\n",
       "        None, None, None, None, None, None, None, None, None, None, None,\n",
       "        None, None, None, None, None, None, None, None, None, None, None,\n",
       "        None, None, None, None, None, None, None, None], dtype=object),\n",
       " array(['junckereu', 'en', 'route', 'pour', 'rencontrer', 'le', 'citoyen',\n",
       "        'dhonneur', 'européen', '12h30.', 'sans', 'lui', 'il', 'n’y',\n",
       "        'aura', 'pas', 'eu', 'de', 'réunification', 'allemande', 'et',\n",
       "        'eu…', None, None, None, None, None, None, None, None, None, None,\n",
       "        None, None, None, None, None, None, None, None, None, None, None,\n",
       "        None, None, None, None, None, None], dtype=object),\n",
       " array(['ep_economics', '.jyrkikatainen', 'euinvest', 'change', 'use',\n",
       "        'publ.', 'money', 'eu.', 'identifying', '1000', 'projects.',\n",
       "        'introduce', 'eu', 'label', None, None, None, None, None, None,\n",
       "        None, None, None, None, None, None, None, None, None, None, None,\n",
       "        None, None, None, None, None, None, None, None, None, None, None,\n",
       "        None, None, None, None, None, None, None], dtype=object),\n",
       " array(['ec_stockholmrep', 'live', 'idag', 'kl', '1430', 'eus',\n",
       "        'rättsliga', 'och', 'migpol', 'agenda', '2020', 'samt', 'analys',\n",
       "        'av', 'eu-ländernas', 'rättssystem', 'http//t.co/go3hibg…', None,\n",
       "        None, None, None, None, None, None, None, None, None, None, None,\n",
       "        None, None, None, None, None, None, None, None, None, None, None,\n",
       "        None, None, None, None, None, None, None, None, None], dtype=object),\n",
       " array(['ecspokeskoen', 'important', 'breakthrough', 'eu', 'strikes',\n",
       "        'comprehensive', 'trade', 'deal', 'east', 'african', 'community',\n",
       "        'eac', 'http//t.co/2gub0iga…', None, None, None, None, None, None,\n",
       "        None, None, None, None, None, None, None, None, None, None, None,\n",
       "        None, None, None, None, None, None, None, None, None, None, None,\n",
       "        None, None, None, None, None, None, None, None], dtype=object),\n",
       " array(['it2014eu', 'tomorrow', '9/10', 'justice', 'home', 'affairs',\n",
       "        'minister', 'angealfa.', 'agenda', 'http//t.co/c0pubwfbcc',\n",
       "        'it2014eu', 'jha', None, None, None, None, None, None, None, None,\n",
       "        None, None, None, None, None, None, None, None, None, None, None,\n",
       "        None, None, None, None, None, None, None, None, None, None, None,\n",
       "        None, None, None, None, None, None, None], dtype=object),\n",
       " array(['it2014eu', 'july', 'first', 'informal', 'jha', 'ministers',\n",
       "        'chaired', 'angealfa', 'it2014eu', 'info', 'http//t.co/kkis6ptu3l',\n",
       "        None, None, None, None, None, None, None, None, None, None, None,\n",
       "        None, None, None, None, None, None, None, None, None, None, None,\n",
       "        None, None, None, None, None, None, None, None, None, None, None,\n",
       "        None, None, None, None, None], dtype=object),\n",
       " array(['cspillmann', 'it2014eu', 'le', 'logo', 'officiel', 'du',\n",
       "        'semestre', 'de', 'présidence', 'italienne', 'de', 'ue',\n",
       "        'it2014eu', 'http//t.co/hdc7ocmfiv', None, None, None, None, None,\n",
       "        None, None, None, None, None, None, None, None, None, None, None,\n",
       "        None, None, None, None, None, None, None, None, None, None, None,\n",
       "        None, None, None, None, None, None, None, None], dtype=object),\n",
       " array(['ep_president', 'welcome', 'albania', 'eu', 'candidate',\n",
       "        'country.', 'important', 'recognition', 'reforms', 'undertaken,',\n",
       "        'eu', 'key', 'actor', 'stability', 'in…', None, None, None, None,\n",
       "        None, None, None, None, None, None, None, None, None, None, None,\n",
       "        None, None, None, None, None, None, None, None, None, None, None,\n",
       "        None, None, None, None, None, None, None, None], dtype=object),\n",
       " array(['teamdeutschland', '3.eu', 'wipol', 'braucht', 'bessere',\n",
       "        'abstimmung.', 'deutschland', 'geht', 'es', 'nur', 'gut,wenn',\n",
       "        'es', 'der', 'eu', 'gut', 'geht', 'ep2014', 'cdu', 'europawahl',\n",
       "        None, None, None, None, None, None, None, None, None, None, None,\n",
       "        None, None, None, None, None, None, None, None, None, None, None,\n",
       "        None, None, None, None, None, None, None, None], dtype=object),\n",
       " array(['teamdeutschland', 'bildungsabschlüsse', 'eu-weit', 'anerkennen.',\n",
       "        'die', 'ausbildung', 'betrieb', 'und', 'berufsschule', 'ganz',\n",
       "        'eu', 'verankern.', 'ep2014', 'cdu', None, None, None, None, None,\n",
       "        None, None, None, None, None, None, None, None, None, None, None,\n",
       "        None, None, None, None, None, None, None, None, None, None, None,\n",
       "        None, None, None, None, None, None, None, None], dtype=object),\n",
       " array(['aldegroup', 'eu', 'climate', 'package', 'deal', 'frustrated',\n",
       "        'national', 'interests', 'euco', 'guyverhofstadt', 'gerbrandy',\n",
       "        'federley', 'ftbrussels', 'http//t.co…', None, None, None, None,\n",
       "        None, None, None, None, None, None, None, None, None, None, None,\n",
       "        None, None, None, None, None, None, None, None, None, None, None,\n",
       "        None, None, None, None, None, None, None, None, None], dtype=object),\n",
       " array(['eu', 'research&amp;innovation', '=successful', 'scilifelab', 'eu',\n",
       "        'business', 'environment', 'prevents', 'translation', 'in2',\n",
       "        'business&amp;jobs', 'vote', 'counts', 'ep2014', None, None, None,\n",
       "        None, None, None, None, None, None, None, None, None, None, None,\n",
       "        None, None, None, None, None, None, None, None, None, None, None,\n",
       "        None, None, None, None, None, None, None, None, None, None],\n",
       "       dtype=object),\n",
       " array(['ed_milibands', 'speech', 'tmr', 'eu', 'putting', 'national',\n",
       "        '(not', 'party)', 'interest', 'first-exports,growth,jobs,the',\n",
       "        'economy', 'agenda2030', None, None, None, None, None, None, None,\n",
       "        None, None, None, None, None, None, None, None, None, None, None,\n",
       "        None, None, None, None, None, None, None, None, None, None, None,\n",
       "        None, None, None, None, None, None, None, None], dtype=object),\n",
       " array(['crucial', 'raise', 'wages', 'deal', 'cost', 'living', 'crisis',\n",
       "        'also', 'grow', 'number', 'middle', 'income', 'jobs', 'economy',\n",
       "        None, None, None, None, None, None, None, None, None, None, None,\n",
       "        None, None, None, None, None, None, None, None, None, None, None,\n",
       "        None, None, None, None, None, None, None, None, None, None, None,\n",
       "        None, None], dtype=object),\n",
       " array(['great', 'catch', 'former', 'french', 'chancellor,', 'pierre',\n",
       "        'moscovici,', 'talk', 'business,', 'economy', 'eu',\n",
       "        'http//t.co/qhrdwca2b3', None, None, None, None, None, None, None,\n",
       "        None, None, None, None, None, None, None, None, None, None, None,\n",
       "        None, None, None, None, None, None, None, None, None, None, None,\n",
       "        None, None, None, None, None, None, None, None], dtype=object),\n",
       " array(['85%', 'manufacturers', 'would', 'vote', 'stay', 'eu.',\n",
       "        'contrast,', '7%', 'would', 'vote', 'pul"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<b>limit_output extension: Maximum message size of 10000 exceeded with 287895 characters</b>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "list(np.asarray(tokens_df_2014))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a2c26d75",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-16T14:12:09.800657Z",
     "start_time": "2022-06-16T14:12:09.613279Z"
    }
   },
   "outputs": [],
   "source": [
    "### Build vocabulary + train\n",
    "model_file_name = os.path.join(data_folder, \"word2vec_2014_tweets_v11\")\n",
    "if not os.path.isfile(model_file_name):\n",
    "    model = gensim.models.Word2Vec(sentences = tokens_df_2014_new, #Train a word2vec model with the birams + the regular words\n",
    "                                  vector_size = vector_size,\n",
    "                                  window = window, \n",
    "                                  min_count = min_count,                              \n",
    "                                  epochs = epochs,\n",
    "                                  sg = 0, #0: CBOW, 1:skip-gram\n",
    "                                  workers = os.cpu_count())\n",
    "    model.save(model_file_name)\n",
    "else:\n",
    "    model = gensim.models.Word2Vec.load(model_file_name)\n",
    "\n",
    "model_2014 = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a9a2713b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-16T14:12:18.773158Z",
     "start_time": "2022-06-16T14:12:18.763143Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.word2vec.Word2Vec at 0x23fcd37f790>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985f4495",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded2684b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9f1811",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

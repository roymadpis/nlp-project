{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc8f56a6",
   "metadata": {},
   "source": [
    "## Step 4 - Sentiment Analysis labels\n",
    "\n",
    "#### In this notebook we:\n",
    "a. read the data_folder/tweets_table_all.csv - this is a table with ~1M tweets, containing tweets of KOL ad tweets of brexit from 2014-2021. It is a table **without sentiment**\n",
    "\n",
    "b. Import the fine-tuned sentiment model - from the location: Brexit_sentiment_model\n",
    "\n",
    "c. We use the sentiment model to give sentiment-prediction-labels to the ~1M tweets (from a)\n",
    "We save the labeled data frame in the following location:  data_folder/tweets_table_all_with_sentimet.csv \n",
    "We will use that table in step 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "159105b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-18T16:18:54.482140Z",
     "start_time": "2022-06-18T16:18:47.156221Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will be training on cpu\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "import gensim, logging, pandas as pd\n",
    "import numpy as np, matplotlib.pyplot as plt, os\n",
    "import pandas as pd\n",
    "import json, zipfile\n",
    "import torch\n",
    "import seaborn as sns\n",
    "\n",
    "from transformers import pipeline\n",
    "from scipy.special import softmax\n",
    "from transformers import AutoTokenizer, AutoConfig\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else \"cpu\") \n",
    "print(f\"Will be training on {device}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3682a75",
   "metadata": {},
   "source": [
    "### 4.a Reading tweets_table_all (~1M tweets)\n",
    "read the data_folder/tweets_table_all.csv - this is a table with ~1M tweets, containing tweets of KOL ad tweets of brexit from 2014-2021. It is a table without sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c201489",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-18T16:27:03.161756Z",
     "start_time": "2022-06-18T16:26:44.911648Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roymad\\AppData\\Local\\Temp\\ipykernel_39852\\4151046788.py:1: DtypeWarning: Columns (13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  tweets_table_all = pd.read_csv(\"data_folder/tweets_table_all.csv\")\n"
     ]
    }
   ],
   "source": [
    "tweets_table_all = pd.read_csv(\"data_folder/tweets_table_all.csv\")\n",
    "tweets_table_all = tweets_table_all.drop(labels = [\"Unnamed: 0\"], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1909f4c2",
   "metadata": {},
   "source": [
    "### 4.b Using the sentiment model that we fine-tuned on Step 3 to make sentiment analysis predictions\n",
    "Import the fine-tuned sentiment model - from the location: Brexit_sentiment_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58d6a38d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-18T16:25:21.706553Z",
     "start_time": "2022-06-18T16:25:00.631131Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import os.path\n",
    "name_dir_to_save_model = \"Brexit_sentiment_model\" #The name of the foler containing the fine-tuned sentiment model\n",
    "\n",
    "# try:\n",
    "#     os.makedirs(name_dir_to_save_model)\n",
    "#     print(\"Creating directory\", name_dir_to_save_model, \" to save the sentimwnt analysis model\")\n",
    "# except:\n",
    "#     print(\"The dir: \", name_dir_to_save_model, \"already exists\")\n",
    "# ### saving the model we re-trained\n",
    "\n",
    "### if you wosh to read the saved model:\n",
    "sentiment_task_example = pipeline(\"sentiment-analysis\",\n",
    "model = \"cardiffnlp/twitter-roberta-base-sentiment-latest\", \n",
    "tokenizer = \"cardiffnlp/twitter-roberta-base-sentiment-latest\")\n",
    "\n",
    "model_loaded = sentiment_task_example.model.from_pretrained(name_dir_to_save_model)\n",
    "\n",
    "sentiment_task_model_loaded = pipeline(\"sentiment-analysis\",\n",
    "model = model_loaded, \n",
    "tokenizer = \"cardiffnlp/twitter-roberta-base-sentiment-latest\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a0cd69",
   "metadata": {},
   "source": [
    "### Defining function for getting the sentiment from all the tweets\n",
    "\n",
    "+ if you define yourself the \"sentiment task\" object then you can save a lot of time!\n",
    " sentiment_task = pipeline(\"sentiment-analysis\", model = model, #this is the model we re-trained\n",
    "            tokenizer = \"cardiffnlp/twitter-roberta-base-sentiment-latest\")\n",
    "\n",
    "+ x = the text to classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f23ecc30",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-18T16:25:39.693175Z",
     "start_time": "2022-06-18T16:25:39.680914Z"
    }
   },
   "outputs": [],
   "source": [
    "def Sentiment_predictions_huggin_face(x, sentiment_task = None, re_trained_model = None, \n",
    "tokenizer = \"cardiffnlp/twitter-roberta-base-sentiment-latest\"):\n",
    "\n",
    "    if sentiment_task is None:\n",
    "        sentiment_task = pipeline(\"sentiment-analysis\",\n",
    "            model = re_trained_model, #this is the model we re-trained\n",
    "            tokenizer = tokenizer)\n",
    "\n",
    "    prediction_score = sentiment_task(x)\n",
    "    prediction = prediction_score[0][\"label\"]\n",
    "    return (prediction)\n",
    "\n",
    "### this functions alows making a column iwth the score of the sentiment model for the prediciton\n",
    "def Sentiment_score_predictions_huggin_face(x, sentiment_task = None, re_trained_model = None, \n",
    "    tokenizer = \"cardiffnlp/twitter-roberta-base-sentiment-latest\"):\n",
    "\n",
    "    if sentiment_task is None:\n",
    "        sentiment_task = pipeline(\"sentiment-analysis\",\n",
    "            model = re_trained_model, #this is the model we re-trained\n",
    "            tokenizer = tokenizer)\n",
    "\n",
    "    prediction_score = sentiment_task(x)\n",
    "    score = prediction_score[0][\"score\"]\n",
    "    return (score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24114c18",
   "metadata": {},
   "source": [
    "## 4.c Predicting the sentiment of all the tweets\n",
    "Now that we have our trained sentiment analysis model, we wish to use it to label all the tweets we have with sentiment label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5605090",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-18T16:28:02.346Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tweets_table_all[\"Predicted_sentiment\"] = tweets_table_all[\"text\"].apply(lambda x: Sentiment_predictions_huggin_face(x = x, sentiment_task=sentiment_task_model_loaded))\n",
    "#tweets_table_all[\"Predicted_sentiment_score\"] = tweets_table_all[\"text\"].apply(lambda x: Sentiment_predictions_huggin_face(x = x, sentiment_task=sentiment_task_model_loaded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6278e9ee",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-18T16:37:14.675Z"
    }
   },
   "outputs": [],
   "source": [
    "data_folder_name = \"data_folder\"\n",
    "tweets_table_all.to_csv(os.path.join(data_folder_name, \"tweets_table_all_with_sentimet.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8fbd56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228623e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e024d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "469f58ef",
   "metadata": {},
   "source": [
    "## Step 4 - Sentiment Analysis labels\n",
    "\n",
    "#### In this notebook we:\n",
    "a. read the data_folder/tweets_table_all.csv - this is a table with ~1M tweets, containing tweets of KOL ad tweets of brexit from 2014-2021. It is a table **without sentiment**\n",
    "\n",
    "b. Import the fine-tuned sentiment model - from the location: Brexit_sentiment_model\n",
    "\n",
    "c. We use the sentiment model to give sentiment-prediction-labels to the ~1M tweets (from a)\n",
    "We save the labeled data frame in the following location:  data_folder/tweets_table_all_with_sentimet.csv \n",
    "We will use that table in step 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "440ca6d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-24T12:28:38.686534Z",
     "start_time": "2022-06-24T12:28:38.671264Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will be training on cpu\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "import gensim, logging, pandas as pd\n",
    "import numpy as np, matplotlib.pyplot as plt, os\n",
    "import pandas as pd\n",
    "import json, zipfile\n",
    "import torch\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "from transformers import pipeline\n",
    "from scipy.special import softmax\n",
    "from transformers import AutoTokenizer, AutoConfig\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else \"cpu\") \n",
    "print(f\"Will be training on {device}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9e00ef",
   "metadata": {},
   "source": [
    "### 4.a Reading tweets_table_all (~1M tweets)\n",
    "read the data_folder/tweets_table_all.csv - this is a table with ~1M tweets, containing tweets of KOL ad tweets of brexit from 2014-2021. It is a table without sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f785ad7a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-24T12:28:50.064605Z",
     "start_time": "2022-06-24T12:28:40.754131Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roymad\\AppData\\Local\\Temp\\ipykernel_8416\\4151046788.py:1: DtypeWarning: Columns (13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  tweets_table_all = pd.read_csv(\"data_folder/tweets_table_all.csv\")\n"
     ]
    }
   ],
   "source": [
    "tweets_table_all = pd.read_csv(\"data_folder/tweets_table_all.csv\")\n",
    "tweets_table_all = tweets_table_all.drop(labels = [\"Unnamed: 0\"], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6beab823",
   "metadata": {},
   "source": [
    "### 4.b Using the sentiment model that we fine-tuned on Step 3 to make sentiment analysis predictions\n",
    "Import the fine-tuned sentiment model - from the location: Brexit_sentiment_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c0da453",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-24T12:36:49.450927Z",
     "start_time": "2022-06-24T12:36:32.411243Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import os.path\n",
    "name_dir_to_save_model = \"Brexit_sentiment_model_new\" #The name of the foler containing the fine-tuned sentiment model\n",
    "\n",
    "# try:\n",
    "#     os.makedirs(name_dir_to_save_model)\n",
    "#     print(\"Creating directory\", name_dir_to_save_model, \" to save the sentiment analysis model\")\n",
    "# except:\n",
    "#     print(\"The dir: \", name_dir_to_save_model, \"already exists\")\n",
    "# ### saving the model we re-trained\n",
    "\n",
    "### if you wosh to read the saved model:\n",
    "sentiment_task_example = pipeline(\"sentiment-analysis\",\n",
    "model = \"cardiffnlp/twitter-roberta-base-sentiment-latest\", \n",
    "tokenizer = \"cardiffnlp/twitter-roberta-base-sentiment-latest\")\n",
    "\n",
    "model_loaded = sentiment_task_example.model.from_pretrained(name_dir_to_save_model)\n",
    "\n",
    "sentiment_task_model_loaded = pipeline(\"sentiment-analysis\",\n",
    "model = model_loaded, \n",
    "tokenizer = \"cardiffnlp/twitter-roberta-base-sentiment-latest\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0ce616",
   "metadata": {},
   "source": [
    "### Defining function for getting the sentiment from all the tweets\n",
    "\n",
    "+ if you define yourself the \"sentiment task\" object then you can save a lot of time!\n",
    " sentiment_task = pipeline(\"sentiment-analysis\", model = model, #this is the model we re-trained\n",
    "            tokenizer = \"cardiffnlp/twitter-roberta-base-sentiment-latest\")\n",
    "\n",
    "+ x = the text to classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b22390d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-24T12:37:56.662697Z",
     "start_time": "2022-06-24T12:37:56.645985Z"
    }
   },
   "outputs": [],
   "source": [
    "def Sentiment_predictions_huggin_face(x, sentiment_task = None, re_trained_model = None, \n",
    "tokenizer = \"cardiffnlp/twitter-roberta-base-sentiment-latest\"):\n",
    "\n",
    "    if sentiment_task is None:\n",
    "        sentiment_task = pipeline(\"sentiment-analysis\",\n",
    "            model = re_trained_model, #this is the model we re-trained\n",
    "            tokenizer = tokenizer)\n",
    "\n",
    "    prediction_score = sentiment_task(x)\n",
    "    prediction = prediction_score[0][\"label\"]\n",
    "    return (prediction)\n",
    "\n",
    "### this functions alows making a column iwth the score of the sentiment model for the prediciton\n",
    "def Sentiment_score_predictions_huggin_face(x, sentiment_task = None, re_trained_model = None, \n",
    "    tokenizer = \"cardiffnlp/twitter-roberta-base-sentiment-latest\"):\n",
    "\n",
    "    if sentiment_task is None:\n",
    "        sentiment_task = pipeline(\"sentiment-analysis\",\n",
    "            model = re_trained_model, #this is the model we re-trained\n",
    "            tokenizer = tokenizer)\n",
    "\n",
    "    prediction_score = sentiment_task(x)\n",
    "    score = prediction_score[0][\"score\"]\n",
    "    return (score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9234cbb0",
   "metadata": {},
   "source": [
    "## 4.c Predicting the sentiment of all the tweets\n",
    "Now that we have our trained sentiment analysis model, we wish to use it to label all the tweets we have with sentiment label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8027c502",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-19T08:18:27.216673Z",
     "start_time": "2022-06-19T08:18:27.193724Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#tweets_table_all[\"Predicted_sentiment\"] = tweets_table_all[\"text\"].apply(lambda x: Sentiment_predictions_huggin_face(x = x, sentiment_task=sentiment_task_model_loaded))\n",
    "#tweets_table_all[\"Predicted_sentiment_score\"] = tweets_table_all[\"text\"].apply(lambda x: Sentiment_predictions_huggin_face(x = x, sentiment_task=sentiment_task_model_loaded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aacefff6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-24T12:38:00.038648Z",
     "start_time": "2022-06-24T12:38:00.025759Z"
    }
   },
   "outputs": [],
   "source": [
    "data_folder_name = \"data_folder\"\n",
    "#tweets_table_all.to_csv(os.path.join(data_folder_name, \"tweets_table_all_with_sentimet.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7768085",
   "metadata": {},
   "source": [
    "## As we have so many tweets, it is very heavy to run the sentiment model on all of them together, so we will perform the labeling task in batches\n",
    "\n",
    "Creating a directory to store all the mini-csv tables with the sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ed5f820",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-24T12:38:38.264165Z",
     "start_time": "2022-06-24T12:38:38.244906Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dir:  data_folder\\Predicted_sentiment_tables already exists\n"
     ]
    }
   ],
   "source": [
    "data_folder_name = \"data_folder\"\n",
    "data_folder_name_for_sentiment = os.path.join(data_folder_name, \"Predicted_sentiment_tables\")\n",
    "try:\n",
    "    os.makedirs(data_folder_name_for_sentiment)\n",
    "    print(\"Creating directory\", data_folder_name_for_sentiment, \" to save the sentiment predicted labels\")\n",
    "except:\n",
    "    print(\"The dir: \", data_folder_name_for_sentiment, \"already exists\")\n",
    "### saving the model we re-trained\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59042377",
   "metadata": {},
   "outputs": [],
   "source": [
    "### creating smaller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "38202e6f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-19T08:19:19.543520Z",
     "start_time": "2022-06-19T08:19:19.504369Z"
    }
   },
   "outputs": [],
   "source": [
    "#tweets_table_all[\"index_num\"] = tweets_table_all.index\n",
    "#smaller_tweets_table_all = tweets_table_all[[\"index_num\",\"id\", \"text\"]]\n",
    "#smaller_tweets_table_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e59c867a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-24T12:38:40.607470Z",
     "start_time": "2022-06-24T12:38:40.529050Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tweets: 979821\n",
      "Number or rows in each group: 9798.2\n"
     ]
    }
   ],
   "source": [
    "num_of_rows = tweets_table_all.shape[0]\n",
    "print(\"Total number of tweets:\", num_of_rows)\n",
    "num_groups = 100\n",
    "print(\"Number or rows in each group:\", round(num_of_rows/num_groups,1))\n",
    "split_groups = np.array_split(range(num_of_rows), num_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aca1190",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in tqdm_notebook(range(len(split_groups))):\n",
    "#     group_i = split_groups[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f721a1",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-24T12:38:50.815Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b83c32f7cf849089e5397bc49262172",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore') #ignore warning messages\n",
    "\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "name_for_csv_table = \"tweets_table_with_sentiment_num\"\n",
    "\n",
    "for i in tqdm_notebook(range(len(split_groups))):\n",
    "    group_i = split_groups[i]\n",
    "    sub_group_i = tweets_table_all.iloc[group_i]\n",
    "    sub_group_i = sub_group_i.dropna(subset=['text']) #dropping tweets with na in the text\n",
    "    sub_group_i[\"Predicted_sentiment\"] = sub_group_i[\"text\"].apply(lambda x: Sentiment_predictions_huggin_face(x = str(x), sentiment_task=sentiment_task_model_loaded))\n",
    "    name_for_csv_table_i = name_for_csv_table + \"_\" + str(i+1) +\".csv\"\n",
    "    sub_group_i.to_csv(os.path.join(data_folder_name_for_sentiment, name_for_csv_table_i))\n",
    "\n",
    "    \n",
    "warnings.filterwarnings('default') #retrieve warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1ae8901b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-21T09:52:05.371679Z",
     "start_time": "2022-06-21T09:52:05.362714Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "979821"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_table_all.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3244fc1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

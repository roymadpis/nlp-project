{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "469f58ef",
   "metadata": {},
   "source": [
    "## Step 4 - Sentiment Analysis labels\n",
    "\n",
    "#### In this notebook we:\n",
    "a. read the data_folder/tweets_table_all.csv - this is a table with ~1M tweets, containing tweets of KOL ad tweets of brexit from 2014-2021. It is a table **without sentiment**\n",
    "\n",
    "b. Import the fine-tuned sentiment model - from the location: Brexit_sentiment_model\n",
    "\n",
    "c. We use the sentiment model to give sentiment-prediction-labels to the ~1M tweets (from a)\n",
    "We save the labeled data frame in the following location:  data_folder/tweets_table_all_with_sentimet.csv \n",
    "We will use that table in step 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "440ca6d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-01T09:38:40.284576Z",
     "start_time": "2022-07-01T09:38:31.737805Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will be training on cpu\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "import gensim, logging, pandas as pd\n",
    "import numpy as np, matplotlib.pyplot as plt, os\n",
    "import pandas as pd\n",
    "import json, zipfile\n",
    "import torch\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "from transformers import pipeline\n",
    "from scipy.special import softmax\n",
    "from transformers import AutoTokenizer, AutoConfig\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else \"cpu\") \n",
    "print(f\"Will be training on {device}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9e00ef",
   "metadata": {},
   "source": [
    "### 4.a Reading tweets_table_all (~1M tweets)\n",
    "read the data_folder/tweets_table_all.csv - this is a table with ~1M tweets, containing tweets of KOL ad tweets of brexit from 2014-2021. It is a table without sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f785ad7a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-01T09:38:58.094710Z",
     "start_time": "2022-07-01T09:38:40.293152Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roymad\\AppData\\Local\\Temp\\ipykernel_37864\\4151046788.py:1: DtypeWarning: Columns (13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  tweets_table_all = pd.read_csv(\"data_folder/tweets_table_all.csv\")\n"
     ]
    }
   ],
   "source": [
    "tweets_table_all = pd.read_csv(\"data_folder/tweets_table_all.csv\")\n",
    "tweets_table_all = tweets_table_all.drop(labels = [\"Unnamed: 0\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62341b7e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-01T09:40:16.538129Z",
     "start_time": "2022-07-01T09:40:16.524613Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rt downingstreet more than untries places in the uk more than meetings with world leaders here are some of pm ther'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_table_all.text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e1d85c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-01T09:40:06.512429Z",
     "start_time": "2022-07-01T09:40:06.250297Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roymad\\AppData\\Local\\Temp\\ipykernel_37864\\1205794096.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tweets_table_all.text[0] = remove_words(tweets_table_all.text[0], bad_words)\n"
     ]
    }
   ],
   "source": [
    "def remove_words(my_str, list_words_to_remove):\n",
    "    for x in list_words_to_remove:\n",
    "        my_str = my_str.replace(x,'')\n",
    "    return my_str\n",
    "\n",
    "bad_words = [\"co\", \"https\", \"bkbdwz\", 'swh']\n",
    "\n",
    "tweets_table_all.text[0] = remove_words(tweets_table_all.text[0], bad_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7159bcd2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-01T09:40:31.774292Z",
     "start_time": "2022-07-01T09:40:31.760968Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rt gavinwilliamson want to thank all those serving in the britisharmy royalnavy and royalairforce for all the work they have done ov'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_table_all.text[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6beab823",
   "metadata": {},
   "source": [
    "### 4.b Using the sentiment model that we fine-tuned on Step 3 to make sentiment analysis predictions\n",
    "Import the fine-tuned sentiment model - from the location: Brexit_sentiment_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c0da453",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-01T09:39:21.212953Z",
     "start_time": "2022-07-01T09:38:59.588834Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import os.path\n",
    "name_dir_to_save_model = \"Brexit_sentiment_model_new\" #The name of the foler containing the fine-tuned sentiment model\n",
    "\n",
    "# try:\n",
    "#     os.makedirs(name_dir_to_save_model)\n",
    "#     print(\"Creating directory\", name_dir_to_save_model, \" to save the sentiment analysis model\")\n",
    "# except:\n",
    "#     print(\"The dir: \", name_dir_to_save_model, \"already exists\")\n",
    "# ### saving the model we re-trained\n",
    "\n",
    "### if you wosh to read the saved model:\n",
    "sentiment_task_example = pipeline(\"sentiment-analysis\",\n",
    "model = \"cardiffnlp/twitter-roberta-base-sentiment-latest\", \n",
    "tokenizer = \"cardiffnlp/twitter-roberta-base-sentiment-latest\")\n",
    "\n",
    "model_loaded = sentiment_task_example.model.from_pretrained(name_dir_to_save_model)\n",
    "\n",
    "sentiment_task_model_loaded = pipeline(\"sentiment-analysis\",\n",
    "model = model_loaded, \n",
    "tokenizer = \"cardiffnlp/twitter-roberta-base-sentiment-latest\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9767f644",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-01T09:39:32.816952Z",
     "start_time": "2022-07-01T09:39:21.789478Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "sentiment_task_model_loaded = pipeline(\"sentiment-analysis\",\n",
    "model = \"cardiffnlp/twitter-roberta-base-sentiment-latest\", \n",
    "tokenizer = \"cardiffnlp/twitter-roberta-base-sentiment-latest\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d1a14d45",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-01T09:40:37.826661Z",
     "start_time": "2022-07-01T09:40:37.686280Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'Neutral', 'score': 0.8567432761192322}]\n",
      "[{'label': 'Positive', 'score': 0.9615033268928528}]\n"
     ]
    }
   ],
   "source": [
    "print(sentiment_task_model_loaded(tweets_table_all.text[0]))\n",
    "print(sentiment_task_model_loaded(\"I love pizza\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0ce616",
   "metadata": {},
   "source": [
    "### Defining function for getting the sentiment from all the tweets\n",
    "\n",
    "+ if you define yourself the \"sentiment task\" object then you can save a lot of time!\n",
    " sentiment_task = pipeline(\"sentiment-analysis\", model = model, #this is the model we re-trained\n",
    "            tokenizer = \"cardiffnlp/twitter-roberta-base-sentiment-latest\")\n",
    "\n",
    "+ x = the text to classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b22390d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-01T09:40:40.106961Z",
     "start_time": "2022-07-01T09:40:40.096728Z"
    }
   },
   "outputs": [],
   "source": [
    "def Sentiment_predictions_huggin_face(x, sentiment_task = None, re_trained_model = None, \n",
    "tokenizer = \"cardiffnlp/twitter-roberta-base-sentiment-latest\"):\n",
    "\n",
    "    if sentiment_task is None:\n",
    "        sentiment_task = pipeline(\"sentiment-analysis\",\n",
    "            model = re_trained_model, #this is the model we re-trained\n",
    "            tokenizer = tokenizer)\n",
    "\n",
    "    prediction_score = sentiment_task(x)\n",
    "    prediction = prediction_score[0][\"label\"]\n",
    "    return (prediction)\n",
    "\n",
    "### this functions alows making a column iwth the score of the sentiment model for the prediciton\n",
    "def Sentiment_score_predictions_huggin_face(x, sentiment_task = None, re_trained_model = None, \n",
    "    tokenizer = \"cardiffnlp/twitter-roberta-base-sentiment-latest\"):\n",
    "\n",
    "    if sentiment_task is None:\n",
    "        sentiment_task = pipeline(\"sentiment-analysis\",\n",
    "            model = re_trained_model, #this is the model we re-trained\n",
    "            tokenizer = tokenizer)\n",
    "\n",
    "    prediction_score = sentiment_task(x)\n",
    "    score = prediction_score[0][\"score\"]\n",
    "    return (score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9d5703bb",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'str' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/michaelkobaivanov/Documents/MyIDC/year3/Semester6/NLP/nlp-project/Step_4_Sentiment_labels.ipynb Cell 13'\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/michaelkobaivanov/Documents/MyIDC/year3/Semester6/NLP/nlp-project/Step_4_Sentiment_labels.ipynb#ch0000026?line=0'>1</a>\u001b[0m retrained_model \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mcardiffnlp/twitter-roberta-base-sentiment-latest\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/michaelkobaivanov/Documents/MyIDC/year3/Semester6/NLP/nlp-project/Step_4_Sentiment_labels.ipynb#ch0000026?line=2'>3</a>\u001b[0m Sentiment_predictions_huggin_face(tweets_table_all\u001b[39m.\u001b[39;49mtext[\u001b[39m0\u001b[39;49m], retrained_model )\n",
      "\u001b[1;32m/Users/michaelkobaivanov/Documents/MyIDC/year3/Semester6/NLP/nlp-project/Step_4_Sentiment_labels.ipynb Cell 12'\u001b[0m in \u001b[0;36mSentiment_predictions_huggin_face\u001b[0;34m(x, sentiment_task, re_trained_model, tokenizer)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/michaelkobaivanov/Documents/MyIDC/year3/Semester6/NLP/nlp-project/Step_4_Sentiment_labels.ipynb#ch0000007?line=3'>4</a>\u001b[0m \u001b[39mif\u001b[39;00m sentiment_task \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/michaelkobaivanov/Documents/MyIDC/year3/Semester6/NLP/nlp-project/Step_4_Sentiment_labels.ipynb#ch0000007?line=4'>5</a>\u001b[0m     sentiment_task \u001b[39m=\u001b[39m pipeline(\u001b[39m\"\u001b[39m\u001b[39msentiment-analysis\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/michaelkobaivanov/Documents/MyIDC/year3/Semester6/NLP/nlp-project/Step_4_Sentiment_labels.ipynb#ch0000007?line=5'>6</a>\u001b[0m         model \u001b[39m=\u001b[39m re_trained_model, \u001b[39m#this is the model we re-trained\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/michaelkobaivanov/Documents/MyIDC/year3/Semester6/NLP/nlp-project/Step_4_Sentiment_labels.ipynb#ch0000007?line=6'>7</a>\u001b[0m         tokenizer \u001b[39m=\u001b[39m tokenizer)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/michaelkobaivanov/Documents/MyIDC/year3/Semester6/NLP/nlp-project/Step_4_Sentiment_labels.ipynb#ch0000007?line=8'>9</a>\u001b[0m prediction_score \u001b[39m=\u001b[39m sentiment_task(x)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/michaelkobaivanov/Documents/MyIDC/year3/Semester6/NLP/nlp-project/Step_4_Sentiment_labels.ipynb#ch0000007?line=9'>10</a>\u001b[0m prediction \u001b[39m=\u001b[39m prediction_score[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/michaelkobaivanov/Documents/MyIDC/year3/Semester6/NLP/nlp-project/Step_4_Sentiment_labels.ipynb#ch0000007?line=10'>11</a>\u001b[0m \u001b[39mreturn\u001b[39;00m (prediction)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'str' object is not callable"
     ]
    }
   ],
   "source": [
    "retrained_model = \"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    "\n",
    "Sentiment_predictions_huggin_face(tweets_table_all.text[0], retrained_model )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "30af21ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-01T09:40:46.444665Z",
     "start_time": "2022-07-01T09:40:46.351707Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Neutral'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sentiment_predictions_huggin_face(tweets_table_all.text[0], sentiment_task_model_loaded )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "05be5b2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'Negative', 'score': 0.8502446413040161}]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_task_example(tweets_table_all.text[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9234cbb0",
   "metadata": {},
   "source": [
    "## 4.c Predicting the sentiment of all the tweets\n",
    "Now that we have our trained sentiment analysis model, we wish to use it to label all the tweets we have with sentiment label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8027c502",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-19T08:18:27.216673Z",
     "start_time": "2022-06-19T08:18:27.193724Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#tweets_table_all[\"Predicted_sentiment\"] = tweets_table_all[\"text\"].apply(lambda x: Sentiment_predictions_huggin_face(x = x, sentiment_task=sentiment_task_model_loaded))\n",
    "#tweets_table_all[\"Predicted_sentiment_score\"] = tweets_table_all[\"text\"].apply(lambda x: Sentiment_predictions_huggin_face(x = x, sentiment_task=sentiment_task_model_loaded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aacefff6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-24T12:38:00.038648Z",
     "start_time": "2022-06-24T12:38:00.025759Z"
    }
   },
   "outputs": [],
   "source": [
    "data_folder_name = \"data_folder\"\n",
    "#tweets_table_all.to_csv(os.path.join(data_folder_name, \"tweets_table_all_with_sentimet.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7768085",
   "metadata": {},
   "source": [
    "## As we have so many tweets, it is very heavy to run the sentiment model on all of them together, so we will perform the labeling task in batches\n",
    "\n",
    "Creating a directory to store all the mini-csv tables with the sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6ed5f820",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-01T09:40:50.993372Z",
     "start_time": "2022-07-01T09:40:50.979761Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating directory data_folder\\Predicted_sentiment_tables_new  to save the sentiment predicted labels\n"
     ]
    }
   ],
   "source": [
    "data_folder_name = \"data_folder\"\n",
    "data_folder_name_for_sentiment = os.path.join(data_folder_name, \"Predicted_sentiment_tables_new\")\n",
    "try:\n",
    "    os.makedirs(data_folder_name_for_sentiment)\n",
    "    print(\"Creating directory\", data_folder_name_for_sentiment, \" to save the sentiment predicted labels\")\n",
    "except:\n",
    "    print(\"The dir: \", data_folder_name_for_sentiment, \"already exists\")\n",
    "### saving the model we re-trained\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59042377",
   "metadata": {},
   "outputs": [],
   "source": [
    "### creating smaller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "38202e6f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-19T08:19:19.543520Z",
     "start_time": "2022-06-19T08:19:19.504369Z"
    }
   },
   "outputs": [],
   "source": [
    "#tweets_table_all[\"index_num\"] = tweets_table_all.index\n",
    "#smaller_tweets_table_all = tweets_table_all[[\"index_num\",\"id\", \"text\"]]\n",
    "#smaller_tweets_table_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e59c867a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-01T09:40:56.303735Z",
     "start_time": "2022-07-01T09:40:56.186255Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tweets: 979821\n",
      "Number or rows in each group: 9798.2\n"
     ]
    }
   ],
   "source": [
    "num_of_rows = tweets_table_all.shape[0]\n",
    "print(\"Total number of tweets:\", num_of_rows)\n",
    "num_groups = 100\n",
    "print(\"Number or rows in each group:\", round(num_of_rows/num_groups,1))\n",
    "split_groups = np.array_split(range(num_of_rows), num_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aca1190",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in tqdm_notebook(range(len(split_groups))):\n",
    "#     group_i = split_groups[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f721a1",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-07-01T09:41:00.249Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c07abf796dd84ffb8646c9d58a50874c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore') #ignore warning messages\n",
    "\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "name_for_csv_table = \"A_new_tweets_table_with_sentiment_num\"\n",
    "\n",
    "for i in tqdm_notebook(range(len(split_groups))):\n",
    "    group_i = split_groups[i]\n",
    "    sub_group_i = tweets_table_all.iloc[group_i]\n",
    "    sub_group_i = sub_group_i.dropna(subset=['text']) #dropping tweets with na in the text\n",
    "    sub_group_i[\"Predicted_sentiment\"] = sub_group_i[\"text\"].apply(lambda x: Sentiment_predictions_huggin_face(x = str(x), sentiment_task=sentiment_task_model_loaded))\n",
    "    name_for_csv_table_i = name_for_csv_table + \"_\" + str(i+1) +\".csv\"\n",
    "    sub_group_i.to_csv(os.path.join(data_folder_name_for_sentiment, name_for_csv_table_i))\n",
    "\n",
    "    \n",
    "warnings.filterwarnings('default') #retrieve warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1ae8901b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-21T09:52:05.371679Z",
     "start_time": "2022-06-21T09:52:05.362714Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "979821"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_table_all.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3244fc1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "eda7ed194a66a72c4c72d3b14b8a6edab256c80249ed585739e6a2e1040b899d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51bd41b4",
   "metadata": {},
   "source": [
    "# Step_6_Visualizing_Word2Vec and Sentiment Analysis\n",
    "### Roy Madpis (319091526) And Michael Kobaivanov (206814485)\n",
    "\n",
    "In this notebook we use all the data we collected so far to collect insights regarding the Brexit issue.\n",
    "    \n",
    "### 1. Sentiment Analysis\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c688cd6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-18T06:12:13.332063Z",
     "start_time": "2022-06-18T06:12:00.407029Z"
    }
   },
   "outputs": [],
   "source": [
    "#! pip3 freeze > roy_libs1.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c92e6eec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-18T16:38:44.208960Z",
     "start_time": "2022-06-18T16:38:40.687920Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Invalid requirement: '#'\n"
     ]
    }
   ],
   "source": [
    "#! pip install --trusted-host=pypi.org --trusted-host=files.pythonhosted.org --user gensim\n",
    "#! pip install dask\n",
    "#! pip install tabulate\n",
    "#! pip install nltk\n",
    "#! pip install langid # for language detection\n",
    "# ! pip install contractions #for cleaning the text - converting abbriviations to long text for example\n",
    "\n",
    "### downloading the 4.5M tweets with sentiment\n",
    "#! curl --remote-name-all https://www.clarin.si/repository/xmlui/bitstream/handle/11356/1135{/Brexit_tweets_stance.zip}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e0f9082",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-24T09:42:48.610907Z",
     "start_time": "2022-06-24T09:42:42.859158Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\roymad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd, numpy as np, os\n",
    "import seaborn as sns\n",
    "\n",
    "import os.path\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "import psutil\n",
    "import sys, requests\n",
    "import time, datetime\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from dask import dataframe as dd\n",
    "import collections\n",
    "from collections import Counter\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "\n",
    "#for readin zip files\n",
    "import zipfile\n",
    "import bz2\n",
    "import itertools\n",
    "import codecs\n",
    "import io\n",
    "\n",
    "import pickle\n",
    "from scipy import spatial\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import gensim\n",
    "import inspect\n",
    "import contractions\n",
    "import langid #for language detection\n",
    "#import logging\n",
    "#logging.basicConfig(format ='%(asctime)s: %(levelname)s: %(message)s', level = logging.ERROR)\n",
    "\n",
    "#stopwords\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "\n",
    "\n",
    "#####################################\n",
    "data_folder = \"data_folder\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5bd1c2b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-24T09:43:16.656880Z",
     "start_time": "2022-06-24T09:43:16.648479Z"
    }
   },
   "outputs": [],
   "source": [
    "### reading the stopwords file / downloading it and add some more stopwords\n",
    "\n",
    "stopwords_file_name =  os.path.join(data_folder, \"StopWords\")\n",
    "stopwords_url = \"https://gist.githubusercontent.com/sebleier/554280/raw/7e0e4a1ce04c2bb7bd41089c9821dbcf6d0c786c/NLTK's%2520list%2520of%2520english%2520stopwords\"\n",
    "\n",
    "\n",
    "stop_words_to_add = [\"http\", \"https\", \"rt\", \"co\", \"vrkhaxde\", \"oeblog\", \"rln\", \"simonjhix\", \"cctvqfr\",\n",
    "\"dcpj\", \"xvy\", \"mycekvwlxr\", \"imydbvvwji\", \"kkd\", \"rwp\",\"yfc\",\"fus\",\"tmawgoafhb\",\"edzmidvpel\", \"brexit.\", \"brexit,\",\n",
    "\"xmljwysih\", \"lnfgc\", \"https//t.co/gx1lpjz5ux\", \"gvabanwvhi\", \"fmgynqxrs\", \"https//t.co/zpwcyltwgk\", \"https//t.co/eacccme91i\",\n",
    "\"https//t.co/memxwp57du\", \"https//t.co/kgjzyab6vu\", \"vxpgogryp\", \"https//t.co/l7cfc70l1w\"] ### add more stopwords you want\n",
    "#################################################################\n",
    "if not os.path.isfile(stopwords_file_name):\n",
    "    StopWords = requests.get(stopwords_url).text.split()\n",
    "    with open(stopwords_file_name,'w+t', encoding='utf-8') as out_file:\n",
    "        out_file.write(' '.join(StopWords))\n",
    "else:\n",
    "    with open(stopwords_file_name,'rt', encoding='utf-8') as in_file:\n",
    "        StopWords = in_file.readline().split()\n",
    "StopWords = set(StopWords)\n",
    "\n",
    "for word_i in stop_words_to_add:\n",
    "    StopWords.add(word_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8acdd298",
   "metadata": {},
   "source": [
    "## 5.1.a Reading Key Opinion leaders tweets:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d6daf2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-13T11:45:07.556334Z",
     "start_time": "2022-05-13T11:45:07.543193Z"
    }
   },
   "source": [
    "a. We split the ~1M tweets data (data_folder/tweets_table_all_with_sentimet.csv) by the year the tweet was published, train a Word2Vec model for each year alone (thus have word2vec model that was trained on tweets from 2014 / model that was trained on tweets from 2015, etc) we also have one Word2Vec model that was trained on all the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a92d09cb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-24T09:43:37.635212Z",
     "start_time": "2022-06-24T09:43:18.317781Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Reading all the csv files\n",
      "There are: 979801 Tweets\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_id</th>\n",
       "      <th>author_id_new</th>\n",
       "      <th>conv_id_new</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>entities.mentions</th>\n",
       "      <th>id</th>\n",
       "      <th>id_new</th>\n",
       "      <th>public_metrics.like_count</th>\n",
       "      <th>public_metrics.quote_count</th>\n",
       "      <th>...</th>\n",
       "      <th>users.public_metrics.followers_count</th>\n",
       "      <th>users.public_metrics.following_count</th>\n",
       "      <th>users.public_metrics.listed_count</th>\n",
       "      <th>users.public_metrics.tweet_count</th>\n",
       "      <th>users.username</th>\n",
       "      <th>users.verified</th>\n",
       "      <th>text_tokens</th>\n",
       "      <th>created_at_date</th>\n",
       "      <th>Year_tweet</th>\n",
       "      <th>Predicted_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>76650839</td>\n",
       "      <td>author_id: 76650839</td>\n",
       "      <td>conv_id: 1079747729419657217</td>\n",
       "      <td>1079747729419657217</td>\n",
       "      <td>2018-12-31T14:34:54.000Z</td>\n",
       "      <td>[{'start': 3, 'end': 19, 'username': '10Downin...</td>\n",
       "      <td>1079747729419657217</td>\n",
       "      <td>id: 1079747729419657217</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>14060</td>\n",
       "      <td>2210</td>\n",
       "      <td>654</td>\n",
       "      <td>10740</td>\n",
       "      <td>AlunCairns</td>\n",
       "      <td>True</td>\n",
       "      <td>['downingstreet', 'countries', 'places', 'uk',...</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>2018</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>76650839</td>\n",
       "      <td>author_id: 76650839</td>\n",
       "      <td>conv_id: 1079747690110570496</td>\n",
       "      <td>1079747690110570496</td>\n",
       "      <td>2018-12-31T14:34:44.000Z</td>\n",
       "      <td>[{'start': 3, 'end': 19, 'username': 'GavinWil...</td>\n",
       "      <td>1079747690110570496</td>\n",
       "      <td>id: 1079747690110570496</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>14060</td>\n",
       "      <td>2210</td>\n",
       "      <td>654</td>\n",
       "      <td>10740</td>\n",
       "      <td>AlunCairns</td>\n",
       "      <td>True</td>\n",
       "      <td>['gavinwilliamson', 'want_thank', 'serving', '...</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>2018</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>76650839</td>\n",
       "      <td>author_id: 76650839</td>\n",
       "      <td>conv_id: 1078943309744070657</td>\n",
       "      <td>1078943309744070657</td>\n",
       "      <td>2018-12-29T09:18:25.000Z</td>\n",
       "      <td>[{'start': 3, 'end': 14, 'username': 'UKGovWal...</td>\n",
       "      <td>1078943309744070657</td>\n",
       "      <td>id: 1078943309744070657</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>14060</td>\n",
       "      <td>2210</td>\n",
       "      <td>654</td>\n",
       "      <td>10740</td>\n",
       "      <td>AlunCairns</td>\n",
       "      <td>True</td>\n",
       "      <td>['ukgovwales_welsh_secretary_aluncairns', 'ext...</td>\n",
       "      <td>2018-12-29</td>\n",
       "      <td>2018</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>76650839</td>\n",
       "      <td>author_id: 76650839</td>\n",
       "      <td>conv_id: 1078738567193640960</td>\n",
       "      <td>1078738567193640960</td>\n",
       "      <td>2018-12-28T19:58:04.000Z</td>\n",
       "      <td>[{'start': 0, 'end': 13, 'username': 'TicketTa...</td>\n",
       "      <td>1078741894761463809</td>\n",
       "      <td>id: 1078741894761463809</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>14060</td>\n",
       "      <td>2210</td>\n",
       "      <td>654</td>\n",
       "      <td>10740</td>\n",
       "      <td>AlunCairns</td>\n",
       "      <td>True</td>\n",
       "      <td>['tickettattle', 'tfwrail', 'sure', 'thing']</td>\n",
       "      <td>2018-12-28</td>\n",
       "      <td>2018</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>76650839</td>\n",
       "      <td>author_id: 76650839</td>\n",
       "      <td>conv_id: 1077967555879452672</td>\n",
       "      <td>1077967555879452672</td>\n",
       "      <td>2018-12-26T21:24:01.000Z</td>\n",
       "      <td>[{'start': 0, 'end': 13, 'username': 'WPL_Offi...</td>\n",
       "      <td>1078038748837888001</td>\n",
       "      <td>id: 1078038748837888001</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>14060</td>\n",
       "      <td>2210</td>\n",
       "      <td>654</td>\n",
       "      <td>10740</td>\n",
       "      <td>AlunCairns</td>\n",
       "      <td>True</td>\n",
       "      <td>['wpl_official', 'barrytownunited', 'the_nomad...</td>\n",
       "      <td>2018-12-26</td>\n",
       "      <td>2018</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   author_id        author_id_new                   conv_id_new  \\\n",
       "0   76650839  author_id: 76650839  conv_id: 1079747729419657217   \n",
       "1   76650839  author_id: 76650839  conv_id: 1079747690110570496   \n",
       "2   76650839  author_id: 76650839  conv_id: 1078943309744070657   \n",
       "3   76650839  author_id: 76650839  conv_id: 1078738567193640960   \n",
       "4   76650839  author_id: 76650839  conv_id: 1077967555879452672   \n",
       "\n",
       "       conversation_id                created_at  \\\n",
       "0  1079747729419657217  2018-12-31T14:34:54.000Z   \n",
       "1  1079747690110570496  2018-12-31T14:34:44.000Z   \n",
       "2  1078943309744070657  2018-12-29T09:18:25.000Z   \n",
       "3  1078738567193640960  2018-12-28T19:58:04.000Z   \n",
       "4  1077967555879452672  2018-12-26T21:24:01.000Z   \n",
       "\n",
       "                                   entities.mentions                   id  \\\n",
       "0  [{'start': 3, 'end': 19, 'username': '10Downin...  1079747729419657217   \n",
       "1  [{'start': 3, 'end': 19, 'username': 'GavinWil...  1079747690110570496   \n",
       "2  [{'start': 3, 'end': 14, 'username': 'UKGovWal...  1078943309744070657   \n",
       "3  [{'start': 0, 'end': 13, 'username': 'TicketTa...  1078741894761463809   \n",
       "4  [{'start': 0, 'end': 13, 'username': 'WPL_Offi...  1078038748837888001   \n",
       "\n",
       "                    id_new  public_metrics.like_count  \\\n",
       "0  id: 1079747729419657217                          0   \n",
       "1  id: 1079747690110570496                          0   \n",
       "2  id: 1078943309744070657                          0   \n",
       "3  id: 1078741894761463809                          1   \n",
       "4  id: 1078038748837888001                          3   \n",
       "\n",
       "   public_metrics.quote_count  ...  users.public_metrics.followers_count  \\\n",
       "0                           0  ...                                 14060   \n",
       "1                           0  ...                                 14060   \n",
       "2                           0  ...                                 14060   \n",
       "3                           0  ...                                 14060   \n",
       "4                           0  ...                                 14060   \n",
       "\n",
       "   users.public_metrics.following_count users.public_metrics.listed_count  \\\n",
       "0                                  2210                               654   \n",
       "1                                  2210                               654   \n",
       "2                                  2210                               654   \n",
       "3                                  2210                               654   \n",
       "4                                  2210                               654   \n",
       "\n",
       "  users.public_metrics.tweet_count users.username users.verified  \\\n",
       "0                            10740     AlunCairns           True   \n",
       "1                            10740     AlunCairns           True   \n",
       "2                            10740     AlunCairns           True   \n",
       "3                            10740     AlunCairns           True   \n",
       "4                            10740     AlunCairns           True   \n",
       "\n",
       "                                         text_tokens created_at_date  \\\n",
       "0  ['downingstreet', 'countries', 'places', 'uk',...      2018-12-31   \n",
       "1  ['gavinwilliamson', 'want_thank', 'serving', '...      2018-12-31   \n",
       "2  ['ukgovwales_welsh_secretary_aluncairns', 'ext...      2018-12-29   \n",
       "3       ['tickettattle', 'tfwrail', 'sure', 'thing']      2018-12-28   \n",
       "4  ['wpl_official', 'barrytownunited', 'the_nomad...      2018-12-26   \n",
       "\n",
       "   Year_tweet  Predicted_sentiment  \n",
       "0        2018              Neutral  \n",
       "1        2018             Positive  \n",
       "2        2018             Positive  \n",
       "3        2018              Neutral  \n",
       "4        2018             Positive  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir_with_all_tweets = os.path.join(data_folder,\"Predicted_sentiment_tables\")\n",
    "\n",
    "print(\"Step 1: Reading all the csv files\")\n",
    "tweets_tables = []\n",
    "csv_files_evaluated = []\n",
    "for root,dirs,files in os.walk(dir_with_all_tweets):\n",
    "    for file in files:\n",
    "        if file.endswith(\".csv\"): #if the file is csv\n",
    "            csv_files_evaluated.append(file)\n",
    "            file_location = os.path.join(dir_with_all_tweets, file)\n",
    "            tweets_tables.append(pd.read_csv(file_location))\n",
    "\n",
    "tweets_table_all_with_sentimet_0 = pd.concat(tweets_tables)\n",
    "print(\"There are:\", tweets_table_all_with_sentimet_0.shape[0], \"Tweets\")\n",
    "\n",
    "tweets_table_all_with_sentimet_0 = tweets_table_all_with_sentimet_0.drop(labels = [\"Unnamed: 0\", \"index_num\"], axis = 1)\n",
    "tweets_table_all_with_sentimet_0.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eecd615",
   "metadata": {},
   "source": [
    "### Reading the table with 300k tweets with sentiments\n",
    "This is the data that we read from twitter using th tweet-ids) [this data is out of the corpus of 4.5M tweet-ids with sentiment]\n",
    "\n",
    "We need to preprocess that table so it would be in the same format and shape as the table we have above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b7e2837",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-24T09:43:44.795276Z",
     "start_time": "2022-06-24T09:43:39.181225Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Reading all the csv files\n",
      "There are: 312735 Tweets\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_id</th>\n",
       "      <th>author_id_new</th>\n",
       "      <th>conv_id_new</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>entities.mentions</th>\n",
       "      <th>id</th>\n",
       "      <th>id_new</th>\n",
       "      <th>public_metrics.like_count</th>\n",
       "      <th>public_metrics.quote_count</th>\n",
       "      <th>...</th>\n",
       "      <th>users.public_metrics.followers_count</th>\n",
       "      <th>users.public_metrics.following_count</th>\n",
       "      <th>users.public_metrics.listed_count</th>\n",
       "      <th>users.public_metrics.tweet_count</th>\n",
       "      <th>users.username</th>\n",
       "      <th>users.verified</th>\n",
       "      <th>Predicted_sentiment</th>\n",
       "      <th>text_tokens</th>\n",
       "      <th>created_at_date</th>\n",
       "      <th>Year_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>137099503</td>\n",
       "      <td>author_id: 137099503</td>\n",
       "      <td>conv_id: 730759365142167552</td>\n",
       "      <td>730759365142167552</td>\n",
       "      <td>2016-05-12T13:59:44.000Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>730759365142167552</td>\n",
       "      <td>id: 730759365142167552</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>463</td>\n",
       "      <td>71</td>\n",
       "      <td>18</td>\n",
       "      <td>22398</td>\n",
       "      <td>FonyBlair</td>\n",
       "      <td>False</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-05-12</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>367718336</td>\n",
       "      <td>author_id: 367718336</td>\n",
       "      <td>conv_id: 730759317884915712</td>\n",
       "      <td>730759317884915712</td>\n",
       "      <td>2016-05-12T13:59:32.000Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>730759317884915712</td>\n",
       "      <td>id: 730759317884915712</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3623</td>\n",
       "      <td>5000</td>\n",
       "      <td>433</td>\n",
       "      <td>301390</td>\n",
       "      <td>janicemorphet</td>\n",
       "      <td>False</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-05-12</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1299769218</td>\n",
       "      <td>author_id: 1299769218</td>\n",
       "      <td>conv_id: 730759295478960129</td>\n",
       "      <td>730759295478960129</td>\n",
       "      <td>2016-05-12T13:59:27.000Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>730759295478960129</td>\n",
       "      <td>id: 730759295478960129</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>558874</td>\n",
       "      <td>359</td>\n",
       "      <td>1630</td>\n",
       "      <td>81943</td>\n",
       "      <td>KayBurley</td>\n",
       "      <td>True</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-05-12</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2772884435</td>\n",
       "      <td>author_id: 2772884435</td>\n",
       "      <td>conv_id: 730759278630424577</td>\n",
       "      <td>730759278630424577</td>\n",
       "      <td>2016-05-12T13:59:23.000Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>730759278630424577</td>\n",
       "      <td>id: 730759278630424577</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1206</td>\n",
       "      <td>1415</td>\n",
       "      <td>25</td>\n",
       "      <td>31524</td>\n",
       "      <td>ernieharding59</td>\n",
       "      <td>False</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-05-12</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2867356894</td>\n",
       "      <td>author_id: 2867356894</td>\n",
       "      <td>conv_id: 730759264386617344</td>\n",
       "      <td>730759264386617344</td>\n",
       "      <td>2016-05-12T13:59:20.000Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>730759264386617344</td>\n",
       "      <td>id: 730759264386617344</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2922</td>\n",
       "      <td>2474</td>\n",
       "      <td>122</td>\n",
       "      <td>64418</td>\n",
       "      <td>CandiSpillard</td>\n",
       "      <td>False</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-05-12</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    author_id          author_id_new                  conv_id_new  \\\n",
       "0   137099503   author_id: 137099503  conv_id: 730759365142167552   \n",
       "1   367718336   author_id: 367718336  conv_id: 730759317884915712   \n",
       "2  1299769218  author_id: 1299769218  conv_id: 730759295478960129   \n",
       "3  2772884435  author_id: 2772884435  conv_id: 730759278630424577   \n",
       "4  2867356894  author_id: 2867356894  conv_id: 730759264386617344   \n",
       "\n",
       "      conversation_id                created_at  entities.mentions  \\\n",
       "0  730759365142167552  2016-05-12T13:59:44.000Z                NaN   \n",
       "1  730759317884915712  2016-05-12T13:59:32.000Z                NaN   \n",
       "2  730759295478960129  2016-05-12T13:59:27.000Z                NaN   \n",
       "3  730759278630424577  2016-05-12T13:59:23.000Z                NaN   \n",
       "4  730759264386617344  2016-05-12T13:59:20.000Z                NaN   \n",
       "\n",
       "                   id                  id_new  public_metrics.like_count  \\\n",
       "0  730759365142167552  id: 730759365142167552                          2   \n",
       "1  730759317884915712  id: 730759317884915712                          0   \n",
       "2  730759295478960129  id: 730759295478960129                          4   \n",
       "3  730759278630424577  id: 730759278630424577                          0   \n",
       "4  730759264386617344  id: 730759264386617344                          0   \n",
       "\n",
       "   public_metrics.quote_count  ...  users.public_metrics.followers_count  \\\n",
       "0                           0  ...                                   463   \n",
       "1                           0  ...                                  3623   \n",
       "2                           0  ...                                558874   \n",
       "3                           0  ...                                  1206   \n",
       "4                           0  ...                                  2922   \n",
       "\n",
       "   users.public_metrics.following_count users.public_metrics.listed_count  \\\n",
       "0                                    71                                18   \n",
       "1                                  5000                               433   \n",
       "2                                   359                              1630   \n",
       "3                                  1415                                25   \n",
       "4                                  2474                               122   \n",
       "\n",
       "  users.public_metrics.tweet_count  users.username users.verified  \\\n",
       "0                            22398       FonyBlair          False   \n",
       "1                           301390   janicemorphet          False   \n",
       "2                            81943       KayBurley           True   \n",
       "3                            31524  ernieharding59          False   \n",
       "4                            64418   CandiSpillard          False   \n",
       "\n",
       "   Predicted_sentiment text_tokens  created_at_date  Year_tweet  \n",
       "0              Neutral           0       2016-05-12        2016  \n",
       "1              Neutral           0       2016-05-12        2016  \n",
       "2              Neutral           0       2016-05-12        2016  \n",
       "3             Positive           0       2016-05-12        2016  \n",
       "4             Negative           0       2016-05-12        2016  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_folder_name_for_sentiment = \"data_folder/tweets_4_5M/tweet_ids_with_sentiment\"\n",
    "\n",
    "print(\"Step 1: Reading all the csv files\")\n",
    "tweets_tables = []\n",
    "csv_files_evaluated = []\n",
    "for root,dirs,files in os.walk(data_folder_name_for_sentiment):\n",
    "    for file in files:\n",
    "        if file.endswith(\".csv\"): #if the file is csv\n",
    "            csv_files_evaluated.append(file)\n",
    "            file_location = os.path.join(data_folder_name_for_sentiment, file)\n",
    "            tweets_tables.append(pd.read_csv(file_location))\n",
    "\n",
    "tweets_with_sentiment_300k = pd.concat(tweets_tables)\n",
    "print(\"There are:\", tweets_with_sentiment_300k.shape[0], \"Tweets\")\n",
    "\n",
    "### preprocess\n",
    "\n",
    "## change the sentiment column name\n",
    "tweets_with_sentiment_300k = tweets_with_sentiment_300k.rename({\"sentimnt\":\"Predicted_sentiment\"}, axis = 1)\n",
    "\n",
    "tweets_with_sentiment_300k[\"text_tokens\"] = 0\n",
    "\n",
    "def take_only_10_first_char(x):\n",
    "    return(x[0:10])\n",
    "tweets_with_sentiment_300k[\"created_at_date\"] = tweets_with_sentiment_300k[\"created_at\"].apply(take_only_10_first_char)\n",
    "tweets_with_sentiment_300k[\"created_at_date\"] = pd.to_datetime(tweets_with_sentiment_300k[\"created_at_date\"])\n",
    "\n",
    "tweets_with_sentiment_300k[\"Year_tweet\"] = pd.DatetimeIndex(tweets_with_sentiment_300k['created_at']).year\n",
    "tweets_with_sentiment_300k = tweets_with_sentiment_300k.drop(labels = [\"Unnamed: 0\",\"tweet_id\"], axis = 1)\n",
    "\n",
    "tweets_with_sentiment_300k.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ec4dfb1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-23T16:44:30.940204Z",
     "start_time": "2022-06-23T16:44:30.926803Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(979801, 28)\n",
      "(312735, 28)\n"
     ]
    }
   ],
   "source": [
    "print(tweets_table_all_with_sentimet_0.shape)\n",
    "print(tweets_with_sentiment_300k.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "293176b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-24T09:43:50.388288Z",
     "start_time": "2022-06-24T09:43:45.515386Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tweets with sentiment = 1292536\n",
      "Total number of tweets with sentiment not duplicate = 1285805\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_id</th>\n",
       "      <th>author_id_new</th>\n",
       "      <th>conv_id_new</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>entities.mentions</th>\n",
       "      <th>id</th>\n",
       "      <th>id_new</th>\n",
       "      <th>public_metrics.like_count</th>\n",
       "      <th>public_metrics.quote_count</th>\n",
       "      <th>...</th>\n",
       "      <th>users.public_metrics.followers_count</th>\n",
       "      <th>users.public_metrics.following_count</th>\n",
       "      <th>users.public_metrics.listed_count</th>\n",
       "      <th>users.public_metrics.tweet_count</th>\n",
       "      <th>users.username</th>\n",
       "      <th>users.verified</th>\n",
       "      <th>text_tokens</th>\n",
       "      <th>created_at_date</th>\n",
       "      <th>Year_tweet</th>\n",
       "      <th>Predicted_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>76650839</td>\n",
       "      <td>author_id: 76650839</td>\n",
       "      <td>conv_id: 1079747729419657217</td>\n",
       "      <td>1079747729419657217</td>\n",
       "      <td>2018-12-31T14:34:54.000Z</td>\n",
       "      <td>[{'start': 3, 'end': 19, 'username': '10Downin...</td>\n",
       "      <td>1079747729419657217</td>\n",
       "      <td>id: 1079747729419657217</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>14060</td>\n",
       "      <td>2210</td>\n",
       "      <td>654</td>\n",
       "      <td>10740</td>\n",
       "      <td>AlunCairns</td>\n",
       "      <td>True</td>\n",
       "      <td>['downingstreet', 'countries', 'places', 'uk',...</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>2018</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>76650839</td>\n",
       "      <td>author_id: 76650839</td>\n",
       "      <td>conv_id: 1079747690110570496</td>\n",
       "      <td>1079747690110570496</td>\n",
       "      <td>2018-12-31T14:34:44.000Z</td>\n",
       "      <td>[{'start': 3, 'end': 19, 'username': 'GavinWil...</td>\n",
       "      <td>1079747690110570496</td>\n",
       "      <td>id: 1079747690110570496</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>14060</td>\n",
       "      <td>2210</td>\n",
       "      <td>654</td>\n",
       "      <td>10740</td>\n",
       "      <td>AlunCairns</td>\n",
       "      <td>True</td>\n",
       "      <td>['gavinwilliamson', 'want_thank', 'serving', '...</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>2018</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>76650839</td>\n",
       "      <td>author_id: 76650839</td>\n",
       "      <td>conv_id: 1078943309744070657</td>\n",
       "      <td>1078943309744070657</td>\n",
       "      <td>2018-12-29T09:18:25.000Z</td>\n",
       "      <td>[{'start': 3, 'end': 14, 'username': 'UKGovWal...</td>\n",
       "      <td>1078943309744070657</td>\n",
       "      <td>id: 1078943309744070657</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>14060</td>\n",
       "      <td>2210</td>\n",
       "      <td>654</td>\n",
       "      <td>10740</td>\n",
       "      <td>AlunCairns</td>\n",
       "      <td>True</td>\n",
       "      <td>['ukgovwales_welsh_secretary_aluncairns', 'ext...</td>\n",
       "      <td>2018-12-29</td>\n",
       "      <td>2018</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>76650839</td>\n",
       "      <td>author_id: 76650839</td>\n",
       "      <td>conv_id: 1078738567193640960</td>\n",
       "      <td>1078738567193640960</td>\n",
       "      <td>2018-12-28T19:58:04.000Z</td>\n",
       "      <td>[{'start': 0, 'end': 13, 'username': 'TicketTa...</td>\n",
       "      <td>1078741894761463809</td>\n",
       "      <td>id: 1078741894761463809</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>14060</td>\n",
       "      <td>2210</td>\n",
       "      <td>654</td>\n",
       "      <td>10740</td>\n",
       "      <td>AlunCairns</td>\n",
       "      <td>True</td>\n",
       "      <td>['tickettattle', 'tfwrail', 'sure', 'thing']</td>\n",
       "      <td>2018-12-28</td>\n",
       "      <td>2018</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>76650839</td>\n",
       "      <td>author_id: 76650839</td>\n",
       "      <td>conv_id: 1077967555879452672</td>\n",
       "      <td>1077967555879452672</td>\n",
       "      <td>2018-12-26T21:24:01.000Z</td>\n",
       "      <td>[{'start': 0, 'end': 13, 'username': 'WPL_Offi...</td>\n",
       "      <td>1078038748837888001</td>\n",
       "      <td>id: 1078038748837888001</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>14060</td>\n",
       "      <td>2210</td>\n",
       "      <td>654</td>\n",
       "      <td>10740</td>\n",
       "      <td>AlunCairns</td>\n",
       "      <td>True</td>\n",
       "      <td>['wpl_official', 'barrytownunited', 'the_nomad...</td>\n",
       "      <td>2018-12-26</td>\n",
       "      <td>2018</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   author_id        author_id_new                   conv_id_new  \\\n",
       "0   76650839  author_id: 76650839  conv_id: 1079747729419657217   \n",
       "1   76650839  author_id: 76650839  conv_id: 1079747690110570496   \n",
       "2   76650839  author_id: 76650839  conv_id: 1078943309744070657   \n",
       "3   76650839  author_id: 76650839  conv_id: 1078738567193640960   \n",
       "4   76650839  author_id: 76650839  conv_id: 1077967555879452672   \n",
       "\n",
       "       conversation_id                created_at  \\\n",
       "0  1079747729419657217  2018-12-31T14:34:54.000Z   \n",
       "1  1079747690110570496  2018-12-31T14:34:44.000Z   \n",
       "2  1078943309744070657  2018-12-29T09:18:25.000Z   \n",
       "3  1078738567193640960  2018-12-28T19:58:04.000Z   \n",
       "4  1077967555879452672  2018-12-26T21:24:01.000Z   \n",
       "\n",
       "                                   entities.mentions                   id  \\\n",
       "0  [{'start': 3, 'end': 19, 'username': '10Downin...  1079747729419657217   \n",
       "1  [{'start': 3, 'end': 19, 'username': 'GavinWil...  1079747690110570496   \n",
       "2  [{'start': 3, 'end': 14, 'username': 'UKGovWal...  1078943309744070657   \n",
       "3  [{'start': 0, 'end': 13, 'username': 'TicketTa...  1078741894761463809   \n",
       "4  [{'start': 0, 'end': 13, 'username': 'WPL_Offi...  1078038748837888001   \n",
       "\n",
       "                    id_new  public_metrics.like_count  \\\n",
       "0  id: 1079747729419657217                          0   \n",
       "1  id: 1079747690110570496                          0   \n",
       "2  id: 1078943309744070657                          0   \n",
       "3  id: 1078741894761463809                          1   \n",
       "4  id: 1078038748837888001                          3   \n",
       "\n",
       "   public_metrics.quote_count  ...  users.public_metrics.followers_count  \\\n",
       "0                           0  ...                                 14060   \n",
       "1                           0  ...                                 14060   \n",
       "2                           0  ...                                 14060   \n",
       "3                           0  ...                                 14060   \n",
       "4                           0  ...                                 14060   \n",
       "\n",
       "   users.public_metrics.following_count users.public_metrics.listed_count  \\\n",
       "0                                  2210                               654   \n",
       "1                                  2210                               654   \n",
       "2                                  2210                               654   \n",
       "3                                  2210                               654   \n",
       "4                                  2210                               654   \n",
       "\n",
       "  users.public_metrics.tweet_count users.username users.verified  \\\n",
       "0                            10740     AlunCairns           True   \n",
       "1                            10740     AlunCairns           True   \n",
       "2                            10740     AlunCairns           True   \n",
       "3                            10740     AlunCairns           True   \n",
       "4                            10740     AlunCairns           True   \n",
       "\n",
       "                                         text_tokens created_at_date  \\\n",
       "0  ['downingstreet', 'countries', 'places', 'uk',...      2018-12-31   \n",
       "1  ['gavinwilliamson', 'want_thank', 'serving', '...      2018-12-31   \n",
       "2  ['ukgovwales_welsh_secretary_aluncairns', 'ext...      2018-12-29   \n",
       "3       ['tickettattle', 'tfwrail', 'sure', 'thing']      2018-12-28   \n",
       "4  ['wpl_official', 'barrytownunited', 'the_nomad...      2018-12-26   \n",
       "\n",
       "   Year_tweet  Predicted_sentiment  \n",
       "0        2018              Neutral  \n",
       "1        2018             Positive  \n",
       "2        2018             Positive  \n",
       "3        2018              Neutral  \n",
       "4        2018             Positive  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### combining the two tables into one big table\n",
    "tweets_table_all_with_sentimet = pd.concat([tweets_table_all_with_sentimet_0, tweets_with_sentiment_300k])\n",
    "print(\"Total number of tweets with sentiment =\", tweets_table_all_with_sentimet.shape[0])\n",
    "\n",
    "### remove duplicates\n",
    "tweets_table_all_with_sentimet = tweets_table_all_with_sentimet.drop_duplicates(subset=['author_id_new', 'conv_id_new', \"id_new\", \"created_at\", \"public_metrics.like_count\", \"text\"])\n",
    "print(\"Total number of tweets with sentiment not duplicate =\", tweets_table_all_with_sentimet.shape[0])\n",
    "\n",
    "tweets_table_all_with_sentimet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "964d0922",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-19T09:37:20.372677Z",
     "start_time": "2022-06-19T09:37:20.346645Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number or rows in each group: 9.8\n"
     ]
    }
   ],
   "source": [
    "# num_of_rows = tweets_table_all_with_sentimet.shape[0]\n",
    "# num_groups = 100\n",
    "# print(\"Number or rows in each group:\", round(num_of_rows/num_groups,1))\n",
    "# split_groups = np.array_split(range(num_of_rows), num_groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4651de2f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-27T13:16:57.560037Z",
     "start_time": "2022-05-27T13:16:57.518064Z"
    }
   },
   "source": [
    "### Preprocess the filtered tweets\n",
    "After we read the tweets filtered table, we need to perform several cleaning / preprocessing on those filtered tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6dc8fa6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-24T09:44:10.603912Z",
     "start_time": "2022-06-24T09:43:51.725814Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ba0a201f380475fac71cccb0fd667aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1285805 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# def clean_text(x):\n",
    "#     from gensim.utils import simple_preprocess\n",
    "#     import contractions\n",
    "#     x = contractions.fix(x)\n",
    "#     x = ' '.join(simple_preprocess(x))\n",
    "#     return x\n",
    "\n",
    "### Pre-processing columns conv_id_new and author_id_new\n",
    "tweets_table_all_with_sentimet['conversation_id'] = tweets_table_all_with_sentimet['conv_id_new'].apply(lambda x: x.replace(\"conv_id: \", \"\"))\n",
    "tweets_table_all_with_sentimet['author_id'] = tweets_table_all_with_sentimet['author_id_new'].apply(lambda x: x.replace(\"author_id: \", \"\"))\n",
    "#tweets_table_all_with_sentimet['clean_text'] = tweets_table_all_with_sentimet['text'].apply(clean_text)\n",
    "tweets_table_all_with_sentimet = tweets_table_all_with_sentimet[tweets_table_all_with_sentimet['text'].notna()] #remove rows with nan values in the text column\n",
    "\n",
    "tweets_table_all_with_sentimet['clean_text'] = tweets_table_all_with_sentimet['text']\n",
    "\n",
    "if \"Year_tweet\" in tweets_table_all_with_sentimet.columns:\n",
    "    years_tweets = tweets_table_all_with_sentimet.Year_tweet\n",
    "else:\n",
    "    years_tweets = pd.DatetimeIndex(tweets_table_all_with_sentimet['created_at_date']).year\n",
    "    tweets_table_all_with_sentimet[\"Year_tweet\"] = years_tweets\n",
    "### detecting the language of the text + preprocess it\n",
    "language_classifications = []\n",
    "tokens_roy = []\n",
    "years_tweets = []\n",
    "for row in tqdm_notebook(tweets_table_all_with_sentimet.clean_text): #tqdm_notebook - to pring progress bar\n",
    "    #language_classification, score = langid.classify(row)\n",
    "    #language_classifications.append(language_classification)\n",
    "\n",
    "    data_clean = row.lower().replace(\"#\", \"\").replace(\"@\", \"\").replace(\"?\", \"\").replace(\"\\\"\", \"\").replace(\"\\'\", \"\").replace(\":\", \"\")\n",
    "    data_clean = data_clean.split()\n",
    "    data_clean = [token for token in data_clean if token not in StopWords]\n",
    "    data_clean = [token for token in data_clean if len(token) >=2]\n",
    "    tokens_roy.append(data_clean) #\n",
    "\n",
    "texts = tweets_table_all_with_sentimet.text\n",
    "text_tokens = tweets_table_all_with_sentimet.text_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef432bf1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-17T07:14:45.115115Z",
     "start_time": "2022-06-17T07:14:45.111113Z"
    }
   },
   "outputs": [],
   "source": [
    "# if \"language\" in filtered_table.columns:\n",
    "#     language_classifications.append(language_classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6a12936",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-24T09:44:16.825598Z",
     "start_time": "2022-06-24T09:44:16.812477Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1285805\n"
     ]
    }
   ],
   "source": [
    "print(len(language_classifications))\n",
    "print(len(tokens_roy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7538c4ec",
   "metadata": {},
   "source": [
    "### splitting the tweets to the relevant years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa82ef3d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-24T09:44:21.518040Z",
     "start_time": "2022-06-24T09:44:21.505203Z"
    }
   },
   "outputs": [],
   "source": [
    "#years_tweets = pd.DatetimeIndex(tweets_table_all_with_sentimet['created_at_date']).year\n",
    "years_tweets = tweets_table_all_with_sentimet['Year_tweet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4fd7a2c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-24T09:44:27.125885Z",
     "start_time": "2022-06-24T09:44:27.066349Z"
    }
   },
   "outputs": [],
   "source": [
    "years_tweets_2014 = [years_tweets==2014]\n",
    "years_tweets_2014 = np.asarray(years_tweets_2014).reshape(-1,1)\n",
    "\n",
    "years_tweets_2015 = [years_tweets==2015]\n",
    "years_tweets_2015 = np.asarray(years_tweets_2015).reshape(-1,1)\n",
    "\n",
    "years_tweets_2016 = [years_tweets==2016]\n",
    "years_tweets_2016 = np.asarray(years_tweets_2016).reshape(-1,1)\n",
    "\n",
    "years_tweets_2017 = [years_tweets==2017]\n",
    "years_tweets_2017 = np.asarray(years_tweets_2017).reshape(-1,1)\n",
    "\n",
    "years_tweets_2018 = [years_tweets==2018]\n",
    "years_tweets_2018 = np.asarray(years_tweets_2018).reshape(-1,1)\n",
    "\n",
    "years_tweets_2019 = [years_tweets==2019]\n",
    "years_tweets_2019 = np.asarray(years_tweets_2019).reshape(-1,1)\n",
    "\n",
    "years_tweets_2020 = [years_tweets==2020]\n",
    "years_tweets_2020 = np.asarray(years_tweets_2020).reshape(-1,1)\n",
    "\n",
    "years_tweets_2021 = [years_tweets==2021]\n",
    "years_tweets_2021 = np.asarray(years_tweets_2021).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1796052",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-23T13:14:20.764027Z",
     "start_time": "2022-06-23T13:14:15.734860Z"
    }
   },
   "outputs": [],
   "source": [
    "tokens_df = pd.DataFrame(tokens_roy)#[years_tweets_2018]\n",
    "tokens_df_2014 = tokens_df[years_tweets_2014]\n",
    "tokens_df_2015 = tokens_df[years_tweets_2015]\n",
    "tokens_df_2016 = tokens_df[years_tweets_2016]\n",
    "tokens_df_2017 = tokens_df[years_tweets_2017]\n",
    "tokens_df_2018 = tokens_df[years_tweets_2018]\n",
    "tokens_df_2019 = tokens_df[years_tweets_2019]\n",
    "tokens_df_2020 = tokens_df[years_tweets_2020]\n",
    "tokens_df_2021 = tokens_df[years_tweets_2021]\n",
    "\n",
    "tokens_df_all = tokens_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50d4253a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-24T09:44:33.218839Z",
     "start_time": "2022-06-24T09:44:32.129546Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokens_df_2014' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_25480\\1161977059.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"2014:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtokens_df_2014\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"2015:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtokens_df_2015\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"2016:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtokens_df_2016\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"2017:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtokens_df_2017\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"2018:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtokens_df_2018\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tokens_df_2014' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"2014:\", tokens_df_2014.shape)\n",
    "print(\"2015:\", tokens_df_2015.shape)\n",
    "print(\"2016:\", tokens_df_2016.shape)\n",
    "print(\"2017:\", tokens_df_2017.shape)\n",
    "print(\"2018:\", tokens_df_2018.shape)\n",
    "print(\"2019:\", tokens_df_2019.shape)\n",
    "print(\"2020:\", tokens_df_2020.shape)\n",
    "print(\"2021:\", tokens_df_2020.shape)\n",
    "print(\"All:\", tokens_df_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5ff744",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-24T09:44:33.221478Z",
     "start_time": "2022-06-24T09:44:33.221478Z"
    }
   },
   "outputs": [],
   "source": [
    "### this function takes the data frame and takes all the None values out + transform it to list of list (each row becomes a list)\n",
    "def tokens_df_new(tokens_df):\n",
    "    tokens_df_new = []\n",
    "    for list_i in tokens_df.values.tolist():\n",
    "        list_i_new = []\n",
    "        for i in list_i:\n",
    "            if i != None:\n",
    "                list_i_new.append(i)\n",
    "\n",
    "        tokens_df_new.append(list_i_new)\n",
    "    return(tokens_df_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a672052",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-24T09:44:33.223762Z",
     "start_time": "2022-06-24T09:44:33.223762Z"
    }
   },
   "outputs": [],
   "source": [
    "tokens_df_new_2014 = tokens_df_new(tokens_df_2014)\n",
    "tokens_df_new_2015 = tokens_df_new(tokens_df_2015)\n",
    "tokens_df_new_2016 = tokens_df_new(tokens_df_2016)\n",
    "tokens_df_new_2017 = tokens_df_new(tokens_df_2017)\n",
    "tokens_df_new_2018 = tokens_df_new(tokens_df_2018)\n",
    "tokens_df_new_2019 = tokens_df_new(tokens_df_2019)\n",
    "tokens_df_new_2020 = tokens_df_new(tokens_df_2020)\n",
    "tokens_df_new_2021 = tokens_df_new(tokens_df_2021)\n",
    "tokens_df_all = tokens_df_new(tokens_df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c477c342",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-24T09:44:33.226390Z",
     "start_time": "2022-06-24T09:44:33.226390Z"
    }
   },
   "outputs": [],
   "source": [
    "len(tokens_df_new_2014)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9aaaae7e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-22T07:55:36.618453Z",
     "start_time": "2022-06-22T07:55:36.604253Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('default')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757371ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c3f069eb",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32096eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# word cloud\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b2e8c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97807f21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd4df43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c24ed8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c81f0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804de19a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f3515314",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-27T16:19:12.082121Z",
     "start_time": "2022-05-27T16:19:12.075122Z"
    }
   },
   "source": [
    "## Sentiment analysis\n",
    "\n",
    "Here we present the EDA we conducted using the sentiment prediction (that was the outcome of the sentiment model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2c7745",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed0ceab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
